[
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "Session Title",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "template.html#objectives",
    "href": "template.html#objectives",
    "title": "Session Title",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "template.html#setup",
    "href": "template.html#setup",
    "title": "Session Title",
    "section": "Setup",
    "text": "Setup\n\nDescription of something participants need to setup, primarily used at the beginning of a section but can also be used for tasks like setting up an Rproject file, folder structure, etc."
  },
  {
    "objectID": "template.html#main-section-1",
    "href": "template.html#main-section-1",
    "title": "Session Title",
    "section": "Main Section 1",
    "text": "Main Section 1\nYour main section(s) can (and probably should) be boken down into subsections.\n\nSubsection 1\n\n\nSubsection 2"
  },
  {
    "objectID": "template.html#done",
    "href": "template.html#done",
    "title": "Session Title",
    "section": "Done!",
    "text": "Done!\nThis last header let‚Äôs students know that they are done with the main material for the day. It should also include a link to the solutions (hosted on github). For example:\n\n\n\n Solution File\n\n\n\nMake sure this link references the main."
  },
  {
    "objectID": "template.html#going-further",
    "href": "template.html#going-further",
    "title": "Session Title",
    "section": "Going Further",
    "text": "Going Further\nAfter your main content is done you should have a section called called ‚ÄúGoing Further‚Äù for students who finish the main content early. It should include: 1. A mention of one or two satellite sessions that would be relevant extensions of the current material 2. A section with ‚Äúextra exercise questions‚Äù (these don‚Äôt need to use the ‚Äúaction blocks‚Äù (see below) and can just be a number list as shown below.\n\nExtra Exercises\n\nDo this.\nThen do that."
  },
  {
    "objectID": "template.html#markdown-reminders",
    "href": "template.html#markdown-reminders",
    "title": "Session Title",
    "section": "Markdown Reminders",
    "text": "Markdown Reminders\nThe rest of this document is a reminder on qmd syntax and a basic style guide. Enjoy.\n\nText Formatting\n\nItalic and Bold will turn out like this\nBlock quotes will look like this:\n\n\nThis is a blockquote made using &gt;\n\n\nTooltips can be done using spans (please do not use asides or footnotes)\n\n\n\nCode\nInline coding will turn out like this\nCode blocks will appear like this:\n\n# comment\nprint('hello world')\n\nWarning: For these tutorials, code blocks are not evaluated by default. If you want to evaluate them, you must indicate it specifically.\n\n# comment\nprint('hello back!')\n\n[1] \"hello back!\"\n\ntest &lt;- function(x) {\n  if (x &gt; 1) {\n    return(x)\n  } else {\n    print('nothing to see here')\n  }\n}\n\nNote. We are no longer using solution blocks, instead a single code file will be available at the end of each session contiaining code that runs through all the exercises.\n\n\nCallouts\nIMPORTANT: please do not use callouts not explicitly defined here; they have not been included in the css and therefore will not render well in the final document.\n\n\n\n\n\n\nNote\n\n\n\nThis is a callout using {.callout-note}\n\n\n\n\n\n\n\n\nTip\n\n\n\nComment about a genral tip / trick or best practice.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWarning / comment on something really important.\n\n\n\n\nAction Boxes\nThese are used for things participants are expected to actually do, ie: exercises. They are split into three categories.\n\nDescription of something participants need to setup, primarily used at the beginning of a section but can also be used for tasks like setting up an Rproject file, folder structure, etc.\n\n\nDescription of something participants should observe, investigate, etc.\n\n\nDescription of a coding exercise that participants are expected to complete.\n\n\n\nTabsets\n\nOneTwoThree\n\n\nContent that will show under the first tab\n\n\nContent that will show under the second tab\n\n\nContent that will show under the third tab\n\n\n\n\n\nImages\nYou can insert images by referring to their relative path using markdown syntax or HTML. Note that the markdown syntax does not allow you to modify image size. In either case, make sure to add alt text for accessibility.\nMarkdown style syntax:\n\n\n\nexample image alt text\n\n\nHTML style syntax (with specification of desired size):\n\n\n\nLinking to Other Pages\nEasy, use relative paths within a standard href, ie: link to home page."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html",
    "href": "sessions_extra/surveillance_companion.html",
    "title": "Surveillance",
    "section": "",
    "text": "Reuse skills aquired in the FETCH-R modules (import, clean and visualize data)\nMore specifically, analyze surveillance data to detect alerts and to help decide which alerts to prioritize for further field investigation."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#objectives",
    "href": "sessions_extra/surveillance_companion.html#objectives",
    "title": "Surveillance",
    "section": "",
    "text": "Reuse skills aquired in the FETCH-R modules (import, clean and visualize data)\nMore specifically, analyze surveillance data to detect alerts and to help decide which alerts to prioritize for further field investigation."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#introduction",
    "href": "sessions_extra/surveillance_companion.html#introduction",
    "title": "Surveillance",
    "section": "Introduction",
    "text": "Introduction\nThis satellite is a companion to the case study Measles emergency response in the Katanga region (DRC) from the FETCH Surveillance module and may thus not make sense as a standalone document.\nFrom an R point of view, this tutorial builds on skills acquired throughout the FETCH-R modules, introduces a couple of useful generalist functions, and some more specialized ones.\n\n\n\n\n\n\nTip\n\n\n\nDo not hesitate to refer to past sessions and your own scripts to remind yourself of some functions!"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#setup-question-2",
    "href": "sessions_extra/surveillance_companion.html#setup-question-2",
    "title": "Surveillance",
    "section": "Setup (Question 2)",
    "text": "Setup (Question 2)\nSince this is part of a specific module, you will create a new RStudio project. We refer you to the main session for help creating a project and importing your data.\n\nSetup a new project\n\n\nCreate a folder surveillance_case_study associated with the FETCH Surveillance module. Add the following subfolders in it:\n\n\nüìÅ data\n\nüìÅ clean\nüìÅ raw\n\nüìÅ R\nüìÅ outputs\n\n\nCreate an RStudio project at the root of the surveillance_case_study folder.\nDownload the raw data.\n\n\n\n\n Download raw data\n\n\n\n 4. Unzip the archive and save the two Excel files it contains in the subfolder data/raw.  5. Create a new script called import_clean.R and save it in the R subdirectory. Add metadata and a section to load the following packages: {here}, {rio}, and {tidyverse}.\n\n\n\nImport data in R\nReminder from the case study: you requested access to the routine surveillance data and the laboratory data to the DRC MoH. The MoH agreed to share it with you on a weekly basis. The first dataset you received is of week 20 in 2022 (the data we are working on are simulated).\n\nIf you have not done it already, open the raw data files in Excel (or another equivalent application) to inspect them.\n\nThe surveillance dataset is pretty straightforward to import. The lab dataset is slightly trickier: the data headers do not start at line one. Fear not, the skip argument from the import() function is made for this situation:\n\n# DO NOT RUN (PSEUDO-CODE)\nimport(\n  here(\"data\", \"raw\", \"example_file.xlsx\"), \n  skip = 3  # Skip the first three lines and start importing from line four.\n) \n\n\n\nAdd a section to your script dedicated to data importation.\nImport the surveillance data and store it into a data_surv_raw data frame. Then, import the lab data and save it in a data_lab_raw data frame.\nVerify that the import went well for both data frames (Viewer, check the dimensions or start and tail of data frames)."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#cleaning-question-2-and-3",
    "href": "sessions_extra/surveillance_companion.html#cleaning-question-2-and-3",
    "title": "Surveillance",
    "section": "Cleaning (Question 2 and 3)",
    "text": "Cleaning (Question 2 and 3)\n\nSurveillance data (Q2)\nNow that the data is correctly imported, we are going to perform some more checks, as usual, before a bit of cleaning.\n\nQuick checks\nDuring the case study you won‚Äôt have time to inspect and clean all columns within the available time, so for now we will focus on key columns: health_zone, week, totalcases and totaldeaths.\n\n\n\n\n\n\nNote\n\n\n\nIf you work on this tutorial in your own time, inspect the quality of the other columns and cross-check information of several columns. We refer you to the discussion of the case study for more checks to perform.\n\n\n\nAdd a section for the exploration and cleaning of the surveillance data into your script.  Now, explore the surveillance data frame and answer the following questions:\n\nWhat are the column names?\nHow many provinces are in the dataset? Is this coherent with what you expect?\nHow many health zones are in the dataset?\nWhat is the range of weeks?\nWhat is the min of totalcases?\nWhat is the max of the totaldeaths?\nDo you notice missing data for these columns? Are the strings of text clean?\n\n\n\n\nClean strings\nNow that we have a better idea of what is the state of the data, let‚Äôs start cleaning. We are going to write a cleaning pipeline like we did in the main modules (check out your code for the end of the cleaning modules to see an example final pipeline).\n\n\n\n\n\n\nTip\n\n\n\nTo facilitate debugging your pipeline, add commands one by one, checking each new command before adding a new one.\n\n\nWe are going to perform a couple of actions on the columns containing text to remove potential problems:\n\ntransform them to lower case\nremove potential extra spaces\nreplace - and spaces by _.\n\nBecause you may not have the time to do all of text colums, work on the health_zone or the province column for the following instructions.\n\nStart a cleaning pipeline with a mutate() that turns the chosen column to lower case.\n\nNow, we are going to introduce two handy functions for more text cleaning. The first one is the str_squish() function from the {stringr} package (help page here), that removes spaces at the start or end of the strings, and replace multiple spaces in the middle of a string by a single space.\n\nexamples &lt;- c(\" Trailing spaces     \",\n              \"Multiple     spaces\",\n              \" Everything     here \")\n\nstr_squish(examples)\n\n[1] \"Trailing spaces\" \"Multiple spaces\" \"Everything here\"\n\n\nThe other function, str_replace (also from the {stringr} package) does what you expect from its name: replace something in a string by something else. It has a pattern argument that take the bit of text to be replaced, and a replacement arguments that takes the bit of text to use as replacement:\n\nstr_replace(\n  \"HAUT-KATANGA\",    # A string of text (or a column, if used in a mutate)\n  pattern = \"-\",     # The bit to replace\n  replacement = \"_\"  # The replacement\n)\n\n[1] \"HAUT_KATANGA\"\n\n\n\nAdd steps to your mutate to:\n\nRemove all unwanted spaces from your chosen column\nChange the - and to _ in the column (in two steps)\n\nThe head of these columns should now be:\n\n\n  country     province    health_zone disease\n1     drc haut_katanga mufunga_sampwe measles\n2     drc haut_katanga        sakania measles\n3     drc haut_katanga        mitwaba measles\n4     drc haut_katanga kilela_balanda measles\n5     drc haut_katanga         likasi measles\n6     drc haut_katanga         kikula measles\n\n\nStore the result data frame in a data_surv object.\n\n\n\nSave the clean data\n\nUse the {rio} package to export data_surv to a .rds file called data_ids_2022-w20_clean in the data/clean subfolder of your project.\n\n\n\n\nLaboratory data (Q2)\nWe are going to follow the same steps as before for the lab data, and focus for now on the columns health_zone, igm_measles and igm_rubella.\n\nQuick checks\n\nPerform data checks on the colums names and dimensions. What are the categories for igm_measles and igm_rubella? What do you need to do to clean these columns?\n\n\n\nClean and recode strings\n\n\nStart a new cleaning pipeline to clean the lab data. As before, for one of the text column, change it to lower case, remove the extra spaces and replace the or - by _.\nRecode at least one of igm_measles or igm_rubella columns so that the categories are negatif, positif and indetermine.\nStore the cleaner version in a data_lab data frame\n\nThe head of the cleaned columns should now be:\n\n\n   health_zone igm_measles igm_rubella\n1      kambove    negative    negative\n2      kambove    negative    negative\n3      kambove    negative    positive\n4      kambove    negative    negative\n5      kambove    negative    positive\n6      kambove    negative    negative\n7      kambove    negative    negative\n8      kambove    negative    positive\n9       manika    negative    negative\n10   kamalondo    negative    negative\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can use the case_when() function to recode the IGM columns.\n\n\n\n\n\nSave the clean data\n\nExport the data_lab data frame to a .rds file called data_lab_2022-w20_clean in the data/clean subfolder of your project.\n\n\n\n\nGoing further\nThis is the end of the steps for question 2! If you finished in advance and there is still time, reuse the functions we just saw to clean the other text columns in both datasets and recode both IGM column in the lab dataset.\nIf you still have time, perform more checks on the data:\n\nDisplay the health zone for which the numbers by age group add up to a different number than the total (if any)\nAre there any health zone for which the number of deaths is higher than the total number of cases?\nAre there duplicated lines (fully duplicated, or several values for health zone and week)?\nAre there unrealistic case numbers?\n\n\n\nComplete surveillance dataset (Q3)\nDuring the case study and the data checks, you realized that some weeks are missing from the surveillance dataset. You discussed the possible reasons for it, and the associated problems. Here we are going providing code to create a dataset that contains all weeks (assuming that missing weeks had zero cases and deaths).\nWe will use the function complete() from the {tidyr} package to add the missing lines and fill the columns containing numbers (totalcases and totaldeaths) with zeros.\nLook at the simplified example below: the Kitenge health zone has no row for week 2:\n\n# Create simplified data frame for the example, with three weeks\nexample_df = data.frame(\n  province    = c(\"haut_katanga\", \"haut_katanga\", \"haut_katanga\", \"haut_lomami\", \"haut_lomami\"),\n  health_zone = c(\"likasi\", \"likasi\", \"likasi\", \"kitenge\", \"kitenge\"),\n  week        = c(1, 2, 3, 1, 3),\n  totalcases  = c(2, 1, 3, 1, 2))\n\nexample_df\n\n      province health_zone week totalcases\n1 haut_katanga      likasi    1          2\n2 haut_katanga      likasi    2          1\n3 haut_katanga      likasi    3          3\n4  haut_lomami     kitenge    1          1\n5  haut_lomami     kitenge    3          2\n\n\nWe use the following code to make sure that all the health zones have all the possible week values. Since the weeks range from one to three in that toy example, we pass a vector with weeks ranging from one to three:\n\n# Complete the missing week in Kitenge\nexample_df |&gt; \n  complete(\n    nesting(province, health_zone), \n    week = seq(1, 3),             # vector from 1 to 3\n    fill = list(totalcases = 0)   # fill new lines with zero (default is NA)\n  ) \n\n# A tibble: 6 √ó 4\n  province     health_zone  week totalcases\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 haut_katanga likasi          1          2\n2 haut_katanga likasi          2          1\n3 haut_katanga likasi          3          3\n4 haut_lomami  kitenge         1          1\n5 haut_lomami  kitenge         2          0\n6 haut_lomami  kitenge         3          2\n\n\nNow both health zones within provinces have values for all three weeks.\nYou may be wondering why we used nesting(province, health_zone) and not just health_zone. The reason is that there could be two health zones in different provinces with the same name. So we need to keep the province column into account. The nesting() argument tells the function to only use the existing combinations of the two columns in the data frame.\n\n\n\n\n\n\nNote\n\n\n\nIf we were passing both column names to the complete() function, it would try to cross all levels of province to all levels of health_zone, which does not make sense in this case:\n\n# Complete the missing week in kikula\nexample_df |&gt; \n  complete(\n    province, health_zone, \n    week = seq(1, 3),  # vector from 1 to 3\n    fill = list(totalcases = 0)\n  ) \n\n# A tibble: 12 √ó 4\n   province     health_zone  week totalcases\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 haut_katanga kitenge         1          0\n 2 haut_katanga kitenge         2          0\n 3 haut_katanga kitenge         3          0\n 4 haut_katanga likasi          1          2\n 5 haut_katanga likasi          2          1\n 6 haut_katanga likasi          3          3\n 7 haut_lomami  kitenge         1          1\n 8 haut_lomami  kitenge         2          0\n 9 haut_lomami  kitenge         3          2\n10 haut_lomami  likasi          1          0\n11 haut_lomami  likasi          2          0\n12 haut_lomami  likasi          3          0\n\n\n\n\nIt would be good to automatically pick the week series, since the data frame is going to change every week. To do that, we can remplace hardcoded values by the smallest and largest week number in the week column to get the range of weeks in the dataset:\n\n# Complete the missing week in kikula\nexample_df |&gt; \n  complete(\n    nesting(province, health_zone),\n    week = seq(min(week, na.rm = TRUE),   # vector ranging from smallest to largest week numbers in dataset\n               max(week, na.rm = TRUE)),\n    fill = list(totalcases = 0)\n  ) \n\n# A tibble: 6 √ó 4\n  province     health_zone  week totalcases\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 haut_katanga likasi          1          2\n2 haut_katanga likasi          2          1\n3 haut_katanga likasi          3          3\n4 haut_lomami  kitenge         1          1\n5 haut_lomami  kitenge         2          0\n6 haut_lomami  kitenge         3          2\n\n\n\n\nStart a new pipeline that takes the data_surv data frame and keeps only the columns province, health_zone, week and total cas.\nAdd a new step to your pipeline and paste the following code to complete the data frame:\n\n\ncomplete(\n  nesting(province, health_zone),\n  week = seq(min(week, na.rm = TRUE), \n             max(week, na.rm = TRUE)),\n  fill = list(totalcases   = 0, \n              totaldeaths = 0 # also add zero to the totaldeaths column\n  )\n) \n\n\nStore the result of the pipeline in a data frame called data_surv_weeks. The head of that data frame looks like:\n\n\n\n# A tibble: 10 √ó 5\n   province     health_zone  week totalcases totaldeaths\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n 1 haut_katanga kafubu          1          0           0\n 2 haut_katanga kafubu          2          0           0\n 3 haut_katanga kafubu          3          0           0\n 4 haut_katanga kafubu          4          0           0\n 5 haut_katanga kafubu          5          0           0\n 6 haut_katanga kafubu          6          0           0\n 7 haut_katanga kafubu          7          0           0\n 8 haut_katanga kafubu          8          0           0\n 9 haut_katanga kafubu          9          0           0\n10 haut_katanga kafubu         10          0           0\n\n\n\nWhen you are done, export that data frame to a .rds file called data_ids_2022-w20__weeks_clean in the data/clean subfolder of your project.\n\n\n\n\nGoing further\nThis is the end of question 3; if you are finished in advance, do not hesitate to carry on checking the data and listing potential problems and cleaning the columns. Or go explore the complete() help page` to better understand how the function works."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#defining-alerts-question-4",
    "href": "sessions_extra/surveillance_companion.html#defining-alerts-question-4",
    "title": "Surveillance",
    "section": "Defining alerts (Question 4)",
    "text": "Defining alerts (Question 4)\n\nPreparing the dataset\nWe are going to carry on preparing the datasets for the analyses.\n\n\nIf you have not had the time to clean both health zone and province in both datasets, as well as both igm columns in the lab dataset you can import cleaner versions of the data:\n\n\n\n\n Download clean data\n\n\n\n Unzip the archive in your data/clean subfolder\n\nCreate a new script analysis_surv.R in the R subfolder. Add the metadata of the script, a package import section to import the packages {here}, {rio}, {tidyverse}, {lubridate} and {zoo}.\nAdd an import data section and import the clean .rds files in R using the import() function as usual (your cleaned version or the one you just downloaded). Assign the cleaned data to data_surv, data_lab and data_surv_weeks and carry on.\n\n\n\nSubset health zone\nTo simplify the work, we are going to focus on four health zones: Dilolo, Kampemba, Kowe, and Lwamba.\n\nStart a new pipeline from data_surv_weeks. Its first step is to only retain data for the the Dilolo, Kampemba, Kowe, and Lwamba health zones.\n\n\n\nWeekly indicator\nThe first indicator we want to caclulate is whether a health zone has 20 or more suspected cases in one week. This indicator is binary and only considers data in a given health zone and week, which corresponds to individual rows of our data frame.\n\nAdd a mutate() to your pipeline, to create a cases20 column that contains 1 if a given health zone has 20 cases or more in that week, and 0 otherwise.\n The top of the data frame created by the pipe thus far looks like this:\n\n\n# A tibble: 10 √ó 6\n   province     health_zone  week totalcases totaldeaths cases20\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n 1 haut_katanga kampemba        1         75           0       1\n 2 haut_katanga kampemba        2         42           0       1\n 3 haut_katanga kampemba        3         46           0       1\n 4 haut_katanga kampemba        4         50           0       1\n 5 haut_katanga kampemba        5         43           0       1\n 6 haut_katanga kampemba        6         33           0       1\n 7 haut_katanga kampemba        7         45           0       1\n 8 haut_katanga kampemba        8         52           0       1\n 9 haut_katanga kampemba        9         38           0       1\n10 haut_katanga kampemba       10         46           0       1\n\n\n\n\n\nCumulative indicator\nThe second indicator you want to calculate is whether a health zone has more than 35 cumulated suspected cases within three weeks. This is a bit more complicated than the previous case: within health zone you need to calculate the sum of cases by groups of three weeks, but the groups are not fixed, they are rolling across time. We are getting in the territory of moving averages/sums/etc.\n\nCumulative sum\nWe are going to use the rollapply() function from the {zoo} package, as it is versatile and powerful. As its name suggests, the rollapply() function applies a function in a rolling way to a vector or a column of a data frame.\nSince we are constrained in time, we are going to provide the code of the rollapply() function to calculate the cumulative sum over three weeks, but check out the details in the Going further section when you have time.\nThis is how to do it for one health zone:\n\n# Create mini example data frame\nexample_df = data.frame(\n  province    = \"Haut Katanga\",\n  health_zone = \"Dilolo\",\n  week        = 1:10,\n  totalcases  = rep(1, times = 10))\n\nexample_df \n\n       province health_zone week totalcases\n1  Haut Katanga      Dilolo    1          1\n2  Haut Katanga      Dilolo    2          1\n3  Haut Katanga      Dilolo    3          1\n4  Haut Katanga      Dilolo    4          1\n5  Haut Katanga      Dilolo    5          1\n6  Haut Katanga      Dilolo    6          1\n7  Haut Katanga      Dilolo    7          1\n8  Haut Katanga      Dilolo    8          1\n9  Haut Katanga      Dilolo    9          1\n10 Haut Katanga      Dilolo   10          1\n\nexample_df |&gt; \n  mutate(cumcas = rollapply(\n    data  = totalcases, # The column to work on\n    width = 3,          # Width of the window  \n    FUN   = sum,        # Function to apply, here the sum   \n    align = \"right\",    # We are counting backward in time\n    partial = TRUE,     # Allows sum to be made even if window is less than three\n    na.rm = TRUE        # Extra unamed argument to be passed to the sum function\n  )\n  )\n\n       province health_zone week totalcases cumcas\n1  Haut Katanga      Dilolo    1          1      1\n2  Haut Katanga      Dilolo    2          1      2\n3  Haut Katanga      Dilolo    3          1      3\n4  Haut Katanga      Dilolo    4          1      3\n5  Haut Katanga      Dilolo    5          1      3\n6  Haut Katanga      Dilolo    6          1      3\n7  Haut Katanga      Dilolo    7          1      3\n8  Haut Katanga      Dilolo    8          1      3\n9  Haut Katanga      Dilolo    9          1      3\n10 Haut Katanga      Dilolo   10          1      3\n\n\n\n\nBy health zone\nNow, we want to do this cumulative sum by health zone. This is not that complicated: we are going to sort our data frame properly by health zone and week, and use the .by argument to tell the mutate() function to perform the action by health zone.\n\n\n\n\n\n\nNote\n\n\n\nYou may remember from the aggregation session how we summarized by groups using the .by argument in the summarize() function. This is exactly the same idea, except that instead of returning one value by group (as summarize() does), we want to return one value per row (as mutate() does).\nAs a little reminder of how summarize() + .by work, here is how we would calculate the total number of patients and deceased by province over the whole dataset:\n\ndata_surv_weeks |&gt; \n  summarize(\n    .by = province,  # Do things by province\n    cases_tot = sum(totalcases, na.rm = TRUE),\n    dead_tot  = sum(totaldeaths, na.rm = TRUE)\n  )\n\n# A tibble: 4 √ó 3\n  province     cases_tot dead_tot\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n1 haut_katanga      5948       34\n2 haut_lomami       6928       70\n3 lualaba           1485        3\n4 tanganyika        7836      137\n\n\n\n\n\n\nAdd a step to your previous pipeline to sort the data frame by province, health zone and week with the arrange() function, which is a sorting function from {dplyr}\n\n\ndata_surv_weeks |&gt; \n  arrange(province, health_zone, week)\n\n\nThen add the following code to calculate the cumulative sum:\n\n\nmutate(\n  .by = c(province, health_zone),\n  cumcas = rollapply(\n    data  = totalcases,\n    width = 3,          # Width of the window  \n    FUN   = sum,        # Function to apply, here the sum   \n    align = \"right\",    # Windows are aligned to the right\n    partial = TRUE,     # Allows sum to be made even if window is less than three\n    na.rm = TRUE        # Extra unamed argument to be passed to the sum function\n  )\n)\n\n\nNow that the complicated part is over (the computing of the cumulative sum) we are left to summarize the information with a binary indicator, for heach week and health zone. Then we can create a second indicator, that aggregates the result of both the weekly and cumulative indicators, to say if an alert is to be raised.\n\n\nAdd a new step to your pipeline to calculate a binary indicator, cumcases35 that is 1 if the cumulative sum of cases for that week is equal or above 35 and 0 if not.\nAdd a new column alert, that is 1 if either the cases20 indicator or the cumcases35 indicator is 1 and 0 otherwise. You can use the | operator, which is R logical OR (the test will output TRUE if at least one of the condition is TRUE)..\nWhen the pipe is working, assign the result to a data_alert data frame.\n\nThe main columns of data_alert should look like this (other hidden for display):\n\n\n# A tibble: 10 √ó 7\n   health_zone  week totalcases cases20 cumcas cumcases35 alert\n   &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 kampemba        1         75       1     75          1     1\n 2 kampemba        2         42       1    117          1     1\n 3 kampemba        3         46       1    163          1     1\n 4 kampemba        4         50       1    138          1     1\n 5 kampemba        5         43       1    139          1     1\n 6 kampemba        6         33       1    126          1     1\n 7 kampemba        7         45       1    121          1     1\n 8 kampemba        8         52       1    130          1     1\n 9 kampemba        9         38       1    135          1     1\n10 kampemba       10         46       1    136          1     1\n\n\n\n\n\n\n\nHealth zones in alert\nAfter all this work we can finally investigate which health zones are in alert in the last week of our dataset (the now of the case study, week 20)!\n\nFilter your data frame to only keep the 20th week. Which health zones are in alert?\nCreate a vector hz_alert that contains the name of the health zones in alert, so that we can use it to filter data from these health zones later."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#draw-the-epicurve-question-4",
    "href": "sessions_extra/surveillance_companion.html#draw-the-epicurve-question-4",
    "title": "Surveillance",
    "section": "Draw the epicurve (Question 4)",
    "text": "Draw the epicurve (Question 4)\nLet us draw the epicurves of health zones currently in alert (in alert during week 20).\nWe have drawn very similar curves in the epicurve session. Here again we will use the ggplot() function with the geom_col() geom to create a barplot showing the distribution of cases. Since we already have the number of cases per week we do not need to count it ourselved like we did in the past.\n\nDraw an epicurve for one of the health zones in alert.\n The graph should look like this (but maybe for another health zone):\n\n\n\n\n\n\n\n\n\n\nThe facet_wrap() function allows us to plot several subplots in the same graph (see the faceting satellite for more information on faceting):\n\ndata_alert |&gt;\n  filter(health_zone %in% hz_alert) |&gt;\n  ggplot(aes(x = week, \n             y = totalcases)) + \n  geom_col(fill = \"#2E4573\") + \n  theme_bw(base_size = 15) + \n  labs(x = \"Week\",\n       y = \"N cases\",\n       title = \"Health zones in alert\") +\n  facet_wrap(vars(health_zone))   # One graph by health_zone"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#key-indicators-question-6",
    "href": "sessions_extra/surveillance_companion.html#key-indicators-question-6",
    "title": "Surveillance",
    "section": "Key indicators (Question 6)",
    "text": "Key indicators (Question 6)\nLet‚Äôs gather more data on both alerts to help you decide which one to investigate.\n\n\n\n\n\n\nTip\n\n\n\nThis session builds on summarizing skills seen in the summary session. Do not hesitate to check it or your code if you forgot something.\n\n\n\nWeek of the first alert\n\nUse the summarize() function to display the first week the alert was raised for each health zone in alert. Which health zone started first?\n\n\n\nSurveillance data indicators\nLet us go back to the full surveillance dataset that contains more columns of interest.\n\n\nAdd a column cunder_5 to data_surv that contains the the number of cases less than five years.\nDerive, for each health zone in alert, the following indicators (organized in a single table):\n\n\nThe number of cases\nThe number of deaths\nThe number of less than five year olds\nThe CFR in percentage\nThe percentage of reported cases under five\n\nThe result should look like this:\n\n\n  health_zone n_cases n_deaths n_under_5 p_under_5     cfr\n1    kampemba     730        0       544 0.7452055 0.00000\n2      lwamba     256        2       233 0.9101562 0.78125\n\n\n\n\n\nLab data indicators\nNow we are going to use the laboratory data to derive a couple more indicators.\n\nFor each health zone in alert, derive the following indicators within one table:\n\nThe number of patients tested for measles\nThe number of positives for measles\nThe percentage of positives for measles\nThe number of patients tested for rubella\nThe number of positive for rubella\nThe percentage of positive for rubella\n\nThe result should look like this:\n\n\n  health_zone n_test_meas n_test_meas_pos positivity_measles n_test_rub\n1      lwamba          10               5          0.5000000         10\n2    kampemba          14               4          0.2857143         14\n  n_test_rub_pos positivity_rubella\n1              0         0.00000000\n2              1         0.07142857\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCheck out the section on summaries with conditions to remind you of the more advanced summaries."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#done",
    "href": "sessions_extra/surveillance_companion.html#done",
    "title": "Surveillance",
    "section": "Done!",
    "text": "Done!\nCongratulation, you are done!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#sec-going-further",
    "href": "sessions_extra/surveillance_companion.html#sec-going-further",
    "title": "Surveillance",
    "section": "Going Further",
    "text": "Going Further\n\nExploring the rollaply() function\nIf we want to do a cumulative sum of cases over three weeks, we want to apply the sum() function over windows of three weeks.\n\nexample_vect &lt;- rep(1, time = 10)\nexample_vect\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\nrollapply(\n  data  = example_vect,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\"  # Value at row i is the sum of i, i-1 and i-2.\n)\n\n[1] 3 3 3 3 3 3 3 3\n\n\nWe inputed a vector of ten values and obtained a vector of lenght height, containing the sums. Obviously the function has a way of dealing with the extremities, and the size of the output is smaller than the size of the input. This would be a problem in a mutate() that creates new columns in a data frame, that need to be the same length as the existing columns.\nYou can control the behavior at the extremities:\n\nFill with NA when there is not enough values to calculate a window of three\nAllow partial sums (some values represent less than three weeks)\n\nThe argument fill = NA pads the extremities with NA (on the left in our case, since we aligned right):\n\nrollapply(\n  data  = example_vect,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  fill  = NA\n)\n\n [1] NA NA  3  3  3  3  3  3  3  3\n\n\nIt is a reasonnable way of dealing with incomplete windows. In our case however, we can do better: if there were 40 cases in week 1 it would be a cause for alert! We thus want the cumulative sum to be calculated from week one to be able to detect early alerts. The partial = TRUE argument allows this:\n\nrollapply(\n  data    = example_vect,\n  width   = 3,       # Width of the window  \n  FUN     = sum,     # Function to apply, here the sum   \n  align   = \"right\", # Windows are aligned to the right\n  partial = TRUE)\n\n [1] 1 2 3 3 3 3 3 3 3 3\n\n\nThis is close to what we need.\n\n\n\n\n\n\nNote\n\n\n\nKeeping in mind that since the first two weeks have only partial data compared to later weeks, a lack of alert in these weeks does not necessarily means there is no alert, just that we do not have the data to detect it.\n\n\nYou may remember that arithmetic operations in R return NA if some of the values are NA and we usually need to pass the argument na.rm = TRUE to the functions for them to ignore missing values.\nIf we had a slightly less complete vector we would have a problem:\n\nexample_vect_missing &lt;- c(1, 1, 1, NA, 1, 1)\n\nrollapply(\n  data  = example_vect_missing,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  partial = TRUE   # Allows sum to be made even if window is less than three\n)\n\n[1]  1  2  3 NA NA NA\n\n\nFortunately we can pass the na.rm = TRUE argument to rollapply() so that it passes it to sum().\n\nrollapply(\n  data  = example_vect_missing,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  partial = TRUE,  # Allows sum to be made even if window is less than three\n  na.rm = TRUE     # Extra unamed argument to be passed to the sum function\n)\n\n[1] 1 2 3 2 2 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nHere we applied the sum() function to create a cumulative sum over 3 weeks. But you could, with minimal modifications, apply the mean() function to caclulate a moving average!\n\n\nA last point on the align argument. It defines the position of the rolling windows compared to the value being calculated. The default is that the window is centered: the value i is the sum of values i, i-1 and i+1.\nExample of the three alignements (pading with NA to better see what‚Äôs happening):\n\nrollapply(data  = c(5, 10, 1, 2, 5, 10),\n          width = 3, \n          FUN   = sum,\n          align = \"left\",\n          fill = NA)\n\n[1] 16 13  8 17 NA NA\n\nrollapply(data  = c(5, 10, 1, 2, 5, 10),\n          width = 3, \n          FUN   = sum,\n          align = \"center\",\n          fill = NA)  # The default\n\n[1] NA 16 13  8 17 NA\n\nrollapply(data  = c(5, 10, 1, 2, 5, 10),\n          width = 3, \n          FUN   = sum,\n          align = \"right\",\n          fill = NA)\n\n[1] NA NA 16 13  8 17\n\n\nIn our case we want the value for a given week to reflect this week and the week past, so we align the window right, to calculate backward in time (by opposition, if we aligned left we would calculate forwards in time).\n\n\nNicely formatted percentages\nThe percent function from the {scales} packages can add percentage formatting to a value.\n\nscales::percent(0.8556)\n\nIt takes an accuracy arguments that controls the number of decimals:\n\nscales::percent(0.8556,\n                accuracy = 0.1)\n\nYou can wrap it around the values that you calulate in the summary tables to change the proportions into nicely formatted percentages. ::: {.callout-important} Once you aplied that function the column is treated as text (since we added a % sign) and you will not be able to do further arithmetical operations on it. :::"
  },
  {
    "objectID": "sessions_extra/data_exploration.html",
    "href": "sessions_extra/data_exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Perform quick exploration of an imported dataset\nProduce frequency tables for variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#objectives",
    "href": "sessions_extra/data_exploration.html#objectives",
    "title": "Data Exploration",
    "section": "",
    "text": "Perform quick exploration of an imported dataset\nProduce frequency tables for variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#setup",
    "href": "sessions_extra/data_exploration.html#setup",
    "title": "Data Exploration",
    "section": "Setup",
    "text": "Setup\nDependencies. This extra session assumes that you have completed the sessions introduction to R and R studio, and data importation.\n\nFor this session we will work with our raw Moissala measles linelist which can be downloaded here:\n\n\n\n  Course Folder\n\n\n\n Make sure it is appropriately stored in data/raw of your project. Then open a new script called data-exploration.R, and make sure packages {here}, {rio} and {dplyr} are loaded. Finally, import the data into R as an object called df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#data-exploration",
    "href": "sessions_extra/data_exploration.html#data-exploration",
    "title": "Data Exploration",
    "section": "Data Exploration",
    "text": "Data Exploration\nRight after importing some data into R, we might want to take a look at it. When talking of data exploration we usually want to do a few things:\n\nExamine dimensions of the data (ie: how many rows and how many columns)\nLook at columns names\nVisualise the first or last few rows\nDetermine the type of the variables\nDetermine the range of values in continuous variables\nObserve the possible values in each categorical variable\n\nThis process is crucial and will allow us to familiarize ourselves with our data and identify issues that will be adressed during the data cleaning step."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#basic-exploration",
    "href": "sessions_extra/data_exploration.html#basic-exploration",
    "title": "Data Exploration",
    "section": "Basic Exploration",
    "text": "Basic Exploration\nThe very first thing you want to know about your data is the dimensions, which refers to the number of rows and number of columns that make up your data. There are several ways to get this information in R:\n\nLook at your environment pane in RStudio and check for your data - the number next to it (5230x25) tells us it is a dataframe with 5230 rows and 25 columns.\nUse dim() on your data to return a vector with both the number of rows and number of columns\nAlternatively, use ncol() to get the number of columns and nrow() for the number of rows\n\nIt‚Äôs good to remember these numbers so you can quickly spot if there are unexpected changes to your data during your analysis (ie: more/fewer rows or columns than expected).\n\nUsing the method of your choice, get the dimensions of your dataframe df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#variable-names",
    "href": "sessions_extra/data_exploration.html#variable-names",
    "title": "Data Exploration",
    "section": "Variable Names",
    "text": "Variable Names\nBecause we are going to use the variable names very often during our analysis, we want to get familiar with them pretty early on. Also, we need to identify the ones that will need to be renamed during our data cleaning. The function names() returns a vector of all the variable names in our dataframe:\n\nnames(df_linelist)\n\n [1] \"id\"                   \"full_name\"            \"sex\"                 \n [4] \"age\"                  \"age_unit\"             \"region\"              \n [7] \"sub_prefecture\"       \"village_commune\"      \"date_onset\"          \n[10] \"date_consultation\"    \"hospitalisation\"      \"date_admission\"      \n[13] \"health_facility_name\" \"malaria_rdt\"          \"fever\"               \n[16] \"rash\"                 \"cough\"                \"red_eye\"             \n[19] \"pneumonia\"            \"encephalitis\"         \"muac\"                \n[22] \"vacc_status\"          \"vacc_doses\"           \"outcome\"             \n[25] \"date_outcome\"        \n\n\n\nWhat do you think of the names in your dataset? Can you already spot some variables names you would like to rename?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#inspecting-your-data",
    "href": "sessions_extra/data_exploration.html#inspecting-your-data",
    "title": "Data Exploration",
    "section": "Inspecting Your Data",
    "text": "Inspecting Your Data\nIt is also nice to inspect your data, it may be easier for you to spot some inconsistencies, variables with a lot of missing values, and it will allow you to see what values to expect in each of them. You can print your data in the console by:\n\nRunning the df_linelist object alone (careful though, you may not want to do this if you have a large dataset)\nUse the head() function to see the top 6 rows (you can increase this number using the argument n)\nUse the tail() function to see the last 6 rows (again, you can increase this number using the argument n)\n\nThese methods will only print the first 40 rows of your data at most because that‚Äôs the limit of your console. Alternatively, you can use View() to see your data in a tabular form. This will open a new window with your data displayed like like an Excel spreadsheet. Note, this command only displays the data, it doesn‚Äôt allow you to modify it.\n\n\n\n\n\n\nTip\n\n\n\nBe very careful with View() on large dataset as this may crash your RStudio session. To avoid this, you can print the output in the console.\n\n\n\nCan you display the first 15 rows of your data? What happen when you change the width of your console pane and run the command again?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#variable-type",
    "href": "sessions_extra/data_exploration.html#variable-type",
    "title": "Data Exploration",
    "section": "Variable Type",
    "text": "Variable Type\nWe now want to check the type of the different variables. This is important as part of data cleaning involves making sure that numerical variables are type numeric, dates Date, and categorical variables are factor or character. You have already seen the class() function, to check the type of a vector. In R, each variable of a dataframe is a vector. We can extract all the values of that vector using the $ sign, and pass it to the class() function:\n\nclass(df_linelist$age)\n\n\nTry extracting all the values from the sex variable. What is the type of this variable?\n\nYou can also use str() on your dataframe to check the class of all the variables at once:\n\nstr(df_linelist)\n\n\nUse str() to check the data type of each column. Does anything look odd? Remember that you can also use functions like is.character() and is.numeric() if you‚Äôd like to test the type of a particular column."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#exploring-continuous-variables",
    "href": "sessions_extra/data_exploration.html#exploring-continuous-variables",
    "title": "Data Exploration",
    "section": "Exploring Continuous Variables",
    "text": "Exploring Continuous Variables\nNow that you know how to extract the values from a variable, you may want to explore some of these values from the numeric variables to check for inconsistencies. Let‚Äôs look for some summary statistics for these, and Base R provides many handy functions:\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nExample\nReturns\n\n\n\n\nmin()\nMinimum value\nmin(x)\nSingle minimum value\n\n\nmax()\nMaximum value\nmax(x)\nSingle maximum value\n\n\nmean()\nArithmetic average\nmean(x)\nAverage value\n\n\nmedian()\nMiddle value\nmedian(x)\nMiddle value\n\n\nrange()\nMin and max\nrange(x)\nVector of (min, max)\n\n\nIQR()\nInterquartile range\nIQR(x)\nQ3 - Q1\n\n\nquantile()\nSpecified quantiles\nquantile(x, probs = c(0.25, 0.75))\nRequested quantiles\n\n\nsd()\nStandard deviation\nsd(x)\nStandard deviation\n\n\nvar()\nVariance\nvar(x)\nVariance\n\n\nsum()\nSum of values\nsum(x)\nSum\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThese functions require you to explicitly remove missing values (NA) using the argument na.rm = TRUE\n\n\nYou can extract the values of a variables using $, and pass them to any of those functions.\n\nUse the $ syntax to get:\n\nThe minimum value of age\nThe maximum of muac\n\nAny problems?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#exploring-categorical-variables",
    "href": "sessions_extra/data_exploration.html#exploring-categorical-variables",
    "title": "Data Exploration",
    "section": "Exploring Categorical Variables",
    "text": "Exploring Categorical Variables\nFinally, let‚Äôs look at the values in our categorical variables. For this we can use frequency tables. This is handy as:\n\nIt allows us to quickly see the unique values in a categorical variable\nThe number of observations for each of those categories\n\nThis is done using the function count() from the package {dplyr}, which accepts the a dataframe and the name of one (or more!) column(s) as arguments. It will then count the number of observations of each unique element in that column. For example, let‚Äôs see the possible values of the variable sex:\n\ncount(df_linelist, sex)\n\nThe output is a new, smaller dataframe containing the number of patients observed stratified by sex. It seems like this variable requires some recoding‚Ä¶ We will do that in a later session.\n\nUsing your linelist data, look into the values for the outcome variable. How does it look?\nNow, try adding the argument sort = TRUE to the count() function. What did this argument do?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#done",
    "href": "sessions_extra/data_exploration.html#done",
    "title": "Data Exploration",
    "section": "Done!",
    "text": "Done!\nWell done taking a first look at your data!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/05_summary_table.html",
    "href": "sessions_core/05_summary_table.html",
    "title": "Summary Tables",
    "section": "",
    "text": "Create contingency tables with count()\nCompute summary statistics by group using summarize()\nReview how to subset rows using filter() and create/modify variables with mutate()\nCreate ordered categorical variables"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#objectives",
    "href": "sessions_core/05_summary_table.html#objectives",
    "title": "Summary Tables",
    "section": "",
    "text": "Create contingency tables with count()\nCompute summary statistics by group using summarize()\nReview how to subset rows using filter() and create/modify variables with mutate()\nCreate ordered categorical variables"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#setup",
    "href": "sessions_core/05_summary_table.html#setup",
    "title": "Summary Tables",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio that you are able to import data and that you know th basic data handling verbs that we have seen in the core sessions so far. If you need a refresher on either of these topics, we encourage you to review the core sessions in the learning pathway.\n\nThis session will use the clean version of the Moissala measles dataset.\n\n\n\n  Course Folder\n\n\n\n Open your RStudio Project and create a new script in the R folder called tables.R with appropriate metadata and a ‚ÄúPackages‚Äù section that imports: {rio}, {here} and {tidyverse}. Add an ‚ÄúImport Data‚Äù section that loads the cleaned version of the measles linelist."
  },
  {
    "objectID": "sessions_core/05_summary_table.html#introduction-data-aggregation",
    "href": "sessions_core/05_summary_table.html#introduction-data-aggregation",
    "title": "Summary Tables",
    "section": "Introduction: Data aggregation",
    "text": "Introduction: Data aggregation\nOK so let‚Äôs recap, you have just performed one of the most important tasks of an epidemiologist: the data cleaning. Now that you have clean and standardized data, you can get into the real business and start analysing them. Analyses typically start with some tables and summaries that describe our data:\n\nUnivariate frequency tables to count occurrences of different values\nSummary statistics of numerical variables (mean, median, standard deviation)\nCross-tabulations to examine relationships between categorical variables\nGroup-wise summaries to compare statistics across different subsets of the data"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#counting-multiple-columns-contingency-tables",
    "href": "sessions_core/05_summary_table.html#counting-multiple-columns-contingency-tables",
    "title": "Summary Tables",
    "section": "Counting Multiple Columns (Contingency Tables)",
    "text": "Counting Multiple Columns (Contingency Tables)\nDuring the data exploration session, you have learned to create a frequency table for a single categorical variable using the count() function. This is nice, but we often want to count the number observations based on two (or more!) variables.\nThese tables are called contingency tables. For example, knowing the number of patients by sub_prefecture is great but we might want to stratify by both sub_prefecture and age_group to see if certain areas have unusually old patients. Doing this is easy, you just need to pass multiple column names to count():\n\ndf_linelist |&gt;\n  count(sub_prefecture, age_group)\n\n\nCreate a new summary table counting the number of patients stratified by sub_prefecture and hospitalisation. What happens if you change the order of the arguments given to count()?  Now, using count(), answer the following questions:\n\nHow many patients were female? What is the proportion?\nWhat are all the possible values of the outcome variable?\nHow many patients between 1 - 4 years have recovered?"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#filtering-out-nas",
    "href": "sessions_core/05_summary_table.html#filtering-out-nas",
    "title": "Summary Tables",
    "section": "Filtering out NAs",
    "text": "Filtering out NAs\nWhen looking at the categories of outcome, you should have spotted that some patients have missing values (NA):\n\ndf_linelist |&gt;\n  count(outcome) |&gt;\n  mutate(prop = n / sum(n))\n\n\nObserve the output of the code above. How can you also call the proportion of patients who died? Are you happy with this calculation?\n\nThe proportion of cases that died is also referred to as the Case Fatality Ratio (CFR). To precisely calculate the CFR we need to make sure that the denominator only includes patient for whom we are sure of their outcome (ie we need to remove all cases with NA or left aginst medical advice).\nRemember that we can do this using filter(). To filter for missing values (NA) in a variable we can use the small function is.na(outcome). Adding a ! in front will do the opposite: removing missing values from outcome:\n\ndf_linelist |&gt;\n  filter(\n    outcome != \"left against medical advice\", \n    !is.na(outcome)\n  ) |&gt;\n  count(outcome)\n\n\nWhich other conditionnal statement could you use in filter() to obtain the same results\n\nNow that we have removed the patients with unknown outcomes, we can add this before creating our frequency table to get the right CFR.\n\nUsing your filter, update your code to summarize the observed number of patients who survived and died as well as the CFR (proportion who died). Store this new dataframe into an object, cfr_df.\n\n\n\n\n\n\n\nTip\n\n\n\nBonus. A useful ‚Äúshortcut‚Äù function is drop_na() from the package {tidyr} that equates to filter(!is.na()).\n\ndf_linelist |&gt;\n  drop_na(outcome) |&gt;\n  count(outcome)\n\ndrop_na() is particularly useful as you can give it multiple column names to filter by. But be careful that doing so will remove all rows where one or more of those columns have a missing value."
  },
  {
    "objectID": "sessions_core/05_summary_table.html#sec-stratify",
    "href": "sessions_core/05_summary_table.html#sec-stratify",
    "title": "Summary Tables",
    "section": "Summary Table: Statistics by Sub Prefecture",
    "text": "Summary Table: Statistics by Sub Prefecture\nOk now that we have produced some simple frequency and contingency tables we may want to increase the complexity. A common task in epidemiology is to look at summary statistics within subsets of the data.\nFor example, we may be asked to produce patient statistics at the sub-prefecture level, ie: for each sub-prefecture in the data, we need to answer the following questions:\n\nHow many patients consulted?\nWhat is their average age?\nWhat was the earliest date of admission?\nHow many patients have been hospitalized?\nAmong children under 6 months, how many have died?\n\nThis is exactly what the function summarize() has been made for! It allows us to calculate summary statistics on a dataset, and the syntax is similar to that of mutate():\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  mutate(new_col = function_to_create(existing_col))\n\ndf |&gt;\n  summarize(\n    .by = grouping_variable,\n    new_col = summary_function(existing_col)\n  )\n\nConsider the following code, here we are summarizing the data to calculate the average age across all patients.\n\ndf_linelist |&gt;\n  summarize(mean_age = mean(age))\n\n  mean_age\n1 6.822047\n\n\nNotice that this code yields a single value for average age. No grouping variable was provided so summarize() returned one summary statistic for the whole dataset. To calculate the average age by a specific strata, we need to specify a grouping variable using the .by argument:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sex,  # Make the summary (here, the mean) by sex\n    mean_age = mean(age)\n  )\n\n  sex mean_age\n1   f 6.773824\n2   m 6.869855\n\n\n\nTake a look at the above results. How would you interpret them?\n\nNow that we can use summarize() we can use it to calculate some proper summary statistics by sub-prefecture. Let‚Äôs start by calling an empty summarize() and grouping the data on sub_prefecture.\n\nRun the following code:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture\n  )\n\nWhat happens when you run these lines?\n\n\nCounts\nWe first want to look at the number of cases in each sub_prefecture. This can be done using the helper function n():\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n() # Count stuffs\n  )\n\n\nOk now let‚Äôs build a summary table for each sub_prefecture. First start by replicating the above lines\n\n\n\nSummarizing Continuous Variables\nWe can then use the mean(), median(), min(), max() functions (and other) to produce summaries for continuous variables. For example the average age:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n(),\n    mean_age = mean(age)\n  )\n\n\nAdd the minimum date of admission to your table for each of the sub_prefecture? Are you happy with the results?\n\n\n\n\n\n\n\nTip\n\n\n\nRemember that with the arithmetic functions such as mean(), median(), min(), max(), you need to explicitly tell R to remove NA.\n\n\n\n\nCounting with a Condition\nWe may also be interested in looking at the number of patients (rows) that fit a condition: the number of patients that were female. Counting by a logical condition can be done with the following syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\nsummarize(\n  sum_category = sum(LOGIC_TEST, na.rm = TRUE)\n  )\n\nThis sum allows us to count all the lines where our condition was met (returns TRUE). For example:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_female = sum(sex == \"f\", na.rm = TRUE)\n  )\n\n\nAdd a variable to your table that counts the number of patients that have been hospitalized. (ie: rows that have yes in variable hospitalisation)\n\n\n\nOther Statistics\nSometimes we want to produce a more complicated statistic, for example the mean age of all hospitalized patients. Here the syntax is a bit different:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  summarize(\n    mean_category = mean(col_to_use[LOGIC_TEST], na.rm = TRUE)\n    )\n\nHere, we have:\n\nStated what summary statistic we want to use (mean())\nIndicated which column we want to calculate that statistic on (col_to_use)\nCreated a condition of which observations in that column to use in the calculation ([LOGIC_TEST])\n\nTo give a concrete example, if we wanted to compute the mean of the age variable but only for hospitalized patients (ie: in rows where hospitalisation == \"yes\") we would write:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n(),\n    mean_age_hosp = mean(age[hospitalisation == \"yes\"], na.rm = TRUE)\n  )\n\nThe use of a logical test in the example above is called logical indexing, where a condition is essentially being used to filter which observations you want to consider when performing a calculation. Logical indexing is very powerful but can also take some getting used to, so don‚Äôt worry too much if it isn‚Äôt perfectly clear at this stage.\n\nCan you use this syntax to calculate the mean age of female patients in your table?\n\nThat is looking great! We are starting to get a pretty exhaustive grouped summary table with a lot of useful information by sub_prefecture! An extra challenge for you:\n\nCHALLENGE: Could you add a variable to your table that counts the number of patients that died among the ones that are &lt; 6 months old.\n Hint. You want to count rows (so use sum()) that fill a specific condition for outcome (outcome == \"dead\"), but only when age_group == \"&lt; 6 months\"\n\n\n\nUse the Output\nFinally, remember that summarize() returns a dataframe that we can then further manipulate (eg: with filter() and mutate()).\n\nAdd a mutate() after producing your summary table to calculate:\n\nThe proportion of hospitalized patients per sub-prefecture\nThe proportion of female patients per sub-prefecture\n\n\nThe head of your final table should look like this:\n\n\n  sub_prefecture n_patients mean_age min_admission n_female n_hosp\n1       Moissala       1808 6.842920    2022-08-14      923    612\n2          Bouna       1376 6.555959    2023-01-11      669    412\n3       Bedjondo        534 7.073034    2023-06-09      251    184\n4       Bekourou        496 6.836694    2023-06-17      251    164\n5         Bedaya        435 7.098851    2023-07-04      209    147\n6         Koumra        253 7.106719    2023-08-14      138     84\n  mean_age_hosp mean_age_female n_death_u6m prop_female prop_hosp\n1      5.485294        6.748646          71   0.5105088 0.3384956\n2      5.665049        6.633782          61   0.4861919 0.2994186\n3      5.211957        6.948207          22   0.4700375 0.3445693\n4      6.042683        6.840637          25   0.5060484 0.3306452\n5      6.156463        7.105263          17   0.4804598 0.3379310\n6      6.261905        6.456522           7   0.5454545 0.3320158"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#done",
    "href": "sessions_core/05_summary_table.html#done",
    "title": "Summary Tables",
    "section": "Done!",
    "text": "Done!\nYou should be proud of yourselves, making summary tables is an important skill to an epidemiologist, making it in R is very efficient! Don‚Äôt forget to save your code!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#going-further",
    "href": "sessions_core/05_summary_table.html#going-further",
    "title": "Summary Tables",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nMake a summary table that summarizes:\n\nThe number of patients\nThe proportion of male\nThe number of deaths\nThe CFR\nThe number of deaths among patients that had pneumonia\nin all the different age groups !\n\nMake a table that shows the proportion of patients by age with any measles vaccine (by oral recall or card) and those with 1 or 2 doses.\nMake a table that compares the proportion of hospitalised and non-hospitalised patients with positive malaria RDT, fever, rash, cough, red eye, pneumonia, encephalitis, and ‚Äúred‚Äù or ‚Äúyellow‚Äù MUAC (less than 125 mm).\nCalculate the mean days from first symptom onset to consultation by sub-prefecture.\nCalculate the mean time spent in hospital (i.e.¬†days from admission to outcome) by outcome (i.e.¬†in those who recovered and those who died).\n\n\n\nAdditional Resources\n\nThe EpiR Handbook chapter on grouping data\nOnce you have tables, you can extensively customize them for display/publication using {gt} package:\n\nWebsite of gt\nBook about gt"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html",
    "href": "sessions_core/03_data_verbs.html",
    "title": "Data Manipulation, Basics",
    "section": "",
    "text": "Learn basic data verbs from {dplyr} to:\n\nSelect specific columns (select())\nRename columns (rename())\nAdd new columns and change existing ones (mutate())\nRemove duplicate observations\n\nUnderstand the pipe operator |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#objectives",
    "href": "sessions_core/03_data_verbs.html#objectives",
    "title": "Data Manipulation, Basics",
    "section": "",
    "text": "Learn basic data verbs from {dplyr} to:\n\nSelect specific columns (select())\nRename columns (rename())\nAdd new columns and change existing ones (mutate())\nRemove duplicate observations\n\nUnderstand the pipe operator |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#setup",
    "href": "sessions_core/03_data_verbs.html#setup",
    "title": "Data Manipulation, Basics",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio and that you are able to import data. If you need a refresher on either of these topics, we encourage you to review the first two sessions in the learning pathway.\n\nThis session will work with the raw Moissala linelist data, which can be downloaded here:\n\n\n\n  Download Data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called data_verbs_practice.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_raw."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#manipulating-data-with-dplyr",
    "href": "sessions_core/03_data_verbs.html#manipulating-data-with-dplyr",
    "title": "Data Manipulation, Basics",
    "section": "Manipulating Data with {dplyr}",
    "text": "Manipulating Data with {dplyr}\nNow that we know how to set up a project and import data, we can finally start to play around with it. Going forward we will be using several packages from the ‚Äútidyverse‚Äù to help us manipulate, summarize, and visualize our data. Today‚Äôs session will focus on data manipulation using a package called {dplyr}.\n\nWhat is {dplyr}\nData manipulation is the foundation of working with data in R and as such is foundational to the work we do as epidemiologists. In particular, data manipulation skills will be critical when trying to clean our data.\nIn R, the package {dplyr} provides a large number of functions to help us manipulate data frames and perform many of the tasks that we will need to use on a daily basis, for example:\n\nSubsetting our data to remove certain variables\nRenaming certain variables\nAdding or modifying a variable\nRemoving duplicate entries\n\nIn {dplyr} each of these actions can be done with a particular function, which typically have an intuitive verb for a name. For example, renaming columns will use the function rename().\nIn today‚Äôs session we will look at the ‚Äúdata manipulation verb‚Äù, ie the function, needed for each of the above tasks as well as how to chain them all together into an efficient data pipeline.\n\n\n\n\n\n\nNote\n\n\n\nYou may have noticed that we asked you to load a package called {tidyverse} rather than {dplyr} in the setup. Loading {tidyverse} will load several of the most useful packages from the broader tidyverse, including {dplyr} and a couple other packages that we will see later in the session."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#basic-data-verbs",
    "href": "sessions_core/03_data_verbs.html#basic-data-verbs",
    "title": "Data Manipulation, Basics",
    "section": "Basic Data Verbs",
    "text": "Basic Data Verbs\n\nSelecting Specific Columns\nA lot of the time when we receive a dataset it will have extra columns that we don‚Äôt need, either because those columns contain sensitive data or because our analysis will only focus on a subset of the data. This is where a function like select() comes in handy.\nHere is the basic syntax, note that this is pseudo-code and isn‚Äôt something you are intended to run yourself.\n\n# DO NOT RUN (PSEUDO-CODE)\nselect(df_raw, first_column_to_keep, second_column_to_keep)\n\nHere we see that the first argument is our dataset and each subsequent argument is the name of a column that we would like to keep. In the tidyverse, variables (ie column names) don‚Äôt need to be put into quotation marks. So for example, if we want to select the columns id, sex, and age we can use the following:\n\nselect(df_raw, id, sex, age)\n\n\nUse select() to select the following variables in your dataset: id, sex, age, sub_prefecture, date_onset, and outcome. The head of your output should look something like this:\n\n\n  id   sex age date_onset   outcome\n1  1 femme  36 2022-08-13 recovered\n2  2     f   5 2022-08-18      &lt;NA&gt;\n3  3     f 156 2022-08-17 recovered\n4  6 homme   8 2022-08-22 recovered\n5  7     m   7 2022-08-30 recovered\n6 10     m   4 2022-08-30 recovered\n\n\n Take a look at this output and then at df_raw. We can see that df_raw still contains all of the columns, which is what we want. But can you tell why it didn‚Äôt change?\n\nOften, we want to keep most of the variables in our dataset and only remove one or two. We can use the above syntax to do this, but it can become pretty tedious to write out every column name. In these cases, instead of telling select what to **keep**, we can use a subtraction sign (-) to tell it what to **remove**. For example, if we wanted to remove thevillage_commune` column from our dataframe we can use the following:\n\nselect(df_raw, -village_commune)\n\nWay easier!\n\nUse the - syntax in select() to select all of the columns in df_raw except: full_name and age_unit from your dataset.\n\n\n\nRenaming Columns\nAnother common issue when we get new datasets is that the variable names are inconvenient. In those cases, rename() can work wonders. Here‚Äôs the basic syntax:\n\n# DO NOT RUN (PSEUDO CODE)\nrename(df,\n       new_column_name = old_column_name,\n       another_new_name = another_old_name)\n\nAs in the case of select(), and indeed in essentially all {dplyr} verbs, the first argument is our daframe. Then each subsequent argument is a statement of new_column_name = old_column_name telling R which columns to rename and the new names that we want to use, with each pair given its own line to improve readability. If we wanted to change village_commune to simply be village, for example, we can write:\n\nrename(df_raw,\n       village = village_commune)\n\n\nUse rename() on df_raw to change the columns sub_prefecture, village_commune, and health_facility_name to be prefecture, village, and facility respectively.\n\nIn the above exercise it may have been difficult to check if the output looked correct because R would have printed out the full data frame. In these cases it can be helpful to create a temporary object just to check if everything looks alright. You can call this object whatever you want, but a common name is tmp.\n\nRepeat the last exercise but this time assign the output to an object called tmp and use names() to check that the column names changed as you expected. The output of names() should give you something like this:\n\n\n [1] \"id\"                \"full_name\"         \"sex\"              \n [4] \"age\"               \"age_unit\"          \"region\"           \n [7] \"prefecture\"        \"village\"           \"date_onset\"       \n[10] \"date_consultation\" \"hospitalisation\"   \"date_admission\"   \n[13] \"facility\"          \"malaria_rdt\"       \"fever\"            \n[16] \"rash\"              \"cough\"             \"red_eye\"          \n[19] \"pneumonia\"         \"encephalitis\"      \"muac\"             \n[22] \"vacc_status\"       \"vacc_doses\"        \"outcome\"          \n[25] \"date_outcome\"     \n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nTemporary objects, like the tmp data frame you just created are just that: temporary. They are usually used to test if something has worked and designed to be overwritten each time you need to test something else. As such, you should not use these temporary objects as the input for other parts of your code. If you want to make a data frame that will be reused, such as a clean version of df_raw, this should be done using an object with a proper name like df or df_clean.\n\n\n\n\nChanging and Adding Columns\nSo now we know how to select and rename columns, but how do we modify them? This is where mutate() comes into play. This function can be used both to add new columns and to change existing ones.\nLet‚Äôs start with the basic mutate() syntax needed to add a new column:\n\n# DO NOT RUN (PSEUDO-CODE)\nmutate(df,\n       new_column = action(existing_column),\n       another_new_column = another_action(another_existing_column))\n\nIn the above code, we are creating a new column (new_column) by performing some sort of action (action()) on an existing column in the dataframe (existing_column). This action could be anything, it could use a function or be a simple arithmetic operation and can use one or more columns. For example, if we wanted to create a new column expressing MUAC in cm we could use the following:\n\nmutate(df_raw,\n       muac_cm = muac / 100)\n\n\nUse mutate() to create a new column called age_years that expresses age in years rather than months. The head of your new age_years column should look like this:\n\n\n   age_years\n1  3.0000000\n2  0.4166667\n3 13.0000000\n4  0.6666667\n5  0.5833333\n6  0.3333333\n\n\n\nGreat! But what if instead of creating a new column we instead wanted to change an existing one? You just need to use the existing column name on the left side of the = instead of giving a new column name. For example, in the above MUAC code we would write:\n\nmutate(df_raw,\n       muac = muac / 100)\n\nWe might want to keep age in months as well as years, so we won‚Äôt reassign that column. But there are some other columns that could stand to be changed. There are a lot of reasons we might want to change a column, two of the most common ones are:\n\nThe format of a string needs changing\nThe data type of a column is incorrect\n\nOur dataset has both of these problems. For example, while it isn‚Äôt per se a problem that region and sub_prefecture are in all capitals, it also isn‚Äôt particularly nice. To fix this, we can use another function from the {tidyverse}, this time from a package called {stringr} to make these columns title case:\n\nmutate(df_raw,\n       region = str_to_title(region),\n       sub_prefecture = str_to_title(sub_prefecture))\n\n\nUse mutate() to update the format of malaria_rdt and outcome to use title case. The head of these two columns should now look something like this:\n\n\n  malaria_rdt   outcome\n1    Negative Recovered\n2    Negative      &lt;NA&gt;\n3    Negative Recovered\n4    Negative Recovered\n5    Negative Recovered\n6    Negative Recovered\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that we didn‚Äôt need to load {stringr} to do the above exercise. That‚Äôs because, like {dplyr} this package is loaded when we load the {tidyverse}.\n\n\nThat‚Äôs nicer. Now let‚Äôs consider the second issue, having variables with the wrong type.\n\nTake a look at the data type of your columns, do any of them look strange?  Hint. str() may be useful here.\n\nMost of the columns look ok, but it seems theres something strange with the dates. Some of them are character type and others are something called POSIXct. We would much rather have all of these columns use the simple Date type.\nTo convert to dates, we are going to call on yet another package from the the tidyverse, {lubridate}. In particular, we are going to use the function ymd(). For example:\n\nmutate(df_raw,\n       date_outcome = ymd(date_outcome))\n\n\nUse mutate() and ymd() to modify date_onset and date_admission to be Date type. Use a temporary data frame tmp to check that your code is doing what you want it to.\n\n\n\nRemoving Duplicates\nOk great! We know how to select, rename, and modify our data. Another task we will often need to do is removing duplicate entries. Fortunately this one is easily done using the function distinct(), which has the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\ndistinct(df)\n\nNotice that distinct only needs one argument by default, the dataset itself. This will look for and remove any duplicate observations in the data frame. There are some fancier ways of using distinct() that will look for duplication on certain variables only, but that‚Äôs outside of the scope of today‚Äôs session.\n\nUse distinct() to create a temporary data frame, tmp, that contains all the unique observations in df_raw. Compare the number of rows in tmp to that of df_raw. Did we have any duplicates?"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#the-pipe-operator",
    "href": "sessions_core/03_data_verbs.html#the-pipe-operator",
    "title": "Data Manipulation, Basics",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\nSo it looks like we have actually done quite a bit of cleaning while learning the core {dplyr} verbs. We should probably try to put some of the above steps together to start building a basic data cleaning pipeline. So far we haven‚Äôt been saving any of our changes, except perhaps to a temporary data frame. It would be nice to keep them in a new clean df object.\nFor example, if we want to effect the column renaming we did above to a reusable object we might write something like this:\n\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n\n\n\n\n\n\nTip\n\n\n\nIn general, it‚Äôs good practice to keep a raw version of your dataset, here df_raw, that remains unmodified in your code. This is so that you always have it available in your environment as a reference and is always available at the start of your cleaning pipeline to improve reproducibility.\n\n\nNow we have a new object, df that we can do more operations on. Brilliant. For example, if we now wanted to select everything except for full_name we could update the above code like this:\n\n# Step 1: Rename Variables\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n# Step 2: Select Variables to Keep\ndf &lt;- select(df,\n             -full_name)\n\nNotice that in this second step we are using df as the input of select() rather than df_raw because we want to continue working on our modified version of the data. Let‚Äôs say now we want to add a column of age in years:\n\n# Step 1: Rename Variables\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n# Step 2: Select Variables to Keep\ndf &lt;- select(df,\n             -full_name)\n\n# Step 3: Add Age in Years\ndf &lt;- mutate(df,\n             age_years = age / 12)\n\nHm, ok well this is working but it is starting to get repetitive. With each step we are reusing the output of the last step and then updating the same data frame, df. It would be better if these actions could be chained together in a simpler way.\nThis is exactly what the pipe operator, |&gt; is for! The pipe has the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\ninput |&gt; action()\n\nHere the input on the left side (input) is ‚Äúpiped into‚Äù the action on the right side (action()). So for example instead of writing:\n\nselect(df_raw, id, sex)\n\nWe could instead write:\n\ndf_raw |&gt;\n  select(id, sex)\n\n\nTry out the above code to see if it works.\n\nThis can be used to chain multiple actions together and you will often see tidyverse style code that uses pipes in the following way:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf &lt;- df_raw |&gt;\n  first_action() |&gt;\n  second_action() |&gt;\n  third_action()\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that here each action in the pipe is given its own line. This is considered good practice as it makes your code easier to read and understand.\n\n\nSo, if we wanted to chain the example actions we saw above into a single pipe, we might write something like this:\n\ndf &lt;- df_raw |&gt;\n  rename(prefecture = sub_prefecture,\n         village = village_commune,\n         facility = health_facility_name) |&gt;\n  select(-full_name) |&gt;\n  mutate(age_years = age / 12)\n\nThat‚Äôs a lot easier than reassigning df after each step!\n\nLet‚Äôs see if we can put together what we learned above into a single pipeline! Use the pipe operator |&gt;, select(), rename(), mutate(), str_to_title(), ymd(), and distinct() to perform the following actions on df_raw and assign the output to a new data frame called df:\n\nRemove the variables full_name and age_unit\nRename the following variables:\n\nage becomes age_months\nsub_prefecture becomes prefecture\nvillage_commune becomes village\nhealth_facility_name becomes facility\n\nAdd a variable age_years with patient age in years\nUpdate region and prefecture to use title case\nUpdate all date columns to use Date type\nRemove any duplicate observations\n\nThe head of your final data should look something like this:\n\n\n  id   sex age_months  region prefecture        village date_onset\n1  1 femme         36 Mandoul   Moissala Sangana Ko√Øtan 2022-08-13\n2  2     f          5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3     f        156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6 homme          8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7     m          7 Mandoul   Moissala      T√©tindaya 2022-08-30\n6 10     m          4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             yes     2022-08-14\n2        2022-08-25             yes     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25              no           &lt;NA&gt;\n5        2022-09-02              no           &lt;NA&gt;\n6        2022-09-02             yes     2022-09-02\n                         facility malaria_rdt fever rash cough red_eye\n1 H√¥pital du District de Moissala    negative    No &lt;NA&gt;   Yes      No\n2 H√¥pital du District de Moissala    negative    No   No   Yes      No\n3                      CS Silambi    negative   Yes &lt;NA&gt;    No      No\n4 H√¥pital du District de Moissala    negative    No   No    No    &lt;NA&gt;\n5                      CS Silambi    negative  &lt;NA&gt;   No   Yes     Yes\n6                    Moissala Est    negative   Yes   No    No    &lt;NA&gt;\n  pneumonia encephalitis muac vacc_status vacc_doses   outcome date_outcome\n1        No           No  244        &lt;NA&gt;       &lt;NA&gt; recovered   2022-08-18\n2      &lt;NA&gt;           No  232          No       &lt;NA&gt;      &lt;NA&gt;   2022-08-28\n3        No         &lt;NA&gt;  123  Yes - oral       &lt;NA&gt; recovered         &lt;NA&gt;\n4        No           No  210          No       &lt;NA&gt; recovered         &lt;NA&gt;\n5        No           No   80          No       &lt;NA&gt; recovered         &lt;NA&gt;\n6        No           No  220          No       &lt;NA&gt; recovered   2022-09-03\n   age_years\n1  3.0000000\n2  0.4166667\n3 13.0000000\n4  0.6666667\n5  0.5833333\n6  0.3333333\n\n\nHint. Be careful with your column names here! If you renamed something you will need to use the new names for any subsequent parts of the pipe.\n\nAmazing! That looks like a great start at a data cleaning pipeline. Keep this code handy, you will use it in the next session where we will look at another common part of data cleaning: recoding."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#done",
    "href": "sessions_core/03_data_verbs.html#done",
    "title": "Data Manipulation, Basics",
    "section": "Done!",
    "text": "Done!\nWell done, you‚Äôve learned the fundamentals of data manipulation and how to string multiple commands together into a data manipulation pipe. Moving forward, solution files will focus less on being ‚Äúexercise by exercise‚Äù and rather provide an example of what a real script might look like in a real world context. In this case, the solutions will then focus only on the final pipe that is created at the end of the session.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#going-further",
    "href": "sessions_core/03_data_verbs.html#going-further",
    "title": "Data Manipulation, Basics",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nA a line to your mutate() to update the hospitalisation variable so that its text would be in title case as well.\nPerhaps you would prefer to use lower case for the region column rather than the title case, update your code to do this instead. Hint: you might want to check out str_to_lower() from {stringr}.\nCreate a delay_consultation column, that contains the number of days between the onset of symptoms and the consultation."
  },
  {
    "objectID": "sessions_core/01_introduction.html",
    "href": "sessions_core/01_introduction.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Familiarize yourself with RStudio\nLearn how to work with the console\nCreate and execute a script\nCreate basic R objects, including vectors and data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.html#objectives",
    "href": "sessions_core/01_introduction.html#objectives",
    "title": "Introduction to R",
    "section": "",
    "text": "Familiarize yourself with RStudio\nLearn how to work with the console\nCreate and execute a script\nCreate basic R objects, including vectors and data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.html#exercise-format",
    "href": "sessions_core/01_introduction.html#exercise-format",
    "title": "Introduction to R",
    "section": "Exercise Format",
    "text": "Exercise Format\nThese exercises are in the format of a self-paced tutorial containing short explanations of key concepts, examples, and exercises for you to follow. The course uses a ‚Äúlearning by doing‚Äù approach, and while this first session will start with a lot of time exploring the RStudio interface, future sessions will focus heavily on having you write your own code.\nInstructions for exercises will be given in the following formats:\n\nThis is a general action block. You will typically see it at the beginning of a session with instructions about the setup for that lesson.\n Example: Open a blank new script and name it my_first_script.R.\n\n\nThis is a code block, it indicates a coding exercise where you will actually write your own code.\n Example: Create an object called region that contains the value \"Mandoul\".\n\n\nThis is an observation block, it will have instructions about something that you are expected to look at or investigate.\n Example: Inspect the RStudio interface.\n\nAs you move through these exercises, you may run into some errors, which occur when R is unable to complete a command. This can happen for many reasons: maybe you misspelled the name of an object, asked R to look for a file that doesn‚Äôt exist, or provided the wrong type of data to a function. Whenever an error occurs, R will stop any ongoing calculation and give you a message explaining what went wrong. Having errors is completely normal and happens to all programmers, novice and expert. Much like a natural language, R is something you will get better at the more you practice and work through your mistakes."
  },
  {
    "objectID": "sessions_core/01_introduction.html#rstudio-and-r",
    "href": "sessions_core/01_introduction.html#rstudio-and-r",
    "title": "Introduction to R",
    "section": "RStudio and R",
    "text": "RStudio and R\nR is a functional programming language that can be used to clean and manipulate data, run analyses (especially statistical ones), visualize results, and much more.\nRStudio is a piece of software that provides a user-friendly interface for R (also called an IDE, for Integrated Development Environment). While using a graphical interface isn‚Äôt required, it is strongly recommended for beginners.\n\nGetting Started with RStudio\nLet‚Äôs get started!\n\nOpen RStudio using the start menu or desktop shortcut; if RStudio is already open, please close it and open it again.\n\nYou should see an interface that looks something like this:\n\n\n\nView of the Rstudio IDE interface at opening\n\n\n\nInspect the RStudio interface.\n\nYou will have either three or four panels, including:\n\nUpper Right Corner\nTo the upper right there will be a panel with several tabs. Many of these are beyond the scope of this course, but we will use the following two tabs during the course:\n\nEnvironment. A list of the objects saved by the user in the current session. Because you‚Äôve just started a new session, your environment should be empty.\nHistory. A record of all the commands you have executed during the current session.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can think of an R session like you would think of starting up a computer. Whenever a session starts, everything is blank and ready for computation in the same way that there aren‚Äôt any programs open when you first turn on your computer. In general, we encourage you to stop and start your R sessions regularly, you may just find that turning it off an on again will fix some of your bugs.\n\n\n\n\nBottom Right Corner\nTo the bottom right there will be another multi tab panel, including:\n\nFiles. A file explorer for the working directory, which is the folder location where R is currently working.\nPlots. A location where RStudio will display static visualizations; this tab should be empty for the moment.\nPackages. A list of all the R packages installed on your computer. Packages are collections of functions that help extend the functionality of R, and we will discuss them in greater detail in the next lesson.\nHelp. A place to read help pages and documentation for functions and packages.\nViewer. A location where RStudio will display html outputs such as tables, interactive widgets, or even full on dashboards.\n\n\n\nLeft Side\n\nTo the left (or bottom left if you have four panels) you should see the console, where R itself is run.\nTo the top left (if you have four panels) will be any open scripts.\n\nIn the next two sections, let‚Äôs talk about the console and scripts in more detail.\n\n\n\nThe Console\nThe console is where R itself is run.\nWhenever you open a new session, R will start by printing a bit of information about your set up, such as your R version number. Below this there should be a line containing the &gt; symbol and a blinking cursor. To run a command in R, you simply need to type it in after this &gt; and press Enter. R will then process your code and print the result (if there is one). A new &gt; line will then appear ready for the next command.\n\n\n\n\n\n\nImportant\n\n\n\nIf the last line shown in the console starts with a + instead of a &gt; that means the console is not ready for a new command either because it is still processing a previous one or because it received a bit of incomplete code. If at any point you would like to cancel an ongoing or incomplete command, press Esc.\n\n\n\nRun the following commands in the console one line at a time and observe the output.\n\n5 + 90\n\n6 * 171\n\n189 / 36.6\n\n92^3\n\n(12 + 9)^4 / 1000\n\nNow, run the following command. Note that the final ) is missing, making the command incomplete. What happens when you do this?\n\n3 / (2 + 97\n\n\nYou may have noticed in the above examples that our code includes a lot of spaces between characters. This is not by accident. It is considered best practice to include spaces around most operators, such as +, -, *, /, &lt;, &gt;, =, and &lt;-. Not only do these spaces make your code easier for other people to read and understand, in some (rare) cases they may even be necessary to avoid errors. That said, do be aware that there are a small number of operators that should not be surrounded by spaces, such as ^, . and :.\n\n1+29+4.8/3*3           # BAD\n1 + 29 + 4.8 / 3 * 3   # GOOD\n\n1 ^ 2 # BAD\n1^2   # GOOD\n\nWe can also run functions in the console. We will discuss functions in more depth later in this lesson, but meanwhile know that the idea of functions in R is very similar to the one in Excel, where you no doubt are familiar with functions such as SUM or MEAN.\n\nRun the following commands in the console (one line at a time).\n\n# Find the minimum value\nmin(5, 10)\nmin(1, 8, 56, 0.3)\n\n# Find the maximum value\nmax(568, 258, 314)\n\n\n\n\nScripts\nScripts are text files that contain a series of commands for a particular programming language. The extension of the file indicates which language the commands were written in, and we will be using .R. Scripts allow us to create code that can be reused, shared, and even automated.\n\nWriting Your First Script\n\n\n\nSteps to create a new script in the RStudio IDE\n\n\nTo create a new script, follow the menu File &gt; New File &gt; R Script. Alternatively, you can click on the small green + sign just below the File menu or use the keyboard shortcut CTRL+SHIFT+N. This new and unsaved script will appear as a blank document in the top left panel.\nTo save your script, either use the menu File &gt; Save As or the keyboard shortcut CTRL+S.\n\nCreate and save a new script called discovery.R. Don‚Äôt forget to include the .R extension. For now, you can save it on your Desktop or any convenient location, but we will talk more about organizing your scripts in the next session.\n\n\n\nExecuting Code from a Script\nTo run code from a script simply place your cursor on the line you wish to run (or select multiple lines) and do one of the following:\n\nClick the Run icon at the top right of the script panel\nUse the shortcut CTRL+Enter (cursor will move to the next line afterwards)\nUse the shortcut ALT+Enter (cursor will stay on the current line afterwards)\n\n\nCopy the code you ran in the previous exercises into your script and run it using each of the above methods.\nFrom now on, you will write your code in your script and execute it from there, unless told otherwise in the instructions.\n\n\n\nComments\nIn R, any text prefaced by a # (until the end of a line) is called a comment. R does not consider comments to be code and will ignore them whenever you run your scripts. This makes comments an excellent way to document your code.\n\n# This is a comment\n\n2 + 3  # This is also a comment\n\nIt is helpful to future you and others to start your scripts with a few commented lines providing some information about the file.\n\n#### IMPORT & PREPARE DATA ####\n# Author :  Mathilde Mousset\n# Creation Date : 23/11/2024\n# Last Update : 30/11/2024\n# Description : Import and clean measles surveillance data from Moissala\n\n\nAdd some comments to the top of your script describing it.\n\nComments are also a handy way to split longer scripts into thematic sections, such as ‚ÄúData Importation‚Äù, ‚ÄúAnalysis‚Äù, ‚ÄúVisualization‚Äù, etc. For example:\n\n# NAME OF SECTION 1 -----------------------------------------------             \n\n# NAME OF SECTION 2 -----------------------------------------------             \n\n\nUse comments to create sections in your script that correspond to the main sections in this tutorial.\n\nFinally, comments allow us write helpful notes for our colleagues (and our future selves) that can help them understand the code and why we wrote it the way we did. The general guidance is to focus on comments that explain the ‚Äúwhy‚Äù rather than the ‚Äúwhat‚Äù. This is because the ‚Äúwhat‚Äù of well written code should be relatively self explanatory.\nThis comment, for example, is completely superfluous:\n\n1 + 3  # Code to add one to three\n\nBy comparison, here are a few use cases that would warrant comments:\n\nYou define a constant, say a seroprevalence threshold value. You may want to add a comment providing the reference for where the value comes from.\nYour code contains a value or file name that needs to be updated every week. You should indicate this with a comment to ensure that anyone else using the code is aware.\nYou use a rare command or package that your colleague may not know or may find counter intuitive. You can use a comment to explain the rational behind that decision.\n\nThat being said, you are learning, and the scripts you are writing during this course are your notes, so feel free to us as many comments (of the ‚Äúwhat‚Äù and ‚Äúwhy‚Äù sort) as you need. You will naturally write less comments in the future, when some of the things that seem alien now become natural.\n\n\n\n\n\n\nTip\n\n\n\nYou can comment a selected line with the shortcut CTRL+SHIFT+C.\nYou can add a first level section with CTRL+SHIFT+R.\n\n\n\nAdd some comments to describe the code that you‚Äôve written thus far in your script."
  },
  {
    "objectID": "sessions_core/01_introduction.html#data-types",
    "href": "sessions_core/01_introduction.html#data-types",
    "title": "Introduction to R",
    "section": "Data Types",
    "text": "Data Types\nR has several different data types. The ones we will see most often in this course include:\n\nnumeric\nstring (text)\nboolean (TRUE / FALSE)\ndate\nfactor\n\n\nNumerics\nThe numeric type includes both integers and doubles (numbers that include a decimal) and can be created by simply writing the ‚Äúnaked‚Äù value into your script or console.\n\n\nStrings\nStrings are the R version of text and can be created by surrounding text with single or double quotation marks, for example \"district\" or 'cases' (double quotations are typically considered best practice).\n\nCompare the output in the console for the following commands:\n\n28         # numeric\n\"28\"       # text\n28 + \"28\"  # produces an error\n\n\nThe last command above will give an error because we cannot perform arithmetic operations that combine text and numbers.\n\n\n\n\n\n\nImportant\n\n\n\nR is case sensitive, meaning that the string \"ABC\" is not the same as \"abc\".\n\n\n\nIf you would like to create a string that contains a quotation mark the best practice is to escape the character by putting a \\ in front of it, ie: \"She said \\\"Hello\\\" then left\" or 'it\\'s a beautiful day'. Equivalently, if you used a double quotation to create the string you can use single quotes inside of it freely (ie: \"it's a beautiful day\") and vice versa (i.e.: 'She said \"Hello\" then left').\n\n\n\nBoolean (Logical)\nThe boolean (or ‚Äúlogical‚Äù) type stores true/false values and is created by writing either TRUE or FALSE without quotation marks.\nInternally, R thinks of TRUE and FALSE as being a special version of 1 and 0 respectively, and boolean values can be easily translated to these numeric equivalents for arithmetic operations.\n\n\n\n\n\n\nNote\n\n\n\nYou may find people using T or F but this is discouraged as T and F can also be used as object or variable names. TRUE and FALSE, however, are protected in R, meaning they cannot be reassigned to another value.\n\n\n\n\nDetermining the Type of an Object\nThere are several functions to determine the type of an object (often called the class of the object in R).\n\nType the following commands in your script and run them:\n\n# Get the Type of an Object\nclass(28)  \nclass(\"Mandoul\")\n\n# Test the Type of an Object\nis.numeric(28)\nis.numeric(\"Mandoul\")\nis.character(\"Mandoul\")\n\nis.numeric(TRUE)\nis.character(TRUE)\nis.logical(FALSE)"
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-assignement-operator",
    "href": "sessions_core/01_introduction.html#sec-assignement-operator",
    "title": "Introduction to R",
    "section": "Creating an Object",
    "text": "Creating an Object\nIn R, pretty much everything is an object, including functions, scalar values, and other more complex data structures. Before introducing these structures, let‚Äôs take an important detour to discuss how objects are saved into your environment.\nOften, we will want to reuse the same values or data throughout a script and it is therefore very useful to store them as objects in our environment. To do this we use the assignment operator, &lt;-.\n\nLook at the environment panel on the top right, verifying that it is empty, then type the following command in your script and run it to save a variable called cases into your environment.\n\ncases &lt;- 28\n\nLook at the environment again. Is it still empty?\n\nIf you‚Äôd like to access the value of your new object, cases, you simply need to execute its name.\n\ncases\n\n[1] 28\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reason we need to wrap strings in quotation marks is actually to allow R to differentiate between strings (\"cases\" and object names cases).\n\n\nOnce created, objects can be used in other commands:\n\ncases + 5\n\n[1] 33\n\n\n\nFrom your script, create an object called region that contains the value \"Mandoul\". Do you see it in your environment?\n\n\n\n\n\n\n\nTip\n\n\n\nDon‚Äôt forget that we should always surround &lt;- with spaces to improve readability and avoid errors.\n\nx&lt;-3     # BAD\nx &lt;- 3   # GOOD\n\n\n\n\nUpdating an Object\nWe often want to update the value stored in an object. To do this, we simply assign a new value with the same syntax we used to create it in the first place:\n\ncases &lt;- 32\n\n\nUpdate the value of region to \"Moyen Chari\".\n\n\n\nObject Names\nWhen naming your objects, there are a few (relatively) hard rules:\n\nDon‚Äôt start with a number\nDon‚Äôt use spaces (use a _ instead)\nDon‚Äôt use protected values (like TRUE and FALSE) or function names (like mean)\nDon‚Äôt use capital letters\n\nBeyond these hard rules, there are also more subjective best practices and personal styles. In general aim for names that are short and descriptive:\n\na &lt;- 19                             # BAD (not informative)\nage_du_patient_a_l_admission &lt;- 19  # BAD (too long)\nage &lt;- 19                           # GOOD\n\nGiving your objects clear and informative names helps to make your code readable, making it easy for others to understand without the need for checking the data dictionary every two seconds."
  },
  {
    "objectID": "sessions_core/01_introduction.html#data-structures",
    "href": "sessions_core/01_introduction.html#data-structures",
    "title": "Introduction to R",
    "section": "Data Structures",
    "text": "Data Structures\nUp until now we have looked only at simple objects that store single values, let‚Äôs now turn our focus to more complex structures that can store entire datasets.\n\nVectors\nWe can collect multiple values (such as numerics or strings) into a single object, called a vector.\nTechnically, there are several types of vectors, for example:\n\nSimple vectors (or atomic vectors) can only contain one type of values. For example, a numeric vector 2, 4, 6 or a string vector \"Mandoul\", \"Moyen Chari\".\nRecursive vectors (usually called lists) are far more complex and can contain multiple dimensions and types of data. We will not learn about them in this lesson.\n\nThis course will not go into detail on the more abstract concepts behind these structures and instead focus only on those you will encounter most often in your daily work.\n\nSimple Vectors\nSimple vectors can contain one or more values of a single data type, they thus have two key properties: length and type. For the purpose of this class, we will use the terms ‚Äúsimple vector‚Äù and ‚Äúvector‚Äù interchangeably (as is typical in the R community).\nYou‚Äôve technically already created your first simple vector when you built cases and region. These were simply vectors with a length of one. To create a vector with more than one value, we will use the function c() (mnemonic):\n\ncases &lt;- c(2, 5, 8, 0, 4)\n\n\nUpdate cases with the above values and update region to create a string vector containing the values: Mandoul, Moyen-Chari, Logone Oriental, Tibesti, and Logone Occidental.\n\nWe can now use functions on the objects we have created:\n\nmean(cases)      # calculate the mean value of the cases vector\n\n[1] 3.8\n\ntoupper(region)  # convert all the values in region to upper case\n\n[1] \"MANDOUL\"           \"MOYEN-CHARI\"       \"LOGONE ORIENTAL\"  \n[4] \"TIBESTI\"           \"LOGONE OCCIDENTAL\"\n\n\n\nLet‚Äôs use some functions! Try to write code that does the following:\n\nCalculate the sum of cases using the function sum()\nConvert the text in region to lowercase using the function tolower()\n\n\n\n\n\nAccessing the Values of a Vector\nIt is possible to access the value of a vector using square brackets containing the index (position) of the desired value, ie: [3] or [189].\n\ncases[2]   # 2nd value of cases\n\n[1] 5\n\ncases[10]  # 10th value of cases\n\n[1] NA\n\n\nOoops it does not exist! We will come back to what this NA means in the Missing Values section.\nWe can also access a range of values, just as we might do in Excel. To create a range we use the : operator to separate the desired minimum and maximum index:\n\ncases[2:4]  # 2nd to 4th values of cases\n\n[1] 5 8 0\n\n\n\nGet the 3rd value of region.\nWrite code to access the values ‚ÄúMandoul‚Äù and ‚ÄúMoyen-Chari‚Äù in the vector region.\n\n\n\nData frames\nData frames are tabular structures / 2D tables with rows and columns. It is very similar to a ‚Äútable‚Äù structure in Excel. As epidemiologists, this type of data structure is perhaps the most useful and you will likely use them on a daily basis, to store linelist data for example.\n\nCreating a data frame\nWe can create a data frame using the function data.frame():\n\ndata.frame(col1 = c(1, 4, 2, 9),\n           col2 = c(\"a bit of text\", \"some more text\", \"hello\", \"epidemiologists!\"))\n\n  col1             col2\n1    1    a bit of text\n2    4   some more text\n3    2            hello\n4    9 epidemiologists!\n\n\nSee how col1 was created from a numeric vector, and col2 from a vector of strings. Here we chose the names of the columns (col1 and col2), which is the normal way, but you can run the code without to see how R handles names by default.\n\nIn your script, create a data frame called data_cases that contains cases in one column and region in the other.\n\n\n\nExploring a data frame\ndata_cases should now appear in your environment. You can click on the blue circle with a white triangle in to see some additional information, or click on its name to open the object in the same pane as the scripts to view it.\n\n\n\nThe data_case data frame now appears in the Environment pane\n\n\nThere are several handy functions we can use to explore a data frame:\n\nRun the following commands and try to determine what type of information they are returning.\n\nstr(data_cases)     # STRucture of the object\ndim(data_cases)     # DIMension of the object\nnrow(data_cases)    # Number of ROWs\nncol(data_cases)    # Number of COLumns\nnames(data_cases)   # column NAMES\n\n\nLet‚Äôs practice a bit more! R comes with several built in data sets that can be accessed directly, including one called iris. It is convenient today as we have not learned to import data in R yet (don‚Äôt worry, we will work on linelist data from the second session then onwards).\nWe can see the first few lines of this data frame using the function head():\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nHow many rows and columns are there in iris? What are the names of its columns?\n\n\n\nAccessing Data in a data frame\nIn R, there are several methods for accessing the rows and/or columns of a data frame. In this introductory session we will focus on the [ ] syntax.\nWe use square brackets to access single values or ranges within our data frame. To do this we must give R both a row number (or range of rows) and column number/name (or range of columns), using the syntax [row, column].\n\ndata_cases[1, 2]          # the value of row one, column 2\n\n[1] \"Mandoul\"\n\ndata_cases[1, \"region\"]   # first value in the region column\n\n[1] \"Mandoul\"\n\n\nIf we want to access all of the rows (or columns) we can simple leave a space in the place of the number/name:\n\ndata_cases[1, ]           # values of all columns in row one\n\n  cases  region\n1     2 Mandoul\n\ndata_cases[2:4, ]         # values of all columns for rows 2 through 4\n\n  cases         region\n2     5       Sud Kivu\n3     8 Kasai oriental\n4     0          Kasai\n\ndata_cases[ , \"region\"]   # values of all rows for the region column\n\n[1] \"Mandoul\"        \"Sud Kivu\"       \"Kasai oriental\" \"Kasai\"         \n[5] \"Haut Katanga\"  \n\n\nWe can even select multiple non-consecutive indices by using a numeric vector:\n\ndata_cases[c(1, 3), ]  # lines 1 and 3 (all columns)\n\n  cases         region\n1     2        Mandoul\n3     8 Kasai oriental\n\n\nDo be careful, as the type of output returned when extracting data from a data frame can sometimes depend on the style of indexing used:\n\nstr(data_cases[1 , ])   # returns a data frame\n\n'data.frame':   1 obs. of  2 variables:\n $ cases : num 2\n $ region: chr \"Mandoul\"\n\nstr(data_cases[ , 1])   # returns a simple vector\n\n num [1:5] 2 5 8 0 4\n\n\nAnother syntaxt to extract the various columns of a data frame:\n\ndata_cases[2]           # returns the second column (as a data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\ndata_cases[\"region\"]    # returns the region column (as a data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\n\nNotice that these commands returned single-column data frames.\n\nWrite some code to:\n\nextract the third value in the region column of your data frame\n\nextract the second and third values of the cases column\n\ncalculate the sum of the cases column of your data frame"
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-missing-values",
    "href": "sessions_core/01_introduction.html#sec-missing-values",
    "title": "Introduction to R",
    "section": "Missing Values",
    "text": "Missing Values\nAs epidemiologists, we work with missing data all the time. In R, missing values are coded using a special value: NA (meaning Not Available). NA is somewhat unique in R as it doesn‚Äôt per se have a fixed type, rather, it will take on the type of the values around it. For example, an NA in a numeric column will then take on the numeric type. We will discuss the idea of missing data in more depth in later sessions of the course."
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-functions",
    "href": "sessions_core/01_introduction.html#sec-functions",
    "title": "Introduction to R",
    "section": "Functions",
    "text": "Functions\nFunctions are objects that contain commands (instead of values) that are run whenever the function is called. You are without doubt familiar with functions in Excel such as SUM or MEAN and the idea of functions in R is exactly the same.\nMost functions require some sort of input, such as a dataset or parameter. These inputs are called arguments and are normally named. For example, when we ran sum(cases), we provided the vector cases as the first (and only) argument to the function sum().\nOften, a function will have a combination of both required and optional arguments. The first argument of a function is almost always required and is typically a dataset. As an obligatory and rather obvious argument, most people omit its name when calling a function; ie: i.e.¬†people will write mean(cases) instead of mean(x = cases). Optional arguments on the other hand are usually added using their name, i.e.: mean(x = cases, na.rm = TRUE).\nOptional arguments typically have default values and we only include them when we want to change their defaults (and thus change the default behavior of the function). For example, the na.rm argument of mean() determines whether R will ignore missing values when calculating a mean. The default state of the na.rm argument is FALSE, so by default, the mean performed on data with missing values will always return NA as the result:\n\nmean(c(1, 3, NA))\n\n[1] NA\n\n\nThis is true for many arithmetic operations in R. If we want R to calculate the mean on whatever data is available (and ignore the missing values) we need to explicitly set na.rm = TRUE:\n\nmean(c(1, 3, NA), na.rm = TRUE)\n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that arguments are separated by commas. These commas should always be followed by a space and whenever a named argument is used the = should be surrounded by spaces:\n\nmean(cases,na.rm=TRUE)     # BAD\nmean(cases, na.rm = TRUE)  # GOOD\n\nAs you work with increasingly complex functions, you may start to have a lot of arguments. For readability, it is typically recommended to split each argument onto its own line:\n\nmean(cases, \n     na.rm = TRUE) \n\n\n\nWhat happens if we put the arguments in the wrong order? If you provided the name of the arguments in you command, the function will still work exactly as expected. That being said, doing this would make your code harder to read and we encourage you to stick with a standard order of putting obligatory arguments like data first.\n\n# technically functional but hard to read:\nmean(na.rm = TRUE,  \n     x = cases) \n\n# better:\nmean(cases,         \n     na.rm = TRUE)\n\nOf course, if you mess up the ordering of arguments and didn‚Äôt include their names your code will not work as expected, or even throw an error:\n\nmean(TRUE, cases)   # not what you expect"
  },
  {
    "objectID": "sessions_core/01_introduction.html#done",
    "href": "sessions_core/01_introduction.html#done",
    "title": "Introduction to R",
    "section": "Done!",
    "text": "Done!\nThat‚Äôs all for this session, congratulations on taking your first steps with R and RStudio!\n\n\n\n Solutions file"
  },
  {
    "objectID": "pathway.html",
    "href": "pathway.html",
    "title": "Pathway",
    "section": "",
    "text": "These sessions can be followed in order to get a baseline level in R. The series assumes no prior experience in R and is suitable for beginners.\nLooking for more? Want more flexibility? Consider browsing the full session catalog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore",
    "section": "",
    "text": "Choose your own adventure by browsing all available sessions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\nCore\n\n\nVisualization\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Exploration\n\n\n\nSatellite\n\n\nData Exploration\n\n\n\nExplore your data after importation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\nCore\n\n\nRStudio\n\n\nData Import\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\nLogic\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceting\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nCreate a plot with multiple subplots (facets)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\nCore\n\n\nR Basics\n\n\nData Types\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\nCore\n\n\nSummary Tables\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurveillance\n\n\n\nSatellite\n\n\nSurveillance\n\n\n\nCompanion satellite to the surveillance Fetch-R module\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeekly Epicurves\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nPlot weekly epicurves and improve date labels on the x-axis\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#hey-there",
    "href": "about.html#hey-there",
    "title": "About",
    "section": "Hey There",
    "text": "Hey There\nWelcome to {repicentre}, an open source site developed by Epicentre to support folks learning R for humanitarian contexts. The site is composed of self paced tutorials and has two main options for learning:\n\nLinear. Designed for people with zero prior experience in R, the linear course will walk you through core R concepts using a case study about measles in Chad. The course covers the following concepts:\n\nData Structures and the RStudio Interface\nData Importation\nData Manipulation\nData Cleaning\nData Aggregation\nData Visualization\n\nChoose Your Own Adventure. If you have a bit more experience or if you are looking for a particular subject, feel free to explore the full range of tutorials. Tutorials are tagged with categories and designed to be self contained."
  },
  {
    "objectID": "about.html#recommendations-and-requests",
    "href": "about.html#recommendations-and-requests",
    "title": "About",
    "section": "Recommendations and Requests",
    "text": "Recommendations and Requests\nIs there a topic that you would like to see a tutorial on that isn‚Äôt currently available? Great! Feel free to let us know by opening an issue on the GitHub repository associated with this website. If you aren‚Äôt familiar with how to open an issue, please get in touch with Cat Eisenhauer instead."
  },
  {
    "objectID": "about.html#contributing",
    "href": "about.html#contributing",
    "title": "About",
    "section": "Contributing",
    "text": "Contributing\nWould you like to help write or maintain some tutorials? Increadible! Please get in touch with Cat."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "{repicentre}",
    "section": "",
    "text": "Welcome to {repicentre}\nAn open source platform to learn R for humanitarian contexts. What would you like to do?\n\n\n\n\n\nLearn Follow a linear path starting with the basics  Start\n\n\n\n\n\nExplore Browse our full catelogue of self paced tutorisals  Start\n\n\n\n\n\nExpand Go even further with a list of external resouces  Start"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "This page will (eventually) contain external resources to continue your R learning journey."
  },
  {
    "objectID": "sessions_core/02_import_data.html",
    "href": "sessions_core/02_import_data.html",
    "title": "Data Importation",
    "section": "",
    "text": "Create a RStudio Project\nSet up an organized and well documented code\nInstall and load packages\nWrite robust file paths\n\nImport and inspect data\n\n\n\n\n\n\n\nImportant\n\n\n\nThe principles you learned in the Introduction to R session will apply here as well: we should do our best to ensure that our projects won‚Äôt just work today but can also be reused and shared in the future. While doing this is not always easy, there are several best practices that can help us, and one of the most important is to start with a good, organized code base."
  },
  {
    "objectID": "sessions_core/02_import_data.html#objectives",
    "href": "sessions_core/02_import_data.html#objectives",
    "title": "Data Importation",
    "section": "",
    "text": "Create a RStudio Project\nSet up an organized and well documented code\nInstall and load packages\nWrite robust file paths\n\nImport and inspect data\n\n\n\n\n\n\n\nImportant\n\n\n\nThe principles you learned in the Introduction to R session will apply here as well: we should do our best to ensure that our projects won‚Äôt just work today but can also be reused and shared in the future. While doing this is not always easy, there are several best practices that can help us, and one of the most important is to start with a good, organized code base."
  },
  {
    "objectID": "sessions_core/02_import_data.html#setting-up-your-project",
    "href": "sessions_core/02_import_data.html#setting-up-your-project",
    "title": "Data Importation",
    "section": "Setting up your Project",
    "text": "Setting up your Project\n\nFolder Structure\n\nIf not done already, download and unzip the course folder. Save the uncompressed folder to a location that is not connected to OneDrive and navigate into it.\n\n\n\n  Course Folder\n\n\n\n\nThis folder gives an example of a typical (and highly recommended) structure for your code projects:\n\nüìÅ data\n\nüìÅ clean\nüìÅ raw\n\nüìÅ R\nüìÅ outputs\n\nThis folder will be you working directory for all the sessions of this course. You will create an Rstudio project in it (explanations below), and save all your scripts in /R. The course datasets are already in data/raw.\n\n\nDefinitions\nTo work through this session you need to understand the two following concepts:\nWorking directory. The working directory is the location (folder) where your R session is actively working. If you save a file, for example, it will be saved into this folder by default. Similarly, when you want to open a file, this folder will be shown by default. All relative paths will be relative to this working directory. By default, R usually picks the ‚ÄúDocuments‚Äù folder as the working directory on Windows machines.\nRoot. The root refers to the top-most folder level of the working directory. If your course folder was called FETCHR, the root would then be directly inside it (as opposed to being inside one of its subfolders like R or Data).\n\n\nRStudio Projects\nAn RStudio Project can be used to make your life easier and help orient RStudio around the various files used in your code\nAs a quick reminder, your interface should look something like this:\n\n\n\n\n\n\nFigure¬†1: Screenshot of a typical Rstudio interface\n\n\n\n\nOpen RStudio and create a new project by clicking File &gt; New Project &gt; Existing Directory &gt; Browse, navigating into (opening) the course folder, and clicking Create Project.\n\n\nIn the Windows Explorer, look at the course folder. You should now see a new file with the extention .Rproj that has a small blue icon with an R in it.\n\n\n\n\nIcon associated with RStudio projects\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you don‚Äôt see this file, it‚Äôs probably because it is hidden by default on your computer. To change this setting in Windows Explorer, go into the View menu and select Filename Extensions.\n\n\nWhen you open an RStudio Project, RStudio starts a new R session, opens the associated project files, and sets your working directory to the root of the course folder. At this time, RStudio also displays the subfolders of this directory in the panel on the bottom right.\n\n\n\n\n\n\nTip\n\n\n\nIt is strongly recommended to set up a separate RStudio Project for each of your analyses to ensure that your project files remain organized and manageable.\n\n\nThere are several ways to open an RStudio Project:\n\nUse the RStudio menu File &gt; Open Project and then select the relevant .Rproj file\nClick on the Project: (none) button on the top right of the RStudio interface\nNavigate in the folder explorer to the analysis folder and double click on the file with the .Rproj extension\n\n\n\nRStudio Options\nBefore continuing, let‚Äôs update some of RStudio‚Äôs problematic default settings:\n\nOpen the global options (Tools &gt; Global Options) and open the tab General (left menu). Make sure that none of the boxes in the sections R Sessions, Workspace, or History are checked.\n\n\n\n\nScreenshot of the Rstudio options\n\n\nWhen checked, these options cause RStudio to save the objects in your environment and reload them as well as any files you previously had open when you open a new R session. While these default may seem like a good idea, it is better to always start your work from a fresh, empty R session to avoid bugs.\n\n\n\n\n\n\nImportant\n\n\n\nRemember that any commands or outputs that is needed for the cleaning and analysis should be saved explicitly in a script in the correct, functional order."
  },
  {
    "objectID": "sessions_core/02_import_data.html#creating-a-new-script",
    "href": "sessions_core/02_import_data.html#creating-a-new-script",
    "title": "Data Importation",
    "section": "Creating a New Script",
    "text": "Creating a New Script\n\nOpen a new script and save it in the R folder of your project under the name import_data.R.\nAdd some metadata to the top of the script as seen in the first session using comments. Be sure to include:\n\nTitle\nAuthor\nCreation Date\nDescription\n\n\nNow you‚Äôre ready to start coding!"
  },
  {
    "objectID": "sessions_core/02_import_data.html#sec-packages",
    "href": "sessions_core/02_import_data.html#sec-packages",
    "title": "Data Importation",
    "section": "Packages",
    "text": "Packages\nPackages are collections of functions that extend the functionality of R. You‚Äôll use them a lot, both in this course and in your daily life. Fortunately, as an open source language, R packages can be downloaded and installed for free from the internet.\n\n\n\n\n\n\nNote\n\n\n\nIn R, packages are referenced using {}. For example {ggplot2} is the name of the ggplot2 package that contains new plotting functions such as ggplot(), geom_point() etc‚Ä¶\n\n\n\nInstallation\nWe can install a new package using the function install.packages(), which downloads and installs it into the package library on your computer. This is done once per computer.\n\ninstall.packages(\"here\") # install the {here} package\n\nDon‚Äôt forget to wrap the package name in quotation marks when using install.packages(). What happens if you don‚Äôt do this?\n\n\n\n\n\n\nNote\n\n\n\nIf you are following this session as part of a course, to avoid any potential internet connectivity issues during the training we already had you install most of the course packages.\nIf are following this tutorial on your own or have not installed the packages yet, you will have to manually install each new package that we encounter.\n\n\n\n\nUsage\nOnce a package is installed we can use it but we have to specify to R that we will be using it every single session. This process is called loading the package and is achieved using the function library().\n\nlibrary(here) # load the \"here\" package\n\n\nUse the library() function to load the packages here and rio, which will be used in the next section.\n\nBased on your computer‚Äôs set up and the package you are trying to load, you may get a warning message noting that some functions have been masked or that the current version of the package was built for a different version of R. These messages are not usually a problem but are still important to note.\n\nTry to run the following code. Can you work out what the error means?\n\nlibrary(ggplot)\n\n\nThe above code throws an error because you have asked for a library that doesn‚Äôt exist. Remember that R is fickle and case sensitive and many of your errors will come from small typos in the names of functions or objects. Here, for example, we wanted to load the package ggplot2 but wrote ggplot instead.\n\n\n\n\n\n\nTip\n\n\n\nMost of the time, you‚Äôll need to load a number of packages for your script and it is recommended to have a section at the start of your code that loads everything you‚Äôll need in one place:\n\n# Packages ----------------------------\nlibrary(tidyverse)   # data manipulation\nlibrary(lubridate)   # date manipulation\n\nThis practice makes it easy to tell which packages need to be installed to run a script.\n\n\n\nUse comments to create a ‚ÄúPackages‚Äù section to your script.\n\n\n\nUpdating Packages\nR has a very active community of developers and it‚Äôs pretty common for packages to be updated from time to time as their owners add in new functions and fix existing bugs. In order to update the packages in your library, you can go into the Packages tab of the bottom right panel and click Update. Don‚Äôt forget that you‚Äôll need to be connected to the internet during this process.\n\n\n\n\n\n\nImportant\n\n\n\nSometimes packages are updated in a way that might remove or change a function that you used in some of your scripts, causing your code to no longer work. Don‚Äôt panic if this happens. The best practice is to adapt your code, although in the worst case scenario you can forcibly install an old version of a package. This is however out of the scope of this session."
  },
  {
    "objectID": "sessions_core/02_import_data.html#data-importation",
    "href": "sessions_core/02_import_data.html#data-importation",
    "title": "Data Importation",
    "section": "Data Importation",
    "text": "Data Importation\n\nUnderstanding File Paths\nTo open a file in R you need to provide a file path. A file path is simply a longer name for a file, that includes not only its name but also its location on your computer. There are several ways of defining these paths, including absolute and relative paths.\n\nAbsolute Paths\nAbsolute paths are specific to your computer and go all the way up to the level of your hard drive. For example, an absolute path may look something like this: D:/OneDrive - MSF/Documents/monitoring/cholera/fancy_project/data/raw/example_linelist.xlsx. Clearly, this path will only work on one specific computer.\nThe use of hard coded absolute paths is strongly discouraged as it makes your code inflexible and prone to break: the paths need to be updated every time your code is shared or the project folder is moved on your computer.\n\n\nRelative Paths\nRelative paths are defined relatively to your current working directory. For example, keeping in mind that our handy .Rproj file set our working directory to the root of our project folder, we could create a relative path that looked like data/raw/example_linelist.xlsx. This means that as long as we maintain the internal structure of our project folder and have an .Rproj file, our code would theoretically run on multiple computers.\n\n\nRobust Paths with the here() function\nThe {here} package has a here() function that really helps defining paths. It has two advantages:\n\nWhen used with RStudio projects, you can give it only the part of the path within the project, (the relative path in other words), and the function uses it to create the absolute path dynamically.\nIt does so using the separator adapted to you operating system, whether it‚Äôs /, \\, or //\n\n\nlibrary(here)\nhere(\"data\", \"raw\", \"example_linelist.xlsx\")\n\n[1] \"C:/Users/M-MOUSSET/AppData/Local/Temp/RtmpKwyCyA/file41782aeb4fc8/data/raw/example_linelist.xlsx\"\n\n\nSee how we only defined the relative path and the function created an absolute path. This way of defining the path will work on your colleagues computer, even if they run on another operating system, as long as you both respect the internal structure of the working directory.\nWe strongly encourage you to use here() whenever you need to create a file path.\n\nRun the above code in the console. What file path does here(\"data\", \"raw\") give you?\n\n\nUsing here(), create a complete file path for the file Moissalla-measles-linelist-EN.xlsx. Keep this path around, we will use it soon.\n\n\n\n\n\n\n\nImportant\n\n\n\nhere() simply creates a file path, it doesn‚Äôt actually check if a file exists on your computer: if the file is absent or there is a typo in your code, the command will yield an error when the path is used. If you would like to use a function to check if a file exists, check out the file.exists() function.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe will often want to source multiple data files in a single project. To make that process easier, it can be helpful to create a section at the start of the script, after loading the packages to define paths and store them in variables.\n\n\n\n\n\nImport function\nIn R different file formats are often imported using different, often specialized functions. This can be tedious as it requires you to memorize and load a large number of functions just to get your data imported. To avoid this problem, we recommend that you use the import() function from the package {rio}. This function is able to open a large variety of files (including Excel, csv, Stata, and many others) by recognizing the file extension of your data and calling a relevant specialized function from another package so that you don‚Äôt have to.\nBecause import() is actually just calling other functions in the background, it is possible that it will need different arguments depending on the type of file you want to load.\n\n\n\n\n\n\nTip\n\n\n\nTo see the full list of all the file types you can load (and save!) with rio, check out the list of supported formats on their website. In the rest of the lesson we will focus on importing data from Excel .xlsx files.\n\n\n\nImporting from the First Sheet\nIn general, the usage of import() is pretty simple, at minima you need to pass the path of the file to the file argument\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"))\n\nNotice that we have nested the command here() inside the import() command. Nesting functions is absolutely allowed in R and is something you will do all the time. When functions are nested, R will evaluate them in the order of the innermost function (in this case here()) to the outermost (in this case import()). In this way, the output of here() is being used as the input of import().\n\nImport the file Moissalla-measles-linelist-EN.xlsx that is in your raw data subfolder into R using here() and import().\n\nIf your import worked correctly, R will print the data into the console but not save it into the environment because we have not assigned them to an object.\n\n\n\n\n\n\nTip\n\n\n\nYou may not want to have R print very large datasets into the console and assign them directly to an object.\n\n\n\nReimport your data but this time save it to an object called df_linelist.\n\n\n\nImporting Data from Any Sheet\nAs you just saw, R selects the first sheet by default. It is however possible to pass the number (or name) of a specific worksheet in your Excel data to import() using the argument which:\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"),\n       which = 2)  # imports the second sheet\n\nNote that the which argument is specific to the file types that have multiple sheets, such as Excel or .Rdata files. If you try to use it on a .csv file the argument will be ignored."
  },
  {
    "objectID": "sessions_core/02_import_data.html#taking-a-first-look-at-your-data",
    "href": "sessions_core/02_import_data.html#taking-a-first-look-at-your-data",
    "title": "Data Importation",
    "section": "Taking a First Look at your Data",
    "text": "Taking a First Look at your Data\nWe have now imported a dataset into R and assigned it to a dataframe (df_linelist). The natural next step is to inspect this dataset, to check that the import went well, get to know it a bit better, and assess if it requires any cleaning before analysis.\nWe can start by taking a quick look at the first few lines of the dataframe using the function head(). This function takes a dataframe as its first argument and optionally accepts a second argument n indicating the number of lines we would like to see.\n\nhead(df_linelist, n = 10) # Inspect 10 first lines\n\n\nUse head() to examine the 12 first lines of df_linelist.\n\nWe can also check out our data by looking at the Environment tab of the top-right panel. Here, we can see our dataframe in the environment, look at its structure, or open it in the data viewer of RStudio.\n\nClick on the round blue button next to df_linelist in your environment to see its structure. Then click on the name of the dataset to open it in the viewer.\n\nThe data viewer displays dataframes as tables and is a convenient way to quickly look at your data. You can even sort and filter your data in the ‚ÄúView‚Äù, though be aware that these actions will not make any changes to the actual object df_linelist. The View can also be opened by passing the dataframe to the function View()."
  },
  {
    "objectID": "sessions_core/02_import_data.html#done",
    "href": "sessions_core/02_import_data.html#done",
    "title": "Data Importation",
    "section": "Done!",
    "text": "Done!\nWell done and don‚Äôt forget to save your code.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/02_import_data.html#going-further",
    "href": "sessions_core/02_import_data.html#going-further",
    "title": "Data Importation",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nUse dim() to take a look at the dimensions of your dataset.\nUse str() to check the data type of each column. Does anything look odd? Remember that you can also use functions like is.character() and is.numeric() if you‚Äôd like to test the type of a particular column.\nUsing a function learned in the first session, can you extract the names of the columns of the dataset? Do these results match what you see when you open the data in Excel?\nTry passing your dataframe to the function summary(). What does this function tell you?\n\n\n\nAdditional Resources\n\nThe {rio} website\nMore examples on importing data of various file types"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html",
    "href": "sessions_core/04_data_verbs_conditional.html",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "",
    "text": "Understand basic conditional logic statements\nLearn how to filter a data frame using filter()\nLearn how to recode variables using case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#objectives",
    "href": "sessions_core/04_data_verbs_conditional.html#objectives",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "",
    "text": "Understand basic conditional logic statements\nLearn how to filter a data frame using filter()\nLearn how to recode variables using case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#setup",
    "href": "sessions_core/04_data_verbs_conditional.html#setup",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know the basics of data manipulation with {dplyr}. If you need a refresher on this, please review the third session in the learning pathway.\n\nThis session will work with the raw Moissala linelist data, which can be downloaded here:\n\n\n\n  Download Data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called filtering_and_recoding_practice.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_raw."
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#using-conditional-logic-to-filter-data",
    "href": "sessions_core/04_data_verbs_conditional.html#using-conditional-logic-to-filter-data",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Using Conditional Logic to Filter Data",
    "text": "Using Conditional Logic to Filter Data\nIn the last session we learned a lot of the core data verbs in {dplyr} for basic manipulation tasks like selecting particular variables of interest and modifying them to better suit our needs. Beyond selecting variables of interest, another common task we have as epidemiologists is selecting observations of interest; ie: filtering our data to look at particular observations that meet a certain criteria.\nFortunately, {dplyr} has our back with the conveniently named function, filter(). To understand how to use it, however, we will need to learn a bit about how to construct conditional logic statements in R. This will be the focus of our session today.\n\nThis Equals That\nThe basic syntax of filter() is pretty simple:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf_raw |&gt;\n  filter([conditional logic statement]) # Keep lines where statement is TRUE\n\nBut what is a conditional logic statement? These are statements that ask ‚ÄúIs this thing true?‚Äù. The simplest conditional logic statement asks ‚Äúdoes this variable equal this value?‚Äù. For example, ‚Äúwas this patient hospitalized?‚Äù. In R, we can ask if one value equals another using ==.\nTo create a filter asking, for each observation, whether the value of hospitalization is equal to yes we can then use the following syntax:\n\ndf_raw |&gt;\n  filter(hospitalisation == 'yes')\n\nWhat filter() is doing here is going down each row of our dataset and asking: ‚Äúfor this row, is the value of hospitalisation equal to \"yes\"?‚Äù. It then returns only the rows where the answer to this question is TRUE.\n\nCreate a filter that selects all of the patients who had a fever, ie: where the value of fever was \"Yes\". The head of fever should look like this:\n\n\n  fever\n1   Yes\n2   Yes\n3   Yes\n4   Yes\n5   Yes\n6   Yes\n\n\nTake a look at your output and then take a look at the head of df_raw. Why does df_raw still contain patients who didn‚Äôt present with fever?\n\n\n\nThis Does Not Equal That\nChecking if something is the same is great, but a lot of the time we might have another question in mind. For example, we might want to know how many patients didn‚Äôt recover, whether this was because they died or because they left against medical advice.\nIn this case, instead of writing == we will instead use !=. So, for example if we want to select all observations where patients didn‚Äôt recover we would write:\n\ndf |&gt;\n  filter(outcome != 'recovered')\n\n\nCreate a filter that selects patients who did not have a card confirmed vaccination status. The head of vacc_status should look like this:\n\n\n  vacc_status\n1          No\n2  Yes - oral\n3          No\n4          No\n5          No\n6          No\n\n\nHint. Remember that you can use count() to check what the options were for vacc_status.\n\n\n\nGreater Than / Less Than\nThe other common question we have is whether a value was greater or less than a particular threshold. For example, how many patients were under 5 years old? Here we will use &lt; and &gt; to evaluate whether a variable is less than or greater than a particular value, respectively.\nFor example, to ask how many patients were less than 60 months old we can write:\n\ndf_raw |&gt;\n  filter(age &lt; 60)\n\n\nCreate a filter that selects all patients with severe accute malnutrition (ie: patients with a MUAC less than 110). The head of muac should look like this:\n\n\n  muac\n1   80\n2   88\n3   60\n4   85\n5   86\n6   68\n\n\nNow create another filter that selects patients who are over 15 years old. The head of your age column should look like this:\n\n\n  age\n1 348\n2 348\n3 312\n4 432\n5 444\n6 324\n\n\n\nSometimes, instead of asking if something is less or greater than a particular value, we want to ask if it is less than or equal to that value. Easy, we just need to add an equal sign! We write &lt;= for ‚Äúless than or equal to‚Äù and &gt;= for ‚Äúgreater than or equal to‚Äù. Careful here, the = must come after &lt; or &gt;, not before.\nSo if we want to ask for how many patients were 10 years of age or younger, we can write:\n\ndf_raw |&gt;\n  filter(age &lt;= 120)\n\n\nCreate a filter that selects all patients with a normal nutrition status, ie: patients with a MUAC greater than or equal to 125. The head of muac should look like this:\n\n\n  muac\n1  244\n2  232\n3  210\n4  220\n5  152\n6  155\n\n\n\n\n\nFilters with Multiple Conditions\nWant to combine several logic statements in a single filter? Easy. We can create a filter with multiple conditions by simply separating each condition with a comma:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  filter([condition 1],\n         [condition 2],\n         [condition 3])\n\nSo for example, let‚Äôs say we want to select all patients under five who were hospitalized. In this case we can write:\n\ndf_raw |&gt;\n  filter(age &lt; 5,\n         hospitalised = \"true\")\n\n\nCreate a filter that selects all patients with severe accute malnutrition who were hospitalized in the Koumra health facility. The head of id, sub_prefecture, hospitalisation, and muac should look like this:\n\n\n    id sub_prefecture hospitalisation muac\n1 8624         KOUMRA             yes  103\n2 8939         KOUMRA             yes   67\n3 9957         KOUMRA             yes   71\n\n\nHint. This filter has a condition on both hospitalisation status, sub_prefecture, and muac.\n\n\n\nSummary of Basic Logic Statements\nGood job working through a quick tour of logic statements in R! Here is a handy table to help you remember the main logic statements we have learned so far:\n\n\n\nStatement\nR\n\n\n\n\nIs A the same as B?\nA == B\n\n\nIs A not the same as B\nA != B\n\n\nIs A greater than B?\nA &gt; B\n\n\nIs A greater than or equal to B?\nA &gt;= B\n\n\nIs A less than B?\nA &lt; B\n\n\nIs A less than or equal to B?\nA &lt;= B"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#recoding-with-case_when",
    "href": "sessions_core/04_data_verbs_conditional.html#recoding-with-case_when",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Recoding with case_when()",
    "text": "Recoding with case_when()\nAs we have seen, conditional logic statements are incredibly useful when trying to filter our data, but you will find that they have many other uses as well. One of their other major use cases for us as epidemiologists is when we need to recode our data. This is where the {dplyr} function case_when() is here to help us.\nThe syntax of case_when() is a little more advanced than what we have seen so far, but we will go slowly and break it down. Once you get the hang of it, case_when() will become a very powerful part of your R toolbelt.\nWe will almost always use case_when() inside of a mutate(), because we will use it either to recode an existing variable or to create a new one. The basic syntax works like this:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  mutate(column_name = case_when([first condition] ~ [value when condition is TRUE],\n                                 [second condition] ~ [value when second condition is TRUE],\n                                 .default = [default value])\n\nOk, that‚Äôs a lot. Let‚Äôs break it down.\nSo the first thing to notice is that, with the exception of the last line, each line inside of case_when() has the following format:\n\n[condition] ~ [value when condition is TRUE]\n\nSo for example, if we want our case_when() to say that anytime a patient had a MUAC less than 110 we want to have a value of \"SAM\", we would have something like this:\n\nmuac &lt; 110 ~ 'SAM'\n\nWe can add multiple possible outcomes by adding additional lines. In this case, our next condition might check if the patient is moderately but not severly malnourished using the statement muac &lt; 125 ~ 'MAM'.\nThe last line, with the argument .default gives the value we want case_when() to use when none of the above conditions have been met. In this case, we might give the value 'Normal'.\nTo put this together, if we wanted to create a variable that classifies the malnutrition status of patients using their MUAC, we would write:\n\ndf_raw |&gt;\n  mutate(malnut = case_when(muac &lt; 110 ~ 'SAM',\n                            muac &lt; 125 ~ 'MAM',\n                            .default = 'Normal'))\n\n\nTry running the above code to see if it successfully creates a new column malnut with the malnutrition status of each case. You should get something like this:\n\n\n  muac malnut\n1  244 Normal\n2  232 Normal\n3  123    MAM\n4  210 Normal\n5   80    SAM\n6  220 Normal\n\n\n\nBe careful. The order of your statements is important here. What case_when() will do is go through each statement from top to bottom and assign the first value that is TRUE. So in our above example, case_when() will ask the following questions in sequence:\n\nDoes this patient have SAM (is muac &lt; 110)? If so, assign the value \"SAM\"\nIf the patient didn‚Äôt have SAM, do they have MAM (is muac &lt; 125)? If so, assign the value `‚ÄúMAM‚Äù\nIf none of the above conditions were true, assign the default value \"Normal\"\n\n\nTry reordering the first and second conditions in the above case_when() so that you first check if muac &lt; 125. The head of your new data frame should now look like this:\n\n\n  muac malnut\n1  244 Normal\n2  232 Normal\n3  123    MAM\n4  210 Normal\n5   80    MAM\n6  220 Normal\n\n\nNotice anything different? Save this new data frame to a tmp object and inspect it to see if we still have any patients classified as \"SAM\". Can you figure out why this no longer gives the correct classification?\n\n\n\n\n\n\n\nNote\n\n\n\nThe .default argument in case_when() is not obligatory. If you don‚Äôt include it then case_when() will use NA by default.\n\n\nAs we saw in our above example, case_when() is an easy way of creating new variables based on the values of an existing column. This can be used to classify status (as we saw with malnutrition) or to regroup variables into categories (like age groups).\n\nUse case_when() to create a new variable age_group with three categories: \"&lt; 5 Years\", \"5 - 15 Years\", and \"&gt; 15 Years\". Patients missing age data should be assigned a default value of \"Unknown\". Be careful with your ordering! The head of your new column should look like this:\n\n\n  age     age_group\n1  36     &lt; 5 Years\n2   5     &lt; 5 Years\n3 156 5 - 15  Years\n4   8     &lt; 5 Years\n5   7     &lt; 5 Years\n6   4     &lt; 5 Years\n\n\n\n\nThe %in% operator\nSo now we can regroup variables into categories, great. But we can also use case_when() to standardize the values we see in a variable.\n\nUsing count() inspect the categorical variables in df_raw to check if any have inconsistencies in their coding.\n\nIn our dataset, we see that there are some issues in the way sex was coded. For example, female patients are coded as f, female and femme. That simply won‚Äôt do. Thankfully, we can use case_when() to recode this variable. This time, instead of creating a new variable we will directly update sex:\n\ndf_raw |&gt;\n  mutate(sex = case_when(sex == \"f\" ~ \"Female\",\n                         sex == \"female\" ~ \"Female\",\n                         sex == \"femme\" ~ \"Female\",\n                         sex == \"m\" ~ \"Male\",\n                         sex == \"male\" ~ \"Male\",\n                         sex == \"homme\" ~ \"Male\",\n                         .default = \"Unknown\"))\n\nWell, that works, but it seems awfully repetitive. It would be easier if we could just list all the options that we want to reassign to ‚ÄúFemale‚Äù and ‚ÄúMale‚Äù respectively. This is where the %in% operator is here to help. The %in% operator will check if a value is in a vector of options using the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\n[value] %in% [vector_of_options]\n\nSo, for example, we could check if the value \"f\" is in the options \"f\", \"female\" using the following:\n\n\"f\" %in% c(\"f\", \"female\")\n\n\nTry running the above statement. What is the data type of your outcome?\n\nSee how the outcome of the above statement is a boolean, ie: a logic outcome? That means we can use it as a condition in case_when()! This means that our verbose code above can now be written as:\n\ndf_raw |&gt;\n  mutate(sex = case_when(sex %in% c(\"f\", \"female\", \"femme\") ~ \"Female\",\n                         sex %in% c(\"m\", \"male\", \"homme\") ~ \"Male\",\n                         .default = \"Unknown\"))\n\nMuch nicer.\n\nUse case_when() and the %in% operator to create a new column vacc_status_strict that has the value \"Yes\" for cases with card confirmed vaccination status, \"No\" for cases who said they were unvaccinated, and \"Unverified\" otherwise. The head of your new column should look like this:\n\n\n  vacc_status_strict\n1         Unverified\n2                 No\n3         Unverified\n4                 No\n5                 No\n6                 No"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#a-last-bit-of-cleanup",
    "href": "sessions_core/04_data_verbs_conditional.html#a-last-bit-of-cleanup",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "A Last Bit of Cleanup",
    "text": "A Last Bit of Cleanup\nNow that we know how to leverage case_when() and conditional logic (in addition to what we learned in the last session, we can actually put together a decent cleaning pipeline. I hope you kept your code from last time handy‚Ä¶\n\nUsing what you have learned above and what you practiced in the last session, create a basic data cleaning pipe that creates a new data frame, df, after doing the following:\n\nRemove the variables full_name and age_unit\nRename the following variables:\n\nage becomes age_months\nsub_prefecture becomes prefecture\nvillage_commune becomes village\nhealth_facility_name becomes facility\n\nAdd a variable age_years with patient age in years\nUpdate region and prefecture to use title case\nUpdate all date columns to use Date type\nCreate a new variable age_group age to include the groups: &lt; 6 months, 6 - 11 months, 12 - 59 months, 5 - 15 years, and &gt; 15 years (patients with unknown age should have a value ‚ÄúUnknown‚Äù)\nRecode sex to have only the values: Female, Male, and Unknown\nRemove any duplicate observations\n\nThe head of your final data should look something like this:\n\n\n  id    sex age_months  region prefecture        village date_onset\n1  1 Female         36 Mandoul   Moissala Sangana Ko√Øtan 2022-08-13\n2  2 Female          5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3 Female        156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6   Male          8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7   Male          7 Mandoul   Moissala      T√©tindaya 2022-08-30\n6 10   Male          4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             yes     2022-08-14\n2        2022-08-25             yes     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25              no           &lt;NA&gt;\n5        2022-09-02              no           &lt;NA&gt;\n6        2022-09-02             yes     2022-09-02\n                         facility malaria_rdt fever rash cough red_eye\n1 H√¥pital du District de Moissala    negative    No &lt;NA&gt;   Yes      No\n2 H√¥pital du District de Moissala    negative    No   No   Yes      No\n3                      CS Silambi    negative   Yes &lt;NA&gt;    No      No\n4 H√¥pital du District de Moissala    negative    No   No    No    &lt;NA&gt;\n5                      CS Silambi    negative  &lt;NA&gt;   No   Yes     Yes\n6                    Moissala Est    negative   Yes   No    No    &lt;NA&gt;\n  pneumonia encephalitis muac vacc_status vacc_doses   outcome date_outcome\n1        No           No  244        &lt;NA&gt;       &lt;NA&gt; recovered   2022-08-18\n2      &lt;NA&gt;           No  232          No       &lt;NA&gt;      &lt;NA&gt;   2022-08-28\n3        No         &lt;NA&gt;  123  Yes - oral       &lt;NA&gt; recovered         &lt;NA&gt;\n4        No           No  210          No       &lt;NA&gt; recovered         &lt;NA&gt;\n5        No           No   80          No       &lt;NA&gt; recovered         &lt;NA&gt;\n6        No           No  220          No       &lt;NA&gt; recovered   2022-09-03\n   age_years      age_group\n1  3.0000000 12 - 59 months\n2  0.4166667     &lt; 6 months\n3 13.0000000   5 - 15 years\n4  0.6666667  6 - 11 months\n5  0.5833333  6 - 11 months\n6  0.3333333     &lt; 6 months\n\n\n\nAmazing! Let‚Äôs look at how to save this (mostly) clean dataset. Here, we will use the function export() from {rio} and here() from {here} to specify where to save our output:\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.xlsx'))\n\nNotice here that we are putting our data in the appropriate clean subfolder of data.\n\n\n\n\n\n\nTip\n\n\n\nIn the above example we save our data as an xlsx, which is helpful if you want to be able to open the clean data in Excel. Often, however, we might prefer to use a file with the extension .rds instead. This is a file type specific to R and is more robust to issues related to encoding or date formatting than files like xlsx or csv. To save your above file as an rds all you need to do is change the extension:\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.rds'))"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#done",
    "href": "sessions_core/04_data_verbs_conditional.html#done",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Done!",
    "text": "Done!\nVery well done. You‚Äôve learned how to use basic data verbs, conditional logic, and create a basic data cleaning pipeline.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#going-further",
    "href": "sessions_core/04_data_verbs_conditional.html#going-further",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises"
  },
  {
    "objectID": "sessions_core/06_epicurves.html",
    "href": "sessions_core/06_epicurves.html",
    "title": "Basic Data Visualization",
    "section": "",
    "text": "Grasp the very basics of data visualization in R using {ggplot2}\nBuild a basic epicurve"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#objectives",
    "href": "sessions_core/06_epicurves.html#objectives",
    "title": "Basic Data Visualization",
    "section": "",
    "text": "Grasp the very basics of data visualization in R using {ggplot2}\nBuild a basic epicurve"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#introduction",
    "href": "sessions_core/06_epicurves.html#introduction",
    "title": "Basic Data Visualization",
    "section": "Introduction",
    "text": "Introduction\nThis session is a short introduction to data visualization using the popular {ggplot2} package. Keep in mind that visualization in general and even {ggplot2} in particular are huge subjects that we can‚Äôt cover in a single core session. This tutorial is intended as a taster to give you a feel for how plotting is typically done. To do that, we will come back to one of our most beloved epidemiological plots: the epicurve.\nOur final plot will look like this:"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#setup",
    "href": "sessions_core/06_epicurves.html#setup",
    "title": "Basic Data Visualization",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio that you are able to import data and that you know th basic data handling verbs that we have seen in the core sessions so far. If you need a refresher on either of these topics, we encourage you to review the core sessions in the learning pathway.\n\nThis session will use the clean version of the Moissala measles linelist data.\n\n\n\n  Course Folder\n\n\n\n Open your RStudio project and create a new script called epicurves.R with appropriate metadata. Load the following packages: {here}, {rio}, {dplyr}, {lubridate}, and {ggplot2}. Add a section to your script called # IMPORT DATA where you import the clean course dataset (moissala_linelist_clean_EN.rds)."
  },
  {
    "objectID": "sessions_core/06_epicurves.html#paradigms-of-plotting",
    "href": "sessions_core/06_epicurves.html#paradigms-of-plotting",
    "title": "Basic Data Visualization",
    "section": "Paradigms of Plotting",
    "text": "Paradigms of Plotting\nIn R, and indeed in everything, there are a lot of ways to approach data visualization. Two of the biggest paradigms are :\n\nThe All-In-One: this approach is characterized by having a single, typically somewhat complex, function that handles all aspects of building a plot. Base R as well as a variety of specialized packages tend to use this approach.\nLayered (or modular): here, instead of creating a plot with a single function, we will use separate functions to add (or modify) different features of a plot (such as the primary shapes, labels, error bars, themes, etc). This is the strategy used by packages like {ggplot2}, {highcharter}, or {echarts4r}.\n\nAn in depth discussion of why one might use one approach versus another is beyond the scope of this course, though we will note that most modern visualization packages tend to use a layered model. With that in mind, let‚Äôs take a look at the types of layers we are talking about in our ‚Äúlayered‚Äù approach.\n\nBreaking it Down: A Visualization and its Parts\nFor the purpose of this tutorial we will talk about only four visualization components (layers):\n\nCanvas / Data\nPrimary Shapes\nLabels\nTheme\n\nTo illustrate these components, let‚Äôs look at a basic schematic of an epicurve:\n\n\n\n\n\nThe most conceptually complex of the above layers is probably the canvas itself. Much as an artist needs to buy a canvas and conceptualize what they want to paint before they start painting, so too does a user of {ggplot2}. Creating the canvas is where we tell R that we want to start making a plot and what parts of the data that plot will use. Here, for example, we will tell R ‚ÄúI want to make a plot where the x axis represents dates (or weeks sometimes) and the y axis represents cases‚Äù. Once that canvas is set up we can start adding other layers in the same way that an artist would begin adding paint, their signature, or a frame.\nNow, let‚Äôs look at the syntax for these layers in {ggplot2} and how to put them together.\n\n\nGetting Started with {ggplot2}\nThe method of building a ggplot is relatively simple and takes the form:\n\nCreate a canvas using a duo of functions ggplot(aes(...))\nAdd things to the canvas\n\n{ggplot2} takes the idea of ‚Äúadding something to the canvas‚Äù very literally: each new layer will be introduced to your plot using the + sign.\nThe general syntax of a ggplot is then:\n\n# DO NOT RUN (PSEUD-CODE)\ndf |&gt;                      # pipe in your data \n  ggplot(aes(x = ...,      # step 1: create canvas\n             y = ...)) +\n  layer_one(...) +         # step 2: add a first layer\n  layer_two(...) +         # step 3: add another layer\n  ...                      # continue adding layers...\n\nThe number of layers you add depends on how complex you want your plot to be. In our case, we will be adding three layers to our canvas with the following functions:\n\n# DO NOT RUN (PSEUD-CODE)\ndf |&gt;                    # pipe in your data\n  ggplot(aes(x = ...,     # step 1: create canvas\n             y = ...)) +\n  geom_col(...) +         # step 2: add shapes (bars)        \n  labs(...) +             # step 3: add titles\n  theme_classic(...)      # step 4: add a nicer theme\n\nWe can update our above schematic of an epicurve with these functions as follows:\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that in the above example, our very first line is actually our dataset being piped into the ggplot() function. This makes sense since {ggplot2} needs to know what data you‚Äôd like to visualize. But be careful, make sure that this line ends in a pipe (|&gt;) and not in a + sign like t |&gt; he other ones.\n\n\nIn the next part of the tutorial we will go through each of these steps (layers) individually using our course dataset to make your first epicurve."
  },
  {
    "objectID": "sessions_core/06_epicurves.html#sec-epicurve-steps",
    "href": "sessions_core/06_epicurves.html#sec-epicurve-steps",
    "title": "Basic Data Visualization",
    "section": "Building Your First ggplot",
    "text": "Building Your First ggplot\n\nPreparing Your Data: Aggregate by Day\nUltimately we would like to plot an epicurve of daily cases. You may have noticed, our current data is daily, but of course several cases may occur on some days. To plot an epicurve we will need to aggregate data by day. Fortunately, you already learned how to summarize data in previous sessions.\n\nUsing count(), create a new dataframe called df_cases that summarizes the total number of cases observed per day. The head of this data frame should look like this:\n\n\n  date_onset n\n1 2022-08-13 1\n2 2022-08-17 1\n3 2022-08-18 1\n4 2022-08-22 1\n5 2022-08-30 2\n6 2022-09-01 1\n\n\n\nGreat! Now we are ready to make our epicurve. In the following steps, you‚Äôll be asked to use df_cases to plot a classic epicurve of the number of daily admissions. To demonstrate the functions you‚Äôll be using, I will plot the curve of the number of daily hospitalizations as an example. To do that, I‚Äôve built myself another dataframe, df_outcome, which looks like this:\n\n\n  date_admission patients\n1     2022-08-14        1\n2     2022-08-25        1\n3     2022-09-02        1\n4     2022-09-06        1\n5     2022-09-09        1\n6     2022-09-10        1\n\n\n\n\nSet up a Canvas: Initialize a Plot\nThe first step is creating your canvas by specifying your dataset and the names of the columns you‚Äôd like to visualize. This is done using ggplot(aes(...)) with the following syntax:\n\n# DO NOT RUN (PSEUD-CODE)\ndf_data |&gt;\n  ggplot(aes(x = x_axis_variable_name,\n             y = y_axis_variable_name))\n\nFor an epicurve of hospitalizations, I‚Äôd like to plot the days (date_admission) on the x-axis and the number of patients hospitalized (patients) on the y-axis. Let‚Äôs update our pseudo-code to do that:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients))\n\n\n\n\n\n\n\n\nFabulous, take a look at that big beautiful box of potential. This is our empty canvas. In RStudio this plot should show up in the panel on the bottom right of the screen.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nJust like with {dplyr}, we write our column names without quotation marks. This is unsurprising as {ggplot2}, like {dplyr}, is a member of the {tidyverse} and therefore uses similar syntax.\n\n\nNow, you may be wondering what is this aes() function that we‚Äôve nested inside of ggplot()? The short answer is that aes() creates an AESthetic mapping that tells {ggplot2} which columns of our data should be represented by which visual elements of our plot (like the axes, for example).\nAesthetic mappings create a map that defines how data elements (variables) are to be represented by visual elements (like axes, colors, and sizes). For example, here we are mapping the days to the x-axis and the number of patients to the y-axis. We could also imagine, for example, an epicurve where bars are colored based on whether patients lived or died. This would be an example where the variable outcome is being mapped to the visual element of color.\nFor now it is enough to know that aes() is the place where you will define your x-and y-axis.\n\nCreate a new section in your script called # PLOT EPICURVE. Then create an empty canvas for your epicurve using df_cases.\n\nAt this point, your plot should look like this:\n\n\n\n\n\n\n\n\n\nExcellent! Now let‚Äôs add some bars.\n\n\nPlot the Bars\nNow that we have our canvas, it‚Äôs time to add some shapes. In {ggplot2}, the shapes plotted on a figure are called geometries. Geometries are the primary visual representation of your data and should feel pretty familiar. A few common types of geometries include:\n\nBar Plots (geom_col() or geom_bar())\nHistograms (geom_hist())\nScatterplots (geom_point())\nLine Plots (geom_line())\nBoxplots (geom_boxplot())\n\nToday, we‚Äôre doing epicurves so we are most interested in learning how to make a bar plot. In our case, we will be using geom_col(). Remember that adding a new layer (in this case a geometry) to our ggplot is as simple as using a +, so we can add bars to the epicurve of hospitalized cases in the following way:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col()\n\n\n\n\n\n\n\n\nBrilliant! That sure looks like an epicurve to me. Though it does look a bit‚Ä¶grey. If we‚Äôd like to update the color of our bars (called the fill), we simply need to add the fill argument to geom_col().\nLet‚Äôs give it a try:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\")\n\n\n\n\n\n\n\n\n\nUpdate your epicurve plot to add bars with the color #E4573.\n\nYour plot should now look like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the {ggplot2} framework, layers must be added to an existing canvas. This means that running geom_col() by itself will not produce any visual output. This, however, makes sense. Continuing with our analogy of ggplots being like paintings, running geom_col() by itself would be like having paint with no canvas to put it on.\n\n\nLooking good. Now it‚Äôs time to make our plot just a bit more informative and just a bit more attractive by adding labels and a nicer theme.\n\n\nAdd Some Labels\nA good plot needs some good labeling; n is hardly an informative axis title. Fortunately, {ggplot2} makes adding labels easy with the function labs(). This function will accept a variety of arguments allowing you to add a variety of label/title elements to your plot, for example:\n\nAxis Titles (x = and y =)\nPlot Title (title =)\nCaption\n\nAs for other layers, we can include a label layer by adding labs() to our current plot with the + sign:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\")\n\n\n\n\n\n\n\n\n\nUpdate your epicurve plot to add some reasonable axis labels and a nice title.  Extra Credit! Try adding a data source using caption.\n\nYour plot might now look like (for example):\n\n\n\n\n\n\n\n\n\n\n\nAdd a Theme\nIf we wanted to, we could stop here if our goal is to produce an informal plot. Ideally, however, it would be nice to use a somewhat more attractive theme and to increase the text size. To do this, we will add one last layer to our plot: a theme layer. Much like how geometries in {ggplot2} all start with geom_, all themes start with theme_. There are several themes available to you and you can check out what they look like on the {ggplot2} website.\nToday, we will use theme_classic(), which offers a simple but elegant output:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nOk, nice. But we‚Äôd also like to increase the size of that tiny font. To do that we can adjust the base_size argument:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\") +\n  theme_classic(base_size = 17)\n\n\n\n\n\n\n\n\nThat looks better! Keep in mind that the font size needed will depend on what the plot is going to be used for (i.e.¬†a presentation, an informal review, or a final report). Similarly, the exact theme you will want to use is ultimately a subjective choice. While there are guidelines, data visualization is as much an art as a science.\n\nAdd one final layer to your plot that adds a theme of your choice with an appropriate base_size.\n\n\n\nSave your plot\nIf you would like to save your epicurve, you can click on the ‚ÄúExport‚Äù button in the plot panel of RStudio:"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#done",
    "href": "sessions_core/06_epicurves.html#done",
    "title": "Basic Data Visualization",
    "section": "Done!",
    "text": "Done!\nVery well done team! You have build your first epicurve!\n\n\n\n Solutions file"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#go-further",
    "href": "sessions_core/06_epicurves.html#go-further",
    "title": "Basic Data Visualization",
    "section": "Go Further",
    "text": "Go Further\n\nExtra Exercises\n\nUse the theme_minimal() on one of your graph, with a base size font of 18.\nGo to this site, pick a color and update the color of your bars.\n\n\n\nChallenge Exercises\n\nInstead of aggregating by date, count the number of patients by sub-prefecture. Try to adapt your epicurve code to create a barplot of the number of patients by sub-prefecture.\n\n\n\nSatellites\n\nWeekly Epicurves\nFaceting"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#resources",
    "href": "sessions_core/06_epicurves.html#resources",
    "title": "Basic Data Visualization",
    "section": "Resources",
    "text": "Resources\n\nA full book on using {ggplot2}\n\nA whole chapter on epicurves"
  },
  {
    "objectID": "sessions_extra/faceting.html",
    "href": "sessions_extra/faceting.html",
    "title": "Faceting",
    "section": "",
    "text": "Learn the syntax to make subplots real quick in {ggplot2}\nLearn arguments to modify the appearance of the subplots"
  },
  {
    "objectID": "sessions_extra/faceting.html#objectives",
    "href": "sessions_extra/faceting.html#objectives",
    "title": "Faceting",
    "section": "",
    "text": "Learn the syntax to make subplots real quick in {ggplot2}\nLearn arguments to modify the appearance of the subplots"
  },
  {
    "objectID": "sessions_extra/faceting.html#introduction",
    "href": "sessions_extra/faceting.html#introduction",
    "title": "Faceting",
    "section": "Introduction",
    "text": "Introduction\nThis satellite builds on the core epicurve session, which is a prerequisite. In that session, we learned how to create an epicurve of measles cases across time:\n\n\n\n\n\n\n\n\n\nNow, this plot is cool, but in your sitrep you would like to show the data by age group. There are several ways to do that:\n\nYou could, for each age group, filter your data frame and copy and paste the plotting command to create specific plots\nYou could learn to use for loops or apply() or map() family functions, which are very useful ways to automatize actions, and involve less copy and pasting\nOr you could trust {ggplot2} to have a solution‚Ä¶\n\nThe first option is tedious and it is error prone, and we advise against it; learning the tools of the second option will be a good investment of you time at some point as they are really powerful, but they are way out of the scope of this tutorial because a much simpler option already exist in {ggplot2}."
  },
  {
    "objectID": "sessions_extra/faceting.html#setup",
    "href": "sessions_extra/faceting.html#setup",
    "title": "Faceting",
    "section": "Setup",
    "text": "Setup\n\nWe will use the same clean linelist that we used in the past sessions, which you can download here:\n\n\n\n Download clean data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called faceting.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_linelist."
  },
  {
    "objectID": "sessions_extra/faceting.html#faceting",
    "href": "sessions_extra/faceting.html#faceting",
    "title": "Faceting",
    "section": "Faceting",
    "text": "Faceting\nThe function facet_wrap() allows you to replicate a graph based on the categories of a variable. For example, you could make the epicurve graph by sex, or by site. As other layers of a ggplot graph, you add it to your existing graph with a +. It creates a a figure with multiple small graphs, that {ggplot2} calls facets or small multiples.\n\nGet the Data Ready\nIn the following session, we will explain the code by creating subplots by sub-prefecture, and you will be plotting the epicurve by age group.\nIf we want to to plot anything by sub-prefecture, the sub_prefecture variable must be present in the aggregated data frame that we use to plot.\nLet‚Äôs create a new summarized dataset that has the number of patients by day and by sub-prefecture!\n\ndf_pref &lt;- df_linelist %&gt;%\n  count(date_onset, sub_prefecture,\n        name = \"patients\")\n\n\n\n  date_onset sub_prefecture patients\n1 2022-08-13       Moissala        1\n2 2022-08-17       Moissala        1\n3 2022-08-18       Moissala        1\n4 2022-08-22       Moissala        1\n5 2022-08-30       Moissala        2\n6 2022-09-01       Moissala        1\n\n\n\nYou will draw a plot of the number of admissions by age group, so you need a new data frame summarized by day and age group. Create this data frame, and call it df_age. It should have this format:\n\n\n  date_onset    age_group n\n1 2022-08-13  1 - 4 years 1\n2 2022-08-17 5 - 14 years 1\n3 2022-08-18   &lt; 6 months 1\n4 2022-08-22 6 - 8 months 1\n5 2022-08-30   &lt; 6 months 1\n6 2022-08-30 6 - 8 months 1\n\n\n\n\n\nAdd the Facet Layer to the Plot\nNow, let‚Äôs plot this data. Look at the code bellow: it is exactly the same as before but for the last line, which creates the facets:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n       title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  facet_wrap(vars(sub_prefecture))   # Make the plot by sub-prefecture!\n\n\n\n\n\n\n\n\nIsn‚Äôt that incredible? As you can see, the function facer_wrap() takes as argument a variable name wrapped in the vars() function.\n\nNow is your turn, draw the epicurve by age group (still keeping all the plots improvement: labels, themes etc.)\nIt should look like this:"
  },
  {
    "objectID": "sessions_extra/faceting.html#customize-facets",
    "href": "sessions_extra/faceting.html#customize-facets",
    "title": "Faceting",
    "section": "Customize Facets",
    "text": "Customize Facets\nCheck out the function help page to learn about the arguments that facet_wrap() accepts. We will cover a couple here.\n\nNumber of Rows or Columns\nThe arguments nrow and ncol allow you to decide how many facets there should be on one row, respectively one column.\nFor exemple, we could have all plots on two rows, for a wide figure:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n        title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sub_prefecture),\n             nrow = 2)  \n\n\n\n\n\n\n\n\nOr force the number of rows to four, which forces a taller figure:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n       title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sub_prefecture),\n             nrow = 4)  \n\n\n\n\n\n\n\n\n\nUsing one of the mentioned argument, create a graph with three columns.\n\n\n\nAxis Ranges\nDid you notice that in the graph we produced, all facets share the same axis in x and y? This is often a desired feature, as playing with axes is one of the best ways to mislead readers.\nThat being said, if you are more interesting in seeing the shape of the epicurve by category and less by comparing categories to each other, zooming on the available data can be appropriate (alert your reader to the scale variation though!)\nThe scales argument accepts the following strings:\n\n\"fixed\": the default, same limits on x and y for all facets\n\"free_x\": the x axis may have different limits in different facets\n\"free_y\": the y axis may have different limits in different facets\n\"free\": both axis may vary in different facets\n\nLook at this graph:\n\n\n\n\n\n\n\n\n\nWe kept time window on the x axis fixed but allowed the y axis to vary to better read the number of cases by sub-prefecture.\n\nYour turn! Draw you graph with age group as facets with a free y axis, and a fixed x axis."
  },
  {
    "objectID": "sessions_extra/faceting.html#done",
    "href": "sessions_extra/faceting.html#done",
    "title": "Faceting",
    "section": "Done!",
    "text": "Done!\nVery well done team! You have learned how to facet plots! This will work not only on bar plots such as epicurves, but also on other types of plots made by {ggplot2}.\nDepending on the size of your graph, the date labels on the x-axis may be a bit messed up, the ones in my examples definitely are. Fear not, this can be controlled and is the object of another satellite!\n\n\n\n Solutions file"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html",
    "href": "sessions_extra/weekly_epicurves.html",
    "title": "Weekly Epicurves",
    "section": "",
    "text": "In the epicurve session you learned how to plot an epicurve of the number of cases per day:\n\n\n\n\n\n\n\n\n\nThis graph is aggregated by day, which is a reasonable level of aggregation if the outbreak is short or if you wish to zoom on a short period. As epidemiologists we however often want to plot data by week.\nIn this tutorial we will learn two ways of aggregating data by week, plot the data and tweak the date labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#objectives",
    "href": "sessions_extra/weekly_epicurves.html#objectives",
    "title": "Weekly Epicurves",
    "section": "",
    "text": "In the epicurve session you learned how to plot an epicurve of the number of cases per day:\n\n\n\n\n\n\n\n\n\nThis graph is aggregated by day, which is a reasonable level of aggregation if the outbreak is short or if you wish to zoom on a short period. As epidemiologists we however often want to plot data by week.\nIn this tutorial we will learn two ways of aggregating data by week, plot the data and tweak the date labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#setup",
    "href": "sessions_extra/weekly_epicurves.html#setup",
    "title": "Weekly Epicurves",
    "section": "Setup",
    "text": "Setup\nWe will build on code from the epicurve session so you may either write your code in the script associated with that session or create a new script.\n\nCreate a new script for this tutorial or open the script from the epicurve lesson.\n Make sure the following packages are installed and loaded:\n\n{here} to write robust absolute paths,\n{rio} to import the data,\n{dplyr} to manipulate data,\n{ggplot2} to create the graphs,\n{lubridate} to manage dates and times\n{scales} to create prettier labels\n\nIf it is not already done, import the clean data (moissala_linelist_clean_EN.rds) into a df_linelist data frame and create a new section in your script called PREPARE DATA.\n\nAs we did in the core session, the examples in this lesson will be shown for outcomes and you will code the classic epicurve for date of onset in the exercises."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#aggregate-data-by-week",
    "href": "sessions_extra/weekly_epicurves.html#aggregate-data-by-week",
    "title": "Weekly Epicurves",
    "section": "Aggregate Data by Week",
    "text": "Aggregate Data by Week\nWe will to discuss two ways of aggregating data by weeks. You may be more familiar with the first one (using week numbers to identify weeks), but we will to focus more heavily on a more robust way (using the firs day of the week to identify weeks).\n\nUsing Week Numbers\nProbably the most intuitive way of thinking of weekly aggregated data is to think in terms of week numbers, as aggregated data from MoH are often in this format, and you probably created a lot of epicurves with week numbers yourselves.\nTheisoweek() from the {lubridate} packages takes a date (or a vector of dates) and returns the associated ISO week.\n\nexample_date &lt;- as.Date('2025-02-24')\n\nexample_date\n\n[1] \"2025-02-24\"\n\nisoweek(example_date)\n\n[1] 9\n\n\nWe can use this function to create a week_outcome_number in our data frame:\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(week_outcome_number = isoweek(date_outcome))\n\nThe head of the date_outcome and week_outcome_number columns looks like this:\n\n\n  date_outcome week_outcome_number\n1   2022-08-18                  33\n2   2022-08-28                  34\n3   2022-09-03                  35\n4   2022-09-12                  37\n5   2022-09-10                  36\n6   2022-09-18                  37\n\n\n\nYour turn. Use the mutate() and isoweek() functions to create a new column in your data frame called week_onset_number that contains the ISO week associated with every onset date. The head of date_onset and week_onset_number columns should look like this:\n\n\n  date_onset week_onset_number\n1 2022-08-13                32\n2 2022-08-18                33\n3 2022-08-17                33\n4 2022-08-22                34\n5 2022-08-30                35\n6 2022-08-30                35\n\n\n\nNow, you could use this column to aggregate data by week using count() and then plot the weekly aggregated data using {ggplot2} with a code very similar to what we saw in the core epicurve session.\nThere is a problem, though. With isoweek() there is a first week in 2022, but also in 2023, 2024 and so on. With a short outbreak that would be only in 2022, this would be fine. However, our data frame gathers data at the whole region scale, and the dates range from 2022 to 2023. So if we were to just count the number of patients by week number, this table would be wrong:\n\n# WRONG\ndf_linelist |&gt; \n  count(week_onset_number) |&gt; \n  head(10)\n\n   week_onset_number  n\n1                  1 36\n2                  2 35\n3                  3 42\n4                  4 56\n5                  5 70\n6                  6 78\n7                  7 85\n8                  8 49\n9                  9 62\n10                10 81\n\n\nInstead, we could count by week stratified by years:\n\ndf_linelist |&gt; \n  mutate(year_onset = isoyear(date_onset)) |&gt; \n  count(year_onset, week_onset_number) |&gt; \n  head(10)\n\n   year_onset week_onset_number  n\n1        2022                32  1\n2        2022                33  2\n3        2022                34  1\n4        2022                35  8\n5        2022                36  8\n6        2022                37 10\n7        2022                38 17\n8        2022                39 17\n9        2022                40 19\n10       2022                41 16\n\n\nThese counts are perfectly correct. You could plot them using faceting by year, or just filter a given year and plot the weekly numbers with the ISO week number on the x-axis. For example:\n\ndf_linelist |&gt; \n  mutate(year_onset = isoyear(date_onset)) |&gt; \n  count(year_onset, week_onset_number) |&gt; \n  ggplot(aes(x = week_onset_number,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  theme_classic(base_size = 16) +\n  facet_wrap(vars(year_onset),  # Magic to make subplots very easily\n             ncol = 1)\n\n\n\n\n\n\n\n\nIf you have not read about facetting yet, do no worry, think of this plot as a teaser of how easily you can make subplots by a variable! But this is out of the scope of this tutorial. Instead, we will show you another way of aggregating data by week which is robust to multi-year data.\n\n\nUsing the First Day of the Week\nAn alternative way of aggregating by week is to use the function floor_date() (also from the {lubridate} package), which returns the first date of a given period. You can think of it as a sort of rounding to the smallest value, but for dates.\nThe function has a unit argument that allows you to choose the period of interest (week, month‚Ä¶) and a week_start argument where you can pass the first day of the week (Mondays are 1).\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(\n    week_outcome_monday = floor_date(date_outcome,\n                                     unit = \"week\",\n                                     week_start = 1)\n  )\n\nLet‚Äôs look at all these different time variables to figure out what‚Äôs happening:\n\ndf_linelist |&gt; \n  select(id, date_outcome, week_outcome_number, week_outcome_monday) |&gt;\n  arrange(date_outcome) |&gt;     # Sort the data by date\n  head(n = 10)\n\n   id date_outcome week_outcome_number week_outcome_monday\n1   1   2022-08-18                  33          2022-08-15\n2   2   2022-08-28                  34          2022-08-22\n3  10   2022-09-03                  35          2022-08-29\n4  16   2022-09-10                  36          2022-09-05\n5  22   2022-09-12                  37          2022-09-12\n6  14   2022-09-12                  37          2022-09-12\n7  41   2022-09-16                  37          2022-09-12\n8  20   2022-09-17                  37          2022-09-12\n9  17   2022-09-18                  37          2022-09-12\n10 23   2022-09-19                  38          2022-09-19\n\n\nIt might be easier to visualize if we calculate the day of the week associated with each date using the function wday() (which also belong to the {lubridate} package, are you maybe seeing a pattern here üòâ):\n\ndf_linelist |&gt; \n  # Get the name of the day for several date variables, to understand a bit better\n  mutate(\n    day_outcome = wday(date_outcome, \n                       label = TRUE, \n                       abbr = FALSE),\n    they_are_mondays   = wday(week_outcome_monday, \n                           label = TRUE, \n                           abbr = FALSE)) |&gt; \n  arrange(date_outcome) |&gt;     # Sort the data by date\n  select(date_outcome,\n         day_outcome,\n         week_outcome_number,\n         week_outcome_monday,\n         they_are_mondays) |&gt; \n  head(n = 10)\n\n   date_outcome day_outcome week_outcome_number week_outcome_monday\n1    2022-08-18       jeudi                  33          2022-08-15\n2    2022-08-28    dimanche                  34          2022-08-22\n3    2022-09-03      samedi                  35          2022-08-29\n4    2022-09-10      samedi                  36          2022-09-05\n5    2022-09-12       lundi                  37          2022-09-12\n6    2022-09-12       lundi                  37          2022-09-12\n7    2022-09-16    vendredi                  37          2022-09-12\n8    2022-09-17      samedi                  37          2022-09-12\n9    2022-09-18    dimanche                  37          2022-09-12\n10   2022-09-19       lundi                  38          2022-09-19\n   they_are_mondays\n1             lundi\n2             lundi\n3             lundi\n4             lundi\n5             lundi\n6             lundi\n7             lundi\n8             lundi\n9             lundi\n10            lundi\n\n\nThis illustrates how week_outcome_number and week_outcome_monday are two ways to have only one value representing a week. While week numbers are not unique as discussed before, dates are!\n\nAdd a new command to your mutate() call and create the variable week_onset_monday that contains the first day of the week for patient date of onset. Choose your argument as if the first day of the week is a Monday.\n\n\n\n\n\n\n\nTip\n\n\n\nGo read the help page for floor_date() to check out the list of possible units.\n\n\n\n\nActually Count Things\nNow that we have variables that represent week, it‚Äôs time to do the actual aggregation, ie count things!\n\nCount the number of patients per week of of onset, using the week start (week_onset_monday).\nHere are the first ten lines of what it should look like:\n\n\n   week_onset_monday  n\n1         2022-08-08  1\n2         2022-08-15  2\n3         2022-08-22  1\n4         2022-08-29  8\n5         2022-09-05  8\n6         2022-09-12 10\n7         2022-09-19 17\n8         2022-09-26 17\n9         2022-10-03 19\n10        2022-10-10 16"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#draw-the-epicurve",
    "href": "sessions_extra/weekly_epicurves.html#draw-the-epicurve",
    "title": "Weekly Epicurves",
    "section": "Draw the Epicurve",
    "text": "Draw the Epicurve\nSo far so good, now we can pipe that aggregated data frame into our plot commands, making a couple adjustments to make it work.\n\nCreate a ggplot with the same look at the epicurve from the epicurve core session, but with the first day of the week on the x-axis. Don‚Äôt forget to update axes names.\n\nIt should look like that:\n\n\n\n\n\n\n\n\n\nWe see dates on the x-axis, but a bar represent data for a week starting on Monday."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#improve-the-axis",
    "href": "sessions_extra/weekly_epicurves.html#improve-the-axis",
    "title": "Weekly Epicurves",
    "section": "Improve the Axis",
    "text": "Improve the Axis\nNow, let‚Äôs learn how to tweak the appearance of that date axis!\n{ggplot2} automatically provided labels for the x-axis, trying to adjust for the range of data. That default may not always please us so we may want to manually force the labels to be more or less frequent, or change their format.\nTo modify the appearance of the axis, we will use another {ggplot2} function, from the scale family: scale_x_date().\n\nModify Breaks\nThe breaks controls the frequency of ticks on the axis.\nThe scale_x_date() function has a date_breaks argument that accepts the interval between two labels in a string. The string can have the following format: \"1 week\", \"2 weeks\", \"4 months\", \"2 years\" etc.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles cases\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(date_breaks = \"4 months\") +  # Define breaks\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nYour turn! Modify your code so that the x-axis displays labels at reasonable intervals on your screen.\n\n\n\nImprove Labels\nNow that we changed the interval between ticks, let‚Äôs improve the labels themselves (the way dates are displayed on the axis). By default the labels are in the form year-month-day. We are going to show you two ways to change that.\n\nWith the {scales} Package.With the strptime Syntax\n\n\nThe scale_x_date() function has a label argument, that accepts several entries, among which a vector containing the dates, but also a function that generates labels from the breaks. The {scales} package provides such a function, label_date_short(), that attempts to create efficient and short labels for dates.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles outcomes\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(date_breaks = \"2 months\",\n               labels = scales::label_date_short()) + # Short labels\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModify your code and use label_date_short() to generate labels.\n\n\n\nIf you prefer to have full control on how to format dates, R has a syntax to describe date and time formats. There is a long help page with all the syntax items accessible with the help(strptime) command, but here are a few of the most useful elements to format a date label:\nDay:\n\n%d: from 01 to 31\n%e: from 1 to 31\n\nMonth:\n\n%b: abbreviated month name (current locale on your computer)\n%B: full month name (current locale on your computer)\n%m: month as a decimal number\n\nYear:\n\n%y: Year without the century (two digits)\n%Y: year in four digits\n\nSpecial separators:\n\n%n: newline\n%t: tab\n\nYou can assemble these items in a string, that you pass to different functions that accept a format as argument. Here we will pass it to the format() function to quickly see what display it creates, but after that we will use them in our graph command.\n\n# Create a date vector to explore different formats\nsome_dates &lt;- as.Date(c(\"2024-10-06\", \"2024-12-15\", \"2025-01-20\"))\n\n# Let's try out different syntax\nformat(some_dates, \"%Y-%b-%d\")\n\n[1] \"2024-oct.-06\"  \"2024-d√©c.-15\"  \"2025-janv.-20\"\n\nformat(some_dates, \"%Y-%b\")\n\n[1] \"2024-oct.\"  \"2024-d√©c.\"  \"2025-janv.\"\n\nformat(some_dates, \"%Y %B %d\")\n\n[1] \"2024 octobre 06\"  \"2024 d√©cembre 15\" \"2025 janvier 20\" \n\nformat(some_dates, \"%y/%m/%d\")\n\n[1] \"24/10/06\" \"24/12/15\" \"25/01/20\"\n\nformat(some_dates, \"%d/%m/%Y\")\n\n[1] \"06/10/2024\" \"15/12/2024\" \"20/01/2025\"\n\n\nBack to the graph! The scale_x_date() function has an argument date_labels that accepts a string of text in the above format for the date labels.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles cases\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(\n    date_breaks = \"2 months\",      # Define intervals betw. labels\n    date_labels = \"%Y%n%b%n%d\") +  # Define format of labels\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModify the code of your graph to have labels look like this:"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#done",
    "href": "sessions_extra/weekly_epicurves.html#done",
    "title": "Weekly Epicurves",
    "section": "Done!",
    "text": "Done!\nCongratulations! Dates are complicated, and their formatting is often scary, but we hope this little introduction showed you some nice tricks for your epicurves!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#going-further",
    "href": "sessions_extra/weekly_epicurves.html#going-further",
    "title": "Weekly Epicurves",
    "section": "Going Further",
    "text": "Going Further\n\nExtra execices\n\nUse date format like this: ‚Äú2024-oct.‚Äù, ‚Äú2024-dec.‚Äù\nCreate an epicurve with the date of consultation, using the first day of the week on the x-axis (format dates the way you prefer)\nCreate an epicurve for 2023 data using the date of hospital admission and the ISO week number on the x-axis.\n\n\n\nChallenge\n\nDo the epicurve for the date of onset, but instead of aggregating by week, aggregate it by month. Find an appropriate format for the labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#resources",
    "href": "sessions_extra/weekly_epicurves.html#resources",
    "title": "Weekly Epicurves",
    "section": "Resources",
    "text": "Resources\n\nChapter of the Elegant graphics for data analyses book on date scales\nGet started with lubridate from the package homepage."
  }
]