[
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "Session Title",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "template.html#objectives",
    "href": "template.html#objectives",
    "title": "Session Title",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "template.html#setup",
    "href": "template.html#setup",
    "title": "Session Title",
    "section": "Setup",
    "text": "Setup\n\nDescription of something participants need to setup, primarily used at the beginning of a section but can also be used for tasks like setting up an Rproject file, folder structure, etc."
  },
  {
    "objectID": "template.html#main-section-1",
    "href": "template.html#main-section-1",
    "title": "Session Title",
    "section": "Main Section 1",
    "text": "Main Section 1\nYour main section(s) can (and probably should) be boken down into subsections.\n\nSubsection 1\n\n\nSubsection 2"
  },
  {
    "objectID": "template.html#done",
    "href": "template.html#done",
    "title": "Session Title",
    "section": "Done!",
    "text": "Done!\nThis last header let’s students know that they are done with the main material for the day. It should also include a link to the solutions (hosted on github). For example:\n\n\n\n Solution File\n\n\n\nMake sure this link references the main."
  },
  {
    "objectID": "template.html#going-further",
    "href": "template.html#going-further",
    "title": "Session Title",
    "section": "Going Further",
    "text": "Going Further\nAfter your main content is done you should have a section called called “Going Further” for students who finish the main content early. It should include: 1. A mention of one or two satellite sessions that would be relevant extensions of the current material 2. A section with “extra exercise questions” (these don’t need to use the “action blocks” (see below) and can just be a number list as shown below.\n\nExtra Exercises\n\nDo this.\nThen do that."
  },
  {
    "objectID": "template.html#markdown-reminders",
    "href": "template.html#markdown-reminders",
    "title": "Session Title",
    "section": "Markdown Reminders",
    "text": "Markdown Reminders\nThe rest of this document is a reminder on qmd syntax and a basic style guide. Enjoy.\n\nText Formatting\n\nItalic and Bold will turn out like this\nBlock quotes will look like this:\n\n\nThis is a blockquote made using &gt;\n\n\nTooltips can be done using spans (please do not use asides or footnotes)\n\n\n\nCode\nInline coding will turn out like this\nCode blocks will appear like this:\n\n# comment\nprint('hello world')\n\nWarning: For these tutorials, code blocks are not evaluated by default. If you want to evaluate them, you must indicate it specifically.\n\n# comment\nprint('hello back!')\n\n[1] \"hello back!\"\n\ntest &lt;- function(x) {\n  if (x &gt; 1) {\n    return(x)\n  } else {\n    print('nothing to see here')\n  }\n}\n\nNote. We are no longer using solution blocks, instead a single code file will be available at the end of each session contiaining code that runs through all the exercises.\n\n\nCallouts\nIMPORTANT: please do not use callouts not explicitly defined here; they have not been included in the css and therefore will not render well in the final document.\n\n\n\n\n\n\nNote\n\n\n\nThis is a callout using {.callout-note}\n\n\n\n\n\n\n\n\nTip\n\n\n\nComment about a genral tip / trick or best practice.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWarning / comment on something really important.\n\n\n\n\nAction Boxes\nThese are used for things participants are expected to actually do, ie: exercises. They are split into three categories.\n\nDescription of something participants need to setup, primarily used at the beginning of a section but can also be used for tasks like setting up an Rproject file, folder structure, etc.\n\n\nDescription of something participants should observe, investigate, etc.\n\n\nDescription of a coding exercise that participants are expected to complete.\n\n\n\nTabsets\n\nOneTwoThree\n\n\nContent that will show under the first tab\n\n\nContent that will show under the second tab\n\n\nContent that will show under the third tab\n\n\n\n\n\nImages\nYou can insert images by referring to their relative path using markdown syntax or HTML. Note that the markdown syntax does not allow you to modify image size. In either case, make sure to add alt text for accessibility.\nMarkdown style syntax:\n\n\n\nexample image alt text\n\n\nHTML style syntax (with specification of desired size):\n\n\n\nLinking to Other Pages\nEasy, use relative paths within a standard href, ie: link to home page."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html",
    "href": "sessions_extra/weekly_epicurves.fr.html",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "",
    "text": "Dans la session principale sur les grapiques, vous avez appris à tracer une courbe épidémique du nombre de cas journaliers :\n\n\n\n\n\n\n\n\n\nIci les données sont agrégées par jour, ce qui raisonnable si l’épidémie est de courte durée ou si vous souhaitez zoomer sur une période spécifique. Il nous arrivera néanmoins de souvent vouloir tracer des courbes hebdomadaires.\nDans cette tutoriel, nous apprendrons à agréger les données par semaine, à tracer le graphique et à améliorer les étiquettes de l’axe des abscisses.\nPrérequis : la session sur les courbes épidémiques."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#objectifs",
    "href": "sessions_extra/weekly_epicurves.fr.html#objectifs",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "",
    "text": "Dans la session principale sur les grapiques, vous avez appris à tracer une courbe épidémique du nombre de cas journaliers :\n\n\n\n\n\n\n\n\n\nIci les données sont agrégées par jour, ce qui raisonnable si l’épidémie est de courte durée ou si vous souhaitez zoomer sur une période spécifique. Il nous arrivera néanmoins de souvent vouloir tracer des courbes hebdomadaires.\nDans cette tutoriel, nous apprendrons à agréger les données par semaine, à tracer le graphique et à améliorer les étiquettes de l’axe des abscisses.\nPrérequis : la session sur les courbes épidémiques."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#mise-en-place",
    "href": "sessions_extra/weekly_epicurves.fr.html#mise-en-place",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Mise en place",
    "text": "Mise en place\n\nNous utiliserons la même liste linéaire nettoyée que précédemment et qui peut être téléchargée ici :\n\n\n\n Télécharger les données\n\n\n\n Si ce n’est pas déjà fait, enregistrez le jeu de données dans data/clean puis créez un nouveau script appelé courbe_hebdo.R dans votre sous-dossier R (alternativement, vous pouvez rajouter une section au script sur les courbes épidémiques journalières).\n Si vous créez un nouveau script, ajoutez un en-tête approprié et chargez les paquets suivants : {here}, {rio}, {tidyverse} et {scales}. Importez ensuite les données propres (moissala_linelist_clean_FR.rds) dans R et enregistrez-les dans un objet df_linelist.\n\nAu cours du tutoriel, les exemples porteront sur les sorties et vous tracerez la courbe épidémique à partir de la date de début des symptômes."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#données-hebdomadaires",
    "href": "sessions_extra/weekly_epicurves.fr.html#données-hebdomadaires",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Données hebdomadaires",
    "text": "Données hebdomadaires\nNous allons aborder deux façons d’agréger les données par semaine. Le concept de la première vous sera sans doute familier (semaines identifiées par leur numéros), mais nous nous concentrerons sur une méthode plus robuste (semaine identifiées par la date du premier jour de la semaine).\n\nNuméros de semaine\nLa manière la plus intuitive de d’agréger par semaine est d’utiliser des numéros de semaines, car les données du MSP sont souvent dans ce format. Vous avez sans doute créé de nombreuses courbes épidémiques dans ce format vous-mêmes.\nLa fonction isoweek() du paquet {lubridate} accepte une date (ou un vecteur de dates) et renvoie le numéro de semaine ISO.\n\nexemple_date &lt;- as.Date('2025-02-24')\n\nexemple_date\n\n[1] \"2025-02-24\"\n\nisoweek(exemple_date)\n\n[1] 9\n\n\nNous pouvons utiliser cette fonction pour créer une colonne sem_sortie_num dans nos données :\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(sem_sortie_num = isoweek(date_sortie))\n\nLe début des colonnes date_sortie et sem_sortie_num ressemble à ceci (sans les NA) :\n\ndf_linelist |&gt; \n  tidyr::drop_na(date_sortie) |&gt; \n  select(date_sortie, sem_sortie_num) |&gt; \n  head()\n\n  date_sortie sem_sortie_num\n1  2022-08-18             33\n2  2022-08-28             34\n3  2022-09-03             35\n4  2022-09-12             37\n5  2022-09-10             36\n6  2022-09-18             37\n\n\n\nA vous de jouer. Utilisez les fonctions mutate() et isoweek() pour créer une nouvelle colonne dans votre data frame appelée sem_symptomes_num qui contient la semaine ISO associée à chaque date de début des symptômes. L’en-tête des colonnes date_debut et sem_symptomes_num devrait ressembler à ceci :\n\n\n  date_debut sem_symptomes_num\n1 2022-08-13                32\n2 2022-08-18                33\n3 2022-08-17                33\n4 2022-08-22                34\n5 2022-08-30                35\n6 2022-08-30                35\n\n\n\nNous pourrions maintenant utiliser count() sur cette colonne pour agréger les données par semaine, puis tracer le graphique avec {ggplot2} avec un code très similaire à la session principale.\nMalheureusement il y a un problème. Avec le numéro de semaine il y a une première semaine en 2022… mais aussi en 2023, 2024 etc. Dans le cas d’une épidémie courte qui n’aurait lieu qu’en 2022, cela ne poserait pas problème. Cependant, notre data frame contient des données de la région entière, et les dates s’étendent de 2022 à 2023. Donc si nous comptions le nombre de patient par numéro de semaine, le tableau suivant serait erroné :\n\n# FAUX\ndf_linelist |&gt; \n  count(sem_symptomes_num) |&gt; \n  head(10)\n\n   sem_symptomes_num  n\n1                  1 36\n2                  2 35\n3                  3 42\n4                  4 56\n5                  5 70\n6                  6 78\n7                  7 85\n8                  8 49\n9                  9 62\n10                10 81\n\n\nPour résoudre le problème nous pouvons stratifier par année :\n\ndf_linelist |&gt; \n  mutate(annee_symptomes = isoyear(date_debut)) |&gt; \n  count(annee_symptomes, sem_symptomes_num) |&gt; \n  head(10)\n\n   annee_symptomes sem_symptomes_num  n\n1             2022                32  1\n2             2022                33  2\n3             2022                34  1\n4             2022                35  8\n5             2022                36  8\n6             2022                37 10\n7             2022                38 17\n8             2022                39 17\n9             2022                40 19\n10            2022                41 16\n\n\nCes chiffres sont désormais corrects. Vous pourriez les représenter avec plusieurs mini graphes par année sur une même figure, ou simplement filtrer une année donnée et tracer la courbe avec les numéros de semaines sur l’axe des x. Dans le premier cas, cela donnerait ceci :\n\ndf_linelist |&gt; \n  mutate(annee_symptomes = isoyear(date_debut)) |&gt; \n  count(annee_symptomes, sem_symptomes_num) |&gt; \n  ggplot(aes(x = sem_symptomes_num,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  theme_classic(base_size = 16) +\n  facet_wrap(vars(annee_symptomes),  # Magie pour faire le graphe par année !\n             ncol = 1)\n\n\n\n\n\n\n\n\nSi vous n’avez pas lu le satellite sur facet_wrap(), ce n’est pas grave, voyez ce graphe comme une page de publicité pour la capacité de ggplot à faire des graphes multiples rapidement. Les explications sortent du cadre de ce tutoriel et nous allons vous montrer une autre façon d’agréger les données par semaine, qui est robuste aux données pluriannuelles.\n\n\nPremier jour de la semaine\nUne autre manière d’agréger par semaine est d’utiliser la fonction floor_date() (également du package {lubridate}), qui renvoie la première date d’une période donnée. Vous pouvez la considérer comme une sorte d’arrondi à la plus petite valeur, mais pour les dates.\nLa fonction a un argument unit pour choisir l’échelle de la période (semaine, mois…) et un argument week_start pour définir le premier jour de la semaine (les lundis sont 1).\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(\n    sem_sortie_lundi = floor_date(date_sortie,\n                                  unit = \"week\",\n                                  week_start = 1)\n  )\n\nRegardons les différentes colonnes de plus près pour bien comprendre :\n\ndf_linelist |&gt; \n  select(date_sortie, sem_sortie_num, sem_sortie_lundi) |&gt;\n  arrange(date_sortie) |&gt;     # Trie par date\n  head(n = 10)\n\n   date_sortie sem_sortie_num sem_sortie_lundi\n1   2022-08-18             33       2022-08-15\n2   2022-08-28             34       2022-08-22\n3   2022-09-03             35       2022-08-29\n4   2022-09-10             36       2022-09-05\n5   2022-09-12             37       2022-09-12\n6   2022-09-12             37       2022-09-12\n7   2022-09-16             37       2022-09-12\n8   2022-09-17             37       2022-09-12\n9   2022-09-18             37       2022-09-12\n10  2022-09-19             38       2022-09-19\n\n\nPour aider à comprendre on peut calculer le jour de la semaine associé à chaque date en utilisant la fonction wday() (qui appartient aussi à {lubridate}, y a comme un thème 😉) [wday est une abréviation pour week day] :\n\ndf_linelist |&gt; \n  # Calcule le premier jour de la semaine\n  mutate(\n    jour_sortie = wday(date_sortie, \n                       label = TRUE, \n                       abbr = FALSE),\n    cest_bien_un_lundi  = wday(sem_sortie_lundi, \n                               label = TRUE, \n                               abbr = FALSE)) |&gt; \n  arrange(date_sortie) |&gt;      # Trie par date\n  select(date_sortie,\n         jour_sortie,\n         sem_sortie_num,\n         sem_sortie_lundi,\n         cest_bien_un_lundi) |&gt; \n  head(n = 10)\n\n   date_sortie jour_sortie sem_sortie_num sem_sortie_lundi cest_bien_un_lundi\n1   2022-08-18       jeudi             33       2022-08-15              lundi\n2   2022-08-28    dimanche             34       2022-08-22              lundi\n3   2022-09-03      samedi             35       2022-08-29              lundi\n4   2022-09-10      samedi             36       2022-09-05              lundi\n5   2022-09-12       lundi             37       2022-09-12              lundi\n6   2022-09-12       lundi             37       2022-09-12              lundi\n7   2022-09-16    vendredi             37       2022-09-12              lundi\n8   2022-09-17      samedi             37       2022-09-12              lundi\n9   2022-09-18    dimanche             37       2022-09-12              lundi\n10  2022-09-19       lundi             38       2022-09-19              lundi\n\n\nCeci illustre comment sem_sortie_num et sem_sortie_lundi sont deux façons de représenter une semaine donnée. Mais si les numéros de semaine ne sont pas uniques, les dates, elles, le sont !\n\nAjoutez une nouvelle instruction à votre mutate() pour créer la variable sem_symptomes_lundi qui contient le premier jour de la semaine pour la date d’apparition des symptômes. Le premier jour de la semaine est un lundi au Tchad.\n\n\n\n\n\n\n\nTip\n\n\n\nLisez la page d’aide de floor_date() pour connaître la liste des unités possibles.\n\n\n\n\nAgréger\nMaintenant que nous avons une variables qui identifie la semaine, nous pouvons enfin agréger nos données !\n\nComptez le nombre de patients par semaine de début des symptômes, en utilisant le début de la semaine pour identifier les semaines (sem_symptomes_lundi).\nVoici les dix premières lignes de ce à quoi il devrait ressembler :\n\n\n   sem_symptomes_lundi  n\n1           2022-08-08  1\n2           2022-08-15  2\n3           2022-08-22  1\n4           2022-08-29  8\n5           2022-09-05  8\n6           2022-09-12 10\n7           2022-09-19 17\n8           2022-09-26 17\n9           2022-10-03 19\n10          2022-10-10 16"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#tracer-le-graphique",
    "href": "sessions_extra/weekly_epicurves.fr.html#tracer-le-graphique",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Tracer le graphique",
    "text": "Tracer le graphique\nParfait. Nous pouvons maintenant passer nos données agrégées à la commande pour créer le graphique, en faisant quelques ajustements pour que le code précédent fonctionne.\n\nCréez un ggplot avec le même aspect que la courbé épidémique de la session principale, mais avec le premier jour de la semaine sur l’axe des abscisses. N’oubliez pas de mettre à jour les noms des axes !\nIl devrait ressembler à ceci :\n\n\n\n\n\n\n\n\n\n\nNotez que même si les étiquettes sur l’axe des abscisses sont des dates, une barre représente les données d’une semaine (sept jours à compter du lundi)."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#améliorer-laxe",
    "href": "sessions_extra/weekly_epicurves.fr.html#améliorer-laxe",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Améliorer l’axe",
    "text": "Améliorer l’axe\nIl est maintenant temps d’améliorer cet axe des abscisses.\n{ggplot2} crée automatiquement des étiquettes pour l’axe des x, en essayant de s’adapter à l’étendue des données. Ces valeurs par défaut ne nous conviennent pas toujours, et nous voulons pouvoir manuellement changer les étiquettes (plus fréquentes ou plus espacées, améliorer le format etc.).\nPour modifier l’apparence de l’axe, nous allons utiliser une fonction de la famille scale de {ggplot2} : scale_x_date() [scale ici est l’échelle].\n\nModifier la fréquence des tirets\nDans {ggplot2}, les breaks [cassures] contrôlent la fréquence des tirets sur l’axe.\nLa fonction scale_x_date() a un argument date_breaks qui accepte l’intervalle entre deux étiquettes dans une chaîne de caractères aux formats suivants : \"1 week\", \"2 weeks\", \"4 months\", \"2 years\", etc.\n\ndf_linelist |&gt; \n  count(sem_sortie_lundi) |&gt; \n  ggplot(aes(x = sem_sortie_lundi,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date de sortie\",\n       y = \"Patients\",\n       title = \"Sorties rougeole dans la région de Mandoul (Tchad)\") +\n  scale_x_date(date_breaks = \"4 months\") +  # Définit l'intervalle entre étiquettes\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModifiez votre code pour que la fréquence des tirets les rendent lisibles sur votre moniteur.\n\n\n\nAméliorer les étiquettes\nMaintenant que nous avons géré l’intervalle entre les tirets, nous pouvons modifier les étiquettes elles-mêmes (la façon dont les dates sont affichées sur l’axe, labels en anglais). Par défaut, elles sont sous la forme année-mois-jour. Nous allons voir deux manières de changer ça\n\nAvec le paquet {scales}Avec la syntaxe strptime\n\n\nLa fonction scale_x_date() a un argument label qui accepte plusieurs types d’entrées, telles qu’un vecteur contenant les dates ou une fonction qui génère des labels. Le paquet {scales} fournit une telle fonction, label_date_short(), qui tente de créer des étiquettes de dates efficaces et courtes.\n\ndf_linelist |&gt; \n  count(sem_sortie_lundi) |&gt; \n  ggplot(aes(x = sem_sortie_lundi,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date de sortie\",\n       y = \"Patients\",\n       title = \"Sorties rougeole dans la région de Mandoul (Tchad)\") +\n  scale_x_date(date_breaks = \"2 months\",\n               labels = scales::label_date_short()) + # Etiquettes courtes\n  theme_classic(base_size = 15)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModifiez votre code et usez label_date_short() pour créer des étiquettes courtes.\n\n\n\nL’automatisation c’est sympa, mais si vous préférez avoir le contrôle total, R dispose d’une syntaxe pour décrire les formats de date et d’heure. Il existe une longue page d’aide (accessibles avec la commande help(strptime)) avec tous les éléments de syntaxe, mais voici un résumé des éléments les plus utiles pour décrire le format d’une date :\nNuméro du jour :\n\n%d: de 01 à 31\n%e: de 1 à 31\n\nMois :\n\n%b : nom du mois, forme abréviée (la langue dépend de la locale de votre ordinateur)\n%B : nom du mois, complet (la langue dépend de la locale de votre ordinateur)\n%m : Numéro du mois\n\nAnnée :\n\n%y : année à deux chiffres (sans le siècle)\n%Y : année à quatre chiffres\n\nSéparateurs spéciaux :\n\n%n : nouvelle ligne\n%t : tab\n\nVous pouvez assembler ces éléments dans une chaîne de caractères, que vous passez à différentes fonctions qui acceptent un format comme argument.\nNous allons d’abord utiliser la fonction format() pour voir rapidement l’affichage qu’elle crée à partir d’une syntaxe strptime, puis nous illustrerons l’usage dans un graphe.\n\n# Crée un vecteur de dates pour explorer des formats différents\nquelques_dates &lt;- as.Date(c(\"2024-10-06\", \"2024-12-15\", \"2025-01-20\"))\n\n# Exemples de syntaxes possibles\nformat(quelques_dates, \"%Y-%b-%d\")\n\n[1] \"2024-oct.-06\"  \"2024-déc.-15\"  \"2025-janv.-20\"\n\nformat(quelques_dates, \"%Y-%b\")\n\n[1] \"2024-oct.\"  \"2024-déc.\"  \"2025-janv.\"\n\nformat(quelques_dates, \"%Y %B %d\")\n\n[1] \"2024 octobre 06\"  \"2024 décembre 15\" \"2025 janvier 20\" \n\nformat(quelques_dates, \"%y/%m/%d\")\n\n[1] \"24/10/06\" \"24/12/15\" \"25/01/20\"\n\nformat(quelques_dates, \"%d/%m/%Y\")\n\n[1] \"06/10/2024\" \"15/12/2024\" \"20/01/2025\"\n\n\nRevenons à notre graphe. La fonction scale_x_date() a un argument date_labels qui accepte une chaîne de caractère dans le format strptime pour formater les étiquettes de dates.\n\ndf_linelist |&gt; \n  count(sem_sortie_lundi) |&gt; \n  ggplot(aes(x = sem_sortie_lundi,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date de sortie\",\n       y = \"Patients\",\n       title = \"Sorties rougeole dans la région de Mandoul (Tchad)\") +\n  scale_x_date(\n    date_breaks = \"2 months\",      # Définit l'intervalle entre étiquettes\n    date_labels = \"%Y%n%b%n%d\") +  # Definit le format des étiquettes\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModifiez votre graphe pour que les étiquettes soient comme ceci :\n\n\n\n\n\n\n\n\n\n\n\nC’est fini !\nBravo ! Les dates dans R sont un sujet compliqué, et leur format est souvent un peu effrayant. Nous espérons que cette petite introduction vous aura donné quelques astuces pour que vos courbes épidémiques soient lisibles.\n\n\n\n Solutions\n\n\n\n\n\nAller plus loin\n\nExercices supplémentaires\n\nUtilisez ce format dans cotre graphe : “2024-oct.”, “2024-dec.”\nCréez une courbe épidémique avec la date de consultation, avec le premier jour de la semaine sur l’axe des x (vous êtes libres du format de la date).\nCréez une courbe épidémique pour l’année 2023 qui montre le nombre d’admissions hospitalières hebdomadaires, avec le numéro ISO de la semaine en abscisse.\n\n\n\nDéfi\n\nTracez une courbe épidémique de la date d’apparition des symptômes par mois. Utilisez un format d’étiquette qui vous semble approprié et lisible.\n\n\n\n\nRessources\n\nLe chapitre (en anglais) “Elegant graphics for data analyses’ book on date scales\nLa page d’aide de lubridate"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#cest-fini",
    "href": "sessions_extra/weekly_epicurves.fr.html#cest-fini",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "C’est fini !",
    "text": "C’est fini !\nBravo ! Les dates dans R sont un sujet compliqué, et leur format est souvent un peu effrayant. Nous espérons que cette petite introduction vous aura donné quelques astuces pour que vos courbes épidémiques soient lisibles.\n\n\n\n Solutions"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#aller-plus-loin",
    "href": "sessions_extra/weekly_epicurves.fr.html#aller-plus-loin",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Aller plus loin",
    "text": "Aller plus loin\n\nExercices supplémentaires\n\nUtilisez ce format dans cotre graphe : “2024-oct.”, “2024-dec.”\nCréez une courbe épidémique avec la date de consultation, avec le premier jour de la semaine sur l’axe des x (vous êtes libres du format de la date).\nCréez une courbe épidémique pour l’année 2023 qui montre le nombre d’admissions hospitalières hebdomadaires, avec le numéro ISO de la semaine en abscisse.\n\n\n\nDéfi\n\nTracez une courbe épidémique de la date d’apparition des symptômes par mois. Utilisez un format d’étiquette qui vous semble approprié et lisible."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.fr.html#ressources",
    "href": "sessions_extra/weekly_epicurves.fr.html#ressources",
    "title": "Courbes épidémiques hebdomadaires",
    "section": "Ressources",
    "text": "Ressources\n\nLe chapitre (en anglais) “Elegant graphics for data analyses’ book on date scales\nLa page d’aide de lubridate"
  },
  {
    "objectID": "sessions_extra/faceting.html",
    "href": "sessions_extra/faceting.html",
    "title": "Faceting",
    "section": "",
    "text": "Learn the syntax to make subplots real quick in {ggplot2}\nLearn arguments to modify the appearance of the subplots"
  },
  {
    "objectID": "sessions_extra/faceting.html#objectives",
    "href": "sessions_extra/faceting.html#objectives",
    "title": "Faceting",
    "section": "",
    "text": "Learn the syntax to make subplots real quick in {ggplot2}\nLearn arguments to modify the appearance of the subplots"
  },
  {
    "objectID": "sessions_extra/faceting.html#introduction",
    "href": "sessions_extra/faceting.html#introduction",
    "title": "Faceting",
    "section": "Introduction",
    "text": "Introduction\nThis satellite builds on the core epicurve session, which is a prerequisite. In that session, we learned how to create an epicurve of measles cases across time:\n\n\n\n\n\n\n\n\n\nNow, this plot is cool, but in your sitrep you would like to show the data by age group. There are several ways to do that:\n\nYou could, for each age group, filter your data frame and copy and paste the plotting command to create specific plots\nYou could learn to use for loops or apply() or map() family functions, which are very useful ways to automatize actions, and involve less copy and pasting\nOr you could trust {ggplot2} to have a solution…\n\nThe first option is tedious and it is error prone, and we advise against it; learning the tools of the second option will be a good investment of you time at some point as they are really powerful, but they are way out of the scope of this tutorial because a much simpler option already exist in {ggplot2}."
  },
  {
    "objectID": "sessions_extra/faceting.html#setup",
    "href": "sessions_extra/faceting.html#setup",
    "title": "Faceting",
    "section": "Setup",
    "text": "Setup\n\nWe will use the same clean linelist that we used in the past sessions, which you can download here:\n\n\n\n Download clean data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called faceting.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_linelist."
  },
  {
    "objectID": "sessions_extra/faceting.html#faceting",
    "href": "sessions_extra/faceting.html#faceting",
    "title": "Faceting",
    "section": "Faceting",
    "text": "Faceting\nThe function facet_wrap() allows you to replicate a graph based on the categories of a variable. For example, you could make the epicurve graph by sex, or by site. As other layers of a ggplot graph, you add it to your existing graph with a +. It creates a a figure with multiple small graphs, that {ggplot2} calls facets or small multiples.\n\nGet the Data Ready\nIn the following session, we will explain the code by creating subplots by sub-prefecture, and you will be plotting the epicurve by age group.\nIf we want to to plot anything by sub-prefecture, the sub_prefecture variable must be present in the aggregated data frame that we use to plot.\nLet’s create a new summarized dataset that has the number of patients by day and by sub-prefecture!\n\ndf_pref &lt;- df_linelist %&gt;%\n  count(date_onset, sub_prefecture,\n        name = \"patients\")\n\n\n\n  date_onset sub_prefecture patients\n1 2022-08-13       Moissala        1\n2 2022-08-17       Moissala        1\n3 2022-08-18       Moissala        1\n4 2022-08-22       Moissala        1\n5 2022-08-30       Moissala        2\n6 2022-09-01       Moissala        1\n\n\n\nYou will draw a plot of the number of admissions by age group, so you need a new data frame summarized by day and age group. Create this data frame, and call it df_age. It should have this format:\n\n\n  date_onset    age_group n\n1 2022-08-13  1 - 4 years 1\n2 2022-08-17 5 - 14 years 1\n3 2022-08-18   &lt; 6 months 1\n4 2022-08-22 6 - 8 months 1\n5 2022-08-30   &lt; 6 months 1\n6 2022-08-30 6 - 8 months 1\n\n\n\n\n\nAdd the Facet Layer to the Plot\nNow, let’s plot this data. Look at the code bellow: it is exactly the same as before but for the last line, which creates the facets:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n       title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  facet_wrap(vars(sub_prefecture))   # Make the plot by sub-prefecture!\n\n\n\n\n\n\n\n\nIsn’t that incredible? As you can see, the function facer_wrap() takes as argument a variable name wrapped in the vars() function.\n\nNow is your turn, draw the epicurve by age group (still keeping all the plots improvement: labels, themes etc.)\nIt should look like this:"
  },
  {
    "objectID": "sessions_extra/faceting.html#customize-facets",
    "href": "sessions_extra/faceting.html#customize-facets",
    "title": "Faceting",
    "section": "Customize Facets",
    "text": "Customize Facets\nCheck out the function help page to learn about the arguments that facet_wrap() accepts. We will cover a couple here.\n\nNumber of Rows or Columns\nThe arguments nrow and ncol allow you to decide how many facets there should be on one row, respectively one column.\nFor exemple, we could have all plots on two rows, for a wide figure:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n        title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sub_prefecture),\n             nrow = 2)  \n\n\n\n\n\n\n\n\nOr force the number of rows to four, which forces a taller figure:\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_onset,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of onset\",\n       y = \"Measles cases\",\n       title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sub_prefecture),\n             nrow = 4)  \n\n\n\n\n\n\n\n\n\nUsing one of the mentioned argument, create a graph with three columns.\n\n\n\nAxis Ranges\nDid you notice that in the graph we produced, all facets share the same axis in x and y? This is often a desired feature, as playing with axes is one of the best ways to mislead readers.\nThat being said, if you are more interesting in seeing the shape of the epicurve by category and less by comparing categories to each other, zooming on the available data can be appropriate (alert your reader to the scale variation though!)\nThe scales argument accepts the following strings:\n\n\"fixed\": the default, same limits on x and y for all facets\n\"free_x\": the x axis may have different limits in different facets\n\"free_y\": the y axis may have different limits in different facets\n\"free\": both axis may vary in different facets\n\nLook at this graph:\n\n\n\n\n\n\n\n\n\nWe kept time window on the x axis fixed but allowed the y axis to vary to better read the number of cases by sub-prefecture.\n\nYour turn! Draw you graph with age group as facets with a free y axis, and a fixed x axis."
  },
  {
    "objectID": "sessions_extra/faceting.html#done",
    "href": "sessions_extra/faceting.html#done",
    "title": "Faceting",
    "section": "Done!",
    "text": "Done!\nVery well done team! You have learned how to facet plots! This will work not only on bar plots such as epicurves, but also on other types of plots made by {ggplot2}.\nDepending on the size of your graph, the date labels on the x-axis may be a bit messed up, the ones in my examples definitely are. Fear not, this can be controlled and is the object of another satellite!\n\n\n\n Solutions file"
  },
  {
    "objectID": "sessions_extra/data_exploration.html",
    "href": "sessions_extra/data_exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Perform quick exploration of an imported dataset\nProduce frequency tables for variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#objectives",
    "href": "sessions_extra/data_exploration.html#objectives",
    "title": "Data Exploration",
    "section": "",
    "text": "Perform quick exploration of an imported dataset\nProduce frequency tables for variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#setup",
    "href": "sessions_extra/data_exploration.html#setup",
    "title": "Data Exploration",
    "section": "Setup",
    "text": "Setup\nDependencies. This extra session assumes that you have completed the sessions introduction to R and R studio, and data importation.\n\nFor this session we will work with our raw Moissala measles linelist which can be downloaded here:\n\n\n\n  Course Folder\n\n\n\n Make sure it is appropriately stored in data/raw of your project. Then open a new script called data-exploration.R, and make sure packages {here}, {rio} and {dplyr} are loaded. Finally, import the data into R as an object called df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#data-exploration",
    "href": "sessions_extra/data_exploration.html#data-exploration",
    "title": "Data Exploration",
    "section": "Data Exploration",
    "text": "Data Exploration\nRight after importing some data into R, we might want to take a look at it. When talking of data exploration we usually want to do a few things:\n\nExamine dimensions of the data (ie: how many rows and how many columns)\nLook at columns names\nVisualise the first or last few rows\nDetermine the type of the variables\nDetermine the range of values in continuous variables\nObserve the possible values in each categorical variable\n\nThis process is crucial and will allow us to familiarize ourselves with our data and identify issues that will be adressed during the data cleaning step."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#basic-exploration",
    "href": "sessions_extra/data_exploration.html#basic-exploration",
    "title": "Data Exploration",
    "section": "Basic Exploration",
    "text": "Basic Exploration\nThe very first thing you want to know about your data is the dimensions, which refers to the number of rows and number of columns that make up your data. There are several ways to get this information in R:\n\nLook at your environment pane in RStudio and check for your data - the number next to it (5230x25) tells us it is a dataframe with 5230 rows and 25 columns.\nUse dim() on your data to return a vector with both the number of rows and number of columns\nAlternatively, use ncol() to get the number of columns and nrow() for the number of rows\n\nIt’s good to remember these numbers so you can quickly spot if there are unexpected changes to your data during your analysis (ie: more/fewer rows or columns than expected).\n\nUsing the method of your choice, get the dimensions of your dataframe df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#variable-names",
    "href": "sessions_extra/data_exploration.html#variable-names",
    "title": "Data Exploration",
    "section": "Variable Names",
    "text": "Variable Names\nBecause we are going to use the variable names very often during our analysis, we want to get familiar with them pretty early on. Also, we need to identify the ones that will need to be renamed during our data cleaning. The function names() returns a vector of all the variable names in our dataframe:\n\nnames(df_linelist)\n\n [1] \"id\"                   \"full_name\"            \"sex\"                 \n [4] \"age\"                  \"age_unit\"             \"region\"              \n [7] \"sub_prefecture\"       \"village_commune\"      \"date_onset\"          \n[10] \"date_consultation\"    \"hospitalisation\"      \"date_admission\"      \n[13] \"health_facility_name\" \"malaria_rdt\"          \"fever\"               \n[16] \"rash\"                 \"cough\"                \"red_eye\"             \n[19] \"pneumonia\"            \"encephalitis\"         \"muac\"                \n[22] \"vacc_status\"          \"vacc_doses\"           \"outcome\"             \n[25] \"date_outcome\"        \n\n\n\nWhat do you think of the names in your dataset? Can you already spot some variables names you would like to rename?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#inspecting-your-data",
    "href": "sessions_extra/data_exploration.html#inspecting-your-data",
    "title": "Data Exploration",
    "section": "Inspecting Your Data",
    "text": "Inspecting Your Data\nIt is also nice to inspect your data, it may be easier for you to spot some inconsistencies, variables with a lot of missing values, and it will allow you to see what values to expect in each of them. You can print your data in the console by:\n\nRunning the df_linelist object alone (careful though, you may not want to do this if you have a large dataset)\nUse the head() function to see the top 6 rows (you can increase this number using the argument n)\nUse the tail() function to see the last 6 rows (again, you can increase this number using the argument n)\n\nThese methods will only print the first 40 rows of your data at most because that’s the limit of your console. Alternatively, you can use View() to see your data in a tabular form. This will open a new window with your data displayed like like an Excel spreadsheet. Note, this command only displays the data, it doesn’t allow you to modify it.\n\n\n\n\n\n\nTip\n\n\n\nBe very careful with View() on large dataset as this may crash your RStudio session. To avoid this, you can print the output in the console.\n\n\n\nCan you display the first 15 rows of your data? What happen when you change the width of your console pane and run the command again?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#variable-type",
    "href": "sessions_extra/data_exploration.html#variable-type",
    "title": "Data Exploration",
    "section": "Variable Type",
    "text": "Variable Type\nWe now want to check the type of the different variables. This is important as part of data cleaning involves making sure that numerical variables are type numeric, dates Date, and categorical variables are factor or character. You have already seen the class() function, to check the type of a vector. In R, each variable of a dataframe is a vector. We can extract all the values of that vector using the $ sign, and pass it to the class() function:\n\nclass(df_linelist$age)\n\n\nTry extracting all the values from the sex variable. What is the type of this variable?\n\nYou can also use str() on your dataframe to check the class of all the variables at once:\n\nstr(df_linelist)\n\n\nUse str() to check the data type of each column. Does anything look odd? Remember that you can also use functions like is.character() and is.numeric() if you’d like to test the type of a particular column."
  },
  {
    "objectID": "sessions_extra/data_exploration.html#exploring-continuous-variables",
    "href": "sessions_extra/data_exploration.html#exploring-continuous-variables",
    "title": "Data Exploration",
    "section": "Exploring Continuous Variables",
    "text": "Exploring Continuous Variables\nNow that you know how to extract the values from a variable, you may want to explore some of these values from the numeric variables to check for inconsistencies. Let’s look for some summary statistics for these, and Base R provides many handy functions:\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nExample\nReturns\n\n\n\n\nmin()\nMinimum value\nmin(x)\nSingle minimum value\n\n\nmax()\nMaximum value\nmax(x)\nSingle maximum value\n\n\nmean()\nArithmetic average\nmean(x)\nAverage value\n\n\nmedian()\nMiddle value\nmedian(x)\nMiddle value\n\n\nrange()\nMin and max\nrange(x)\nVector of (min, max)\n\n\nIQR()\nInterquartile range\nIQR(x)\nQ3 - Q1\n\n\nquantile()\nSpecified quantiles\nquantile(x, probs = c(0.25, 0.75))\nRequested quantiles\n\n\nsd()\nStandard deviation\nsd(x)\nStandard deviation\n\n\nvar()\nVariance\nvar(x)\nVariance\n\n\nsum()\nSum of values\nsum(x)\nSum\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThese functions require you to explicitly remove missing values (NA) using the argument na.rm = TRUE\n\n\nYou can extract the values of a variables using $, and pass them to any of those functions.\n\nUse the $ syntax to get:\n\nThe minimum value of age\nThe maximum of muac\n\nAny problems?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#exploring-categorical-variables",
    "href": "sessions_extra/data_exploration.html#exploring-categorical-variables",
    "title": "Data Exploration",
    "section": "Exploring Categorical Variables",
    "text": "Exploring Categorical Variables\nFinally, let’s look at the values in our categorical variables. For this we can use frequency tables. This is handy as:\n\nIt allows us to quickly see the unique values in a categorical variable\nThe number of observations for each of those categories\n\nThis is done using the function count() from the package {dplyr}, which accepts the a dataframe and the name of one (or more!) column(s) as arguments. It will then count the number of observations of each unique element in that column. For example, let’s see the possible values of the variable sex:\n\ncount(df_linelist, sex)\n\nThe output is a new, smaller dataframe containing the number of patients observed stratified by sex. It seems like this variable requires some recoding… We will do that in a later session.\n\nUsing your linelist data, look into the values for the outcome variable. How does it look?\nNow, try adding the argument sort = TRUE to the count() function. What did this argument do?"
  },
  {
    "objectID": "sessions_extra/data_exploration.html#done",
    "href": "sessions_extra/data_exploration.html#done",
    "title": "Data Exploration",
    "section": "Done!",
    "text": "Done!\nWell done taking a first look at your data!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/06_epicurves.html",
    "href": "sessions_core/06_epicurves.html",
    "title": "Basic Data Visualization",
    "section": "",
    "text": "Grasp the very basics of data visualization in R using {ggplot2}\nBuild a basic epicurve"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#objectives",
    "href": "sessions_core/06_epicurves.html#objectives",
    "title": "Basic Data Visualization",
    "section": "",
    "text": "Grasp the very basics of data visualization in R using {ggplot2}\nBuild a basic epicurve"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#introduction",
    "href": "sessions_core/06_epicurves.html#introduction",
    "title": "Basic Data Visualization",
    "section": "Introduction",
    "text": "Introduction\nThis session is a short introduction to data visualization using the popular {ggplot2} package. Keep in mind that visualization in general and even {ggplot2} in particular are huge subjects that we can’t cover in a single core session. This tutorial is intended as a taster to give you a feel for how plotting is typically done. To do that, we will come back to one of our most beloved epidemiological plots: the epicurve.\nOur final plot will look like this:"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#setup",
    "href": "sessions_core/06_epicurves.html#setup",
    "title": "Basic Data Visualization",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio that you are able to import data and that you know th basic data handling verbs that we have seen in the core sessions so far. If you need a refresher on either of these topics, we encourage you to review the core sessions in the learning pathway.\n\nThis session will use the clean version of the Moissala measles linelist data.\n\n\n\n  Course Folder\n\n\n\n Open your RStudio project and create a new script called epicurves.R with appropriate metadata. Load the following packages: {here}, {rio}, {dplyr}, {lubridate}, and {ggplot2}. Add a section to your script called # IMPORT DATA where you import the clean course dataset (moissala_linelist_clean_EN.rds)."
  },
  {
    "objectID": "sessions_core/06_epicurves.html#paradigms-of-plotting",
    "href": "sessions_core/06_epicurves.html#paradigms-of-plotting",
    "title": "Basic Data Visualization",
    "section": "Paradigms of Plotting",
    "text": "Paradigms of Plotting\nIn R, and indeed in everything, there are a lot of ways to approach data visualization. Two of the biggest paradigms are :\n\nThe All-In-One: this approach is characterized by having a single, typically somewhat complex, function that handles all aspects of building a plot. Base R as well as a variety of specialized packages tend to use this approach.\nLayered (or modular): here, instead of creating a plot with a single function, we will use separate functions to add (or modify) different features of a plot (such as the primary shapes, labels, error bars, themes, etc). This is the strategy used by packages like {ggplot2}, {highcharter}, or {echarts4r}.\n\nAn in depth discussion of why one might use one approach versus another is beyond the scope of this course, though we will note that most modern visualization packages tend to use a layered model. With that in mind, let’s take a look at the types of layers we are talking about in our “layered” approach.\n\nBreaking it Down: A Visualization and its Parts\nFor the purpose of this tutorial we will talk about only four visualization components (layers):\n\nCanvas / Data\nPrimary Shapes\nLabels\nTheme\n\nTo illustrate these components, let’s look at a basic schematic of an epicurve:\n\n\n\n\n\nThe most conceptually complex of the above layers is probably the canvas itself. Much as an artist needs to buy a canvas and conceptualize what they want to paint before they start painting, so too does a user of {ggplot2}. Creating the canvas is where we tell R that we want to start making a plot and what parts of the data that plot will use. Here, for example, we will tell R “I want to make a plot where the x axis represents dates (or weeks sometimes) and the y axis represents cases”. Once that canvas is set up we can start adding other layers in the same way that an artist would begin adding paint, their signature, or a frame.\nNow, let’s look at the syntax for these layers in {ggplot2} and how to put them together.\n\n\nGetting Started with {ggplot2}\nThe method of building a ggplot is relatively simple and takes the form:\n\nCreate a canvas using a duo of functions ggplot(aes(...))\nAdd things to the canvas\n\n{ggplot2} takes the idea of “adding something to the canvas” very literally: each new layer will be introduced to your plot using the + sign.\nThe general syntax of a ggplot is then:\n\n# DO NOT RUN (PSEUD-CODE)\ndf |&gt;                      # pipe in your data \n  ggplot(aes(x = ...,      # step 1: create canvas\n             y = ...)) +\n  layer_one(...) +         # step 2: add a first layer\n  layer_two(...) +         # step 3: add another layer\n  ...                      # continue adding layers...\n\nThe number of layers you add depends on how complex you want your plot to be. In our case, we will be adding three layers to our canvas with the following functions:\n\n# DO NOT RUN (PSEUD-CODE)\ndf |&gt;                    # pipe in your data\n  ggplot(aes(x = ...,     # step 1: create canvas\n             y = ...)) +\n  geom_col(...) +         # step 2: add shapes (bars)        \n  labs(...) +             # step 3: add titles\n  theme_classic(...)      # step 4: add a nicer theme\n\nWe can update our above schematic of an epicurve with these functions as follows:\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that in the above example, our very first line is actually our dataset being piped into the ggplot() function. This makes sense since {ggplot2} needs to know what data you’d like to visualize. But be careful, make sure that this line ends in a pipe (|&gt;) and not in a + sign like t |&gt; he other ones.\n\n\nIn the next part of the tutorial we will go through each of these steps (layers) individually using our course dataset to make your first epicurve."
  },
  {
    "objectID": "sessions_core/06_epicurves.html#sec-epicurve-steps",
    "href": "sessions_core/06_epicurves.html#sec-epicurve-steps",
    "title": "Basic Data Visualization",
    "section": "Building Your First ggplot",
    "text": "Building Your First ggplot\n\nPreparing Your Data: Aggregate by Day\nUltimately we would like to plot an epicurve of daily cases. You may have noticed, our current data is daily, but of course several cases may occur on some days. To plot an epicurve we will need to aggregate data by day. Fortunately, you already learned how to summarize data in previous sessions.\n\nUsing count(), create a new dataframe called df_cases that summarizes the total number of cases observed per day. The head of this data frame should look like this:\n\n\n  date_onset n\n1 2022-08-13 1\n2 2022-08-17 1\n3 2022-08-18 1\n4 2022-08-22 1\n5 2022-08-30 2\n6 2022-09-01 1\n\n\n\nGreat! Now we are ready to make our epicurve. In the following steps, you’ll be asked to use df_cases to plot a classic epicurve of the number of daily admissions. To demonstrate the functions you’ll be using, I will plot the curve of the number of daily hospitalizations as an example. To do that, I’ve built myself another dataframe, df_outcome, which looks like this:\n\n\n  date_admission patients\n1     2022-08-14        1\n2     2022-08-25        1\n3     2022-09-02        1\n4     2022-09-06        1\n5     2022-09-09        1\n6     2022-09-10        1\n\n\n\n\nSet up a Canvas: Initialize a Plot\nThe first step is creating your canvas by specifying your dataset and the names of the columns you’d like to visualize. This is done using ggplot(aes(...)) with the following syntax:\n\n# DO NOT RUN (PSEUD-CODE)\ndf_data |&gt;\n  ggplot(aes(x = x_axis_variable_name,\n             y = y_axis_variable_name))\n\nFor an epicurve of hospitalizations, I’d like to plot the days (date_admission) on the x-axis and the number of patients hospitalized (patients) on the y-axis. Let’s update our pseudo-code to do that:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients))\n\n\n\n\n\n\n\n\nFabulous, take a look at that big beautiful box of potential. This is our empty canvas. In RStudio this plot should show up in the panel on the bottom right of the screen.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nJust like with {dplyr}, we write our column names without quotation marks. This is unsurprising as {ggplot2}, like {dplyr}, is a member of the {tidyverse} and therefore uses similar syntax.\n\n\nNow, you may be wondering what is this aes() function that we’ve nested inside of ggplot()? The short answer is that aes() creates an AESthetic mapping that tells {ggplot2} which columns of our data should be represented by which visual elements of our plot (like the axes, for example).\nAesthetic mappings create a map that defines how data elements (variables) are to be represented by visual elements (like axes, colors, and sizes). For example, here we are mapping the days to the x-axis and the number of patients to the y-axis. We could also imagine, for example, an epicurve where bars are colored based on whether patients lived or died. This would be an example where the variable outcome is being mapped to the visual element of color.\nFor now it is enough to know that aes() is the place where you will define your x-and y-axis.\n\nCreate a new section in your script called # PLOT EPICURVE. Then create an empty canvas for your epicurve using df_cases.\n\nAt this point, your plot should look like this:\n\n\n\n\n\n\n\n\n\nExcellent! Now let’s add some bars.\n\n\nPlot the Bars\nNow that we have our canvas, it’s time to add some shapes. In {ggplot2}, the shapes plotted on a figure are called geometries. Geometries are the primary visual representation of your data and should feel pretty familiar. A few common types of geometries include:\n\nBar Plots (geom_col() or geom_bar())\nHistograms (geom_hist())\nScatterplots (geom_point())\nLine Plots (geom_line())\nBoxplots (geom_boxplot())\n\nToday, we’re doing epicurves so we are most interested in learning how to make a bar plot. In our case, we will be using geom_col(). Remember that adding a new layer (in this case a geometry) to our ggplot is as simple as using a +, so we can add bars to the epicurve of hospitalized cases in the following way:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col()\n\n\n\n\n\n\n\n\nBrilliant! That sure looks like an epicurve to me. Though it does look a bit…grey. If we’d like to update the color of our bars (called the fill), we simply need to add the fill argument to geom_col().\nLet’s give it a try:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\")\n\n\n\n\n\n\n\n\n\nUpdate your epicurve plot to add bars with the color #E4573.\n\nYour plot should now look like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the {ggplot2} framework, layers must be added to an existing canvas. This means that running geom_col() by itself will not produce any visual output. This, however, makes sense. Continuing with our analogy of ggplots being like paintings, running geom_col() by itself would be like having paint with no canvas to put it on.\n\n\nLooking good. Now it’s time to make our plot just a bit more informative and just a bit more attractive by adding labels and a nicer theme.\n\n\nAdd Some Labels\nA good plot needs some good labeling; n is hardly an informative axis title. Fortunately, {ggplot2} makes adding labels easy with the function labs(). This function will accept a variety of arguments allowing you to add a variety of label/title elements to your plot, for example:\n\nAxis Titles (x = and y =)\nPlot Title (title =)\nCaption\n\nAs for other layers, we can include a label layer by adding labs() to our current plot with the + sign:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\")\n\n\n\n\n\n\n\n\n\nUpdate your epicurve plot to add some reasonable axis labels and a nice title.  Extra Credit! Try adding a data source using caption.\n\nYour plot might now look like (for example):\n\n\n\n\n\n\n\n\n\n\n\nAdd a Theme\nIf we wanted to, we could stop here if our goal is to produce an informal plot. Ideally, however, it would be nice to use a somewhat more attractive theme and to increase the text size. To do this, we will add one last layer to our plot: a theme layer. Much like how geometries in {ggplot2} all start with geom_, all themes start with theme_. There are several themes available to you and you can check out what they look like on the {ggplot2} website.\nToday, we will use theme_classic(), which offers a simple but elegant output:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nOk, nice. But we’d also like to increase the size of that tiny font. To do that we can adjust the base_size argument:\n\ndf_hospital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Daily Patients\",\n       title = \"Measles Hospitalizations in Mandoul Region (Chad)\") +\n  theme_classic(base_size = 17)\n\n\n\n\n\n\n\n\nThat looks better! Keep in mind that the font size needed will depend on what the plot is going to be used for (i.e. a presentation, an informal review, or a final report). Similarly, the exact theme you will want to use is ultimately a subjective choice. While there are guidelines, data visualization is as much an art as a science.\n\nAdd one final layer to your plot that adds a theme of your choice with an appropriate base_size.\n\n\n\nSave your plot\nIf you would like to save your epicurve, you can click on the “Export” button in the plot panel of RStudio:"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#done",
    "href": "sessions_core/06_epicurves.html#done",
    "title": "Basic Data Visualization",
    "section": "Done!",
    "text": "Done!\nVery well done team! You have build your first epicurve!\n\n\n\n Solutions file"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#go-further",
    "href": "sessions_core/06_epicurves.html#go-further",
    "title": "Basic Data Visualization",
    "section": "Go Further",
    "text": "Go Further\n\nExtra Exercises\n\nUse the theme_minimal() on one of your graph, with a base size font of 18.\nGo to this site, pick a color and update the color of your bars.\n\n\n\nChallenge Exercises\n\nInstead of aggregating by date, count the number of patients by sub-prefecture. Try to adapt your epicurve code to create a barplot of the number of patients by sub-prefecture.\n\n\n\nSatellites\n\nWeekly Epicurves\nFaceting"
  },
  {
    "objectID": "sessions_core/06_epicurves.html#resources",
    "href": "sessions_core/06_epicurves.html#resources",
    "title": "Basic Data Visualization",
    "section": "Resources",
    "text": "Resources\n\nA full book on using {ggplot2}\n\nA whole chapter on epicurves"
  },
  {
    "objectID": "sessions_core/05_summary_table.html",
    "href": "sessions_core/05_summary_table.html",
    "title": "Summary Tables",
    "section": "",
    "text": "Create contingency tables with count()\nCompute summary statistics by group using summarize()\nReview how to subset rows using filter() and create/modify variables with mutate()\nCreate ordered categorical variables"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#objectives",
    "href": "sessions_core/05_summary_table.html#objectives",
    "title": "Summary Tables",
    "section": "",
    "text": "Create contingency tables with count()\nCompute summary statistics by group using summarize()\nReview how to subset rows using filter() and create/modify variables with mutate()\nCreate ordered categorical variables"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#setup",
    "href": "sessions_core/05_summary_table.html#setup",
    "title": "Summary Tables",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio that you are able to import data and that you know th basic data handling verbs that we have seen in the core sessions so far. If you need a refresher on either of these topics, we encourage you to review the core sessions in the learning pathway.\n\nThis session will use the clean version of the Moissala measles dataset.\n\n\n\n  Course Folder\n\n\n\n Open your RStudio Project and create a new script in the R folder called tables.R with appropriate metadata and a “Packages” section that imports: {rio}, {here} and {tidyverse}. Add an “Import Data” section that loads the cleaned version of the measles linelist."
  },
  {
    "objectID": "sessions_core/05_summary_table.html#introduction-data-aggregation",
    "href": "sessions_core/05_summary_table.html#introduction-data-aggregation",
    "title": "Summary Tables",
    "section": "Introduction: Data aggregation",
    "text": "Introduction: Data aggregation\nOK so let’s recap, you have just performed one of the most important tasks of an epidemiologist: the data cleaning. Now that you have clean and standardized data, you can get into the real business and start analysing them. Analyses typically start with some tables and summaries that describe our data:\n\nUnivariate frequency tables to count occurrences of different values\nSummary statistics of numerical variables (mean, median, standard deviation)\nCross-tabulations to examine relationships between categorical variables\nGroup-wise summaries to compare statistics across different subsets of the data"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#counting-multiple-columns-contingency-tables",
    "href": "sessions_core/05_summary_table.html#counting-multiple-columns-contingency-tables",
    "title": "Summary Tables",
    "section": "Counting Multiple Columns (Contingency Tables)",
    "text": "Counting Multiple Columns (Contingency Tables)\nDuring the data exploration session, you have learned to create a frequency table for a single categorical variable using the count() function. This is nice, but we often want to count the number observations based on two (or more!) variables.\nThese tables are called contingency tables. For example, knowing the number of patients by sub_prefecture is great but we might want to stratify by both sub_prefecture and age_group to see if certain areas have unusually old patients. Doing this is easy, you just need to pass multiple column names to count():\n\ndf_linelist |&gt;\n  count(sub_prefecture, age_group)\n\n\nCreate a new summary table counting the number of patients stratified by sub_prefecture and hospitalisation. What happens if you change the order of the arguments given to count()?  Now, using count(), answer the following questions:\n\nHow many patients were female? What is the proportion?\nWhat are all the possible values of the outcome variable?\nHow many patients between 1 - 4 years have recovered?"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#filtering-out-nas",
    "href": "sessions_core/05_summary_table.html#filtering-out-nas",
    "title": "Summary Tables",
    "section": "Filtering out NAs",
    "text": "Filtering out NAs\nWhen looking at the categories of outcome, you should have spotted that some patients have missing values (NA):\n\ndf_linelist |&gt;\n  count(outcome) |&gt;\n  mutate(prop = n / sum(n))\n\n\nObserve the output of the code above. How can you also call the proportion of patients who died? Are you happy with this calculation?\n\nThe proportion of cases that died is also referred to as the Case Fatality Ratio (CFR). To precisely calculate the CFR we need to make sure that the denominator only includes patient for whom we are sure of their outcome (ie we need to remove all cases with NA or left aginst medical advice).\nRemember that we can do this using filter(). To filter for missing values (NA) in a variable we can use the small function is.na(outcome). Adding a ! in front will do the opposite: removing missing values from outcome:\n\ndf_linelist |&gt;\n  filter(\n    outcome != \"left against medical advice\", \n    !is.na(outcome)\n  ) |&gt;\n  count(outcome)\n\n\nWhich other conditionnal statement could you use in filter() to obtain the same results\n\nNow that we have removed the patients with unknown outcomes, we can add this before creating our frequency table to get the right CFR.\n\nUsing your filter, update your code to summarize the observed number of patients who survived and died as well as the CFR (proportion who died). Store this new dataframe into an object, cfr_df.\n\n\n\n\n\n\n\nTip\n\n\n\nBonus. A useful “shortcut” function is drop_na() from the package {tidyr} that equates to filter(!is.na()).\n\ndf_linelist |&gt;\n  drop_na(outcome) |&gt;\n  count(outcome)\n\ndrop_na() is particularly useful as you can give it multiple column names to filter by. But be careful that doing so will remove all rows where one or more of those columns have a missing value."
  },
  {
    "objectID": "sessions_core/05_summary_table.html#sec-stratify",
    "href": "sessions_core/05_summary_table.html#sec-stratify",
    "title": "Summary Tables",
    "section": "Summary Table: Statistics by Sub Prefecture",
    "text": "Summary Table: Statistics by Sub Prefecture\nOk now that we have produced some simple frequency and contingency tables we may want to increase the complexity. A common task in epidemiology is to look at summary statistics within subsets of the data.\nFor example, we may be asked to produce patient statistics at the sub-prefecture level, ie: for each sub-prefecture in the data, we need to answer the following questions:\n\nHow many patients consulted?\nWhat is their average age?\nWhat was the earliest date of admission?\nHow many patients have been hospitalized?\nAmong children under 6 months, how many have died?\n\nThis is exactly what the function summarize() has been made for! It allows us to calculate summary statistics on a dataset, and the syntax is similar to that of mutate():\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  mutate(new_col = function_to_create(existing_col))\n\ndf |&gt;\n  summarize(\n    .by = grouping_variable,\n    new_col = summary_function(existing_col)\n  )\n\nConsider the following code, here we are summarizing the data to calculate the average age across all patients.\n\ndf_linelist |&gt;\n  summarize(mean_age = mean(age))\n\n  mean_age\n1 6.822047\n\n\nNotice that this code yields a single value for average age. No grouping variable was provided so summarize() returned one summary statistic for the whole dataset. To calculate the average age by a specific strata, we need to specify a grouping variable using the .by argument:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sex,  # Make the summary (here, the mean) by sex\n    mean_age = mean(age)\n  )\n\n  sex mean_age\n1   f 6.773824\n2   m 6.869855\n\n\n\nTake a look at the above results. How would you interpret them?\n\nNow that we can use summarize() we can use it to calculate some proper summary statistics by sub-prefecture. Let’s start by calling an empty summarize() and grouping the data on sub_prefecture.\n\nRun the following code:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture\n  )\n\nWhat happens when you run these lines?\n\n\nCounts\nWe first want to look at the number of cases in each sub_prefecture. This can be done using the helper function n():\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n() # Count stuffs\n  )\n\n\nOk now let’s build a summary table for each sub_prefecture. First start by replicating the above lines\n\n\n\nSummarizing Continuous Variables\nWe can then use the mean(), median(), min(), max() functions (and other) to produce summaries for continuous variables. For example the average age:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n(),\n    mean_age = mean(age)\n  )\n\n\nAdd the minimum date of admission to your table for each of the sub_prefecture? Are you happy with the results?\n\n\n\n\n\n\n\nTip\n\n\n\nRemember that with the arithmetic functions such as mean(), median(), min(), max(), you need to explicitly tell R to remove NA.\n\n\n\n\nCounting with a Condition\nWe may also be interested in looking at the number of patients (rows) that fit a condition: the number of patients that were female. Counting by a logical condition can be done with the following syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\nsummarize(\n  sum_category = sum(LOGIC_TEST, na.rm = TRUE)\n  )\n\nThis sum allows us to count all the lines where our condition was met (returns TRUE). For example:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_female = sum(sex == \"f\", na.rm = TRUE)\n  )\n\n\nAdd a variable to your table that counts the number of patients that have been hospitalized. (ie: rows that have yes in variable hospitalisation)\n\n\n\nOther Statistics\nSometimes we want to produce a more complicated statistic, for example the mean age of all hospitalized patients. Here the syntax is a bit different:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  summarize(\n    mean_category = mean(col_to_use[LOGIC_TEST], na.rm = TRUE)\n    )\n\nHere, we have:\n\nStated what summary statistic we want to use (mean())\nIndicated which column we want to calculate that statistic on (col_to_use)\nCreated a condition of which observations in that column to use in the calculation ([LOGIC_TEST])\n\nTo give a concrete example, if we wanted to compute the mean of the age variable but only for hospitalized patients (ie: in rows where hospitalisation == \"yes\") we would write:\n\ndf_linelist |&gt;\n  summarize(\n    .by = sub_prefecture,\n    n_patients = n(),\n    mean_age_hosp = mean(age[hospitalisation == \"yes\"], na.rm = TRUE)\n  )\n\nThe use of a logical test in the example above is called logical indexing, where a condition is essentially being used to filter which observations you want to consider when performing a calculation. Logical indexing is very powerful but can also take some getting used to, so don’t worry too much if it isn’t perfectly clear at this stage.\n\nCan you use this syntax to calculate the mean age of female patients in your table?\n\nThat is looking great! We are starting to get a pretty exhaustive grouped summary table with a lot of useful information by sub_prefecture! An extra challenge for you:\n\nCHALLENGE: Could you add a variable to your table that counts the number of patients that died among the ones that are &lt; 6 months old.\n Hint. You want to count rows (so use sum()) that fill a specific condition for outcome (outcome == \"dead\"), but only when age_group == \"&lt; 6 months\"\n\n\n\nUse the Output\nFinally, remember that summarize() returns a dataframe that we can then further manipulate (eg: with filter() and mutate()).\n\nAdd a mutate() after producing your summary table to calculate:\n\nThe proportion of hospitalized patients per sub-prefecture\nThe proportion of female patients per sub-prefecture\n\n\nThe head of your final table should look like this:\n\n\n  sub_prefecture n_patients mean_age min_admission n_female n_hosp\n1       Moissala       1808 6.842920    2022-08-14      923    612\n2          Bouna       1376 6.555959    2023-01-11      669    412\n3       Bedjondo        534 7.073034    2023-06-09      251    184\n4       Bekourou        496 6.836694    2023-06-17      251    164\n5         Bedaya        435 7.098851    2023-07-04      209    147\n6         Koumra        253 7.106719    2023-08-14      138     84\n  mean_age_hosp mean_age_female n_death_u6m prop_female prop_hosp\n1      5.485294        6.748646          71   0.5105088 0.3384956\n2      5.665049        6.633782          61   0.4861919 0.2994186\n3      5.211957        6.948207          22   0.4700375 0.3445693\n4      6.042683        6.840637          25   0.5060484 0.3306452\n5      6.156463        7.105263          17   0.4804598 0.3379310\n6      6.261905        6.456522           7   0.5454545 0.3320158"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#done",
    "href": "sessions_core/05_summary_table.html#done",
    "title": "Summary Tables",
    "section": "Done!",
    "text": "Done!\nYou should be proud of yourselves, making summary tables is an important skill to an epidemiologist, making it in R is very efficient! Don’t forget to save your code!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/05_summary_table.html#going-further",
    "href": "sessions_core/05_summary_table.html#going-further",
    "title": "Summary Tables",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nMake a summary table that summarizes:\n\nThe number of patients\nThe proportion of male\nThe number of deaths\nThe CFR\nThe number of deaths among patients that had pneumonia\nin all the different age groups !\n\nMake a table that shows the proportion of patients by age with any measles vaccine (by oral recall or card) and those with 1 or 2 doses.\nMake a table that compares the proportion of hospitalised and non-hospitalised patients with positive malaria RDT, fever, rash, cough, red eye, pneumonia, encephalitis, and “red” or “yellow” MUAC (less than 125 mm).\nCalculate the mean days from first symptom onset to consultation by sub-prefecture.\nCalculate the mean time spent in hospital (i.e. days from admission to outcome) by outcome (i.e. in those who recovered and those who died).\n\n\n\nAdditional Resources\n\nThe EpiR Handbook chapter on grouping data\nOnce you have tables, you can extensively customize them for display/publication using {gt} package:\n\nWebsite of gt\nBook about gt"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html",
    "href": "sessions_core/04_data_verbs_conditional.html",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "",
    "text": "Understand basic conditional logic statements\nLearn how to filter a data frame using filter()\nLearn how to recode variables using case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#objectives",
    "href": "sessions_core/04_data_verbs_conditional.html#objectives",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "",
    "text": "Understand basic conditional logic statements\nLearn how to filter a data frame using filter()\nLearn how to recode variables using case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#setup",
    "href": "sessions_core/04_data_verbs_conditional.html#setup",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know the basics of data manipulation with {dplyr}. If you need a refresher on this, please review the third session in the learning pathway.\n\nThis session will work with the raw Moissala linelist data, which can be downloaded here:\n\n\n\n  Download Data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called filtering_and_recoding_practice.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_raw."
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#using-conditional-logic-to-filter-data",
    "href": "sessions_core/04_data_verbs_conditional.html#using-conditional-logic-to-filter-data",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Using Conditional Logic to Filter Data",
    "text": "Using Conditional Logic to Filter Data\nIn the last session we learned a lot of the core data verbs in {dplyr} for basic manipulation tasks like selecting particular variables of interest and modifying them to better suit our needs. Beyond selecting variables of interest, another common task we have as epidemiologists is selecting observations of interest; ie: filtering our data to look at particular observations that meet a certain criteria.\nFortunately, {dplyr} has our back with the conveniently named function, filter(). To understand how to use it, however, we will need to learn a bit about how to construct conditional logic statements in R. This will be the focus of our session today.\n\nThis Equals That\nThe basic syntax of filter() is pretty simple:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf_raw |&gt;\n  filter([conditional logic statement]) # Keep lines where statement is TRUE\n\nBut what is a conditional logic statement? These are statements that ask “Is this thing true?”. The simplest conditional logic statement asks “does this variable equal this value?”. For example, “was this patient hospitalized?”. In R, we can ask if one value equals another using ==.\nTo create a filter asking, for each observation, whether the value of hospitalization is equal to yes we can then use the following syntax:\n\ndf_raw |&gt;\n  filter(hospitalisation == 'yes')\n\nWhat filter() is doing here is going down each row of our dataset and asking: “for this row, is the value of hospitalisation equal to \"yes\"?”. It then returns only the rows where the answer to this question is TRUE.\n\nCreate a filter that selects all of the patients who had a fever, ie: where the value of fever was \"Yes\". The head of fever should look like this:\n\n\n  fever\n1   Yes\n2   Yes\n3   Yes\n4   Yes\n5   Yes\n6   Yes\n\n\nTake a look at your output and then take a look at the head of df_raw. Why does df_raw still contain patients who didn’t present with fever?\n\n\n\nThis Does Not Equal That\nChecking if something is the same is great, but a lot of the time we might have another question in mind. For example, we might want to know how many patients didn’t recover, whether this was because they died or because they left against medical advice.\nIn this case, instead of writing == we will instead use !=. So, for example if we want to select all observations where patients didn’t recover we would write:\n\ndf |&gt;\n  filter(outcome != 'recovered')\n\n\nCreate a filter that selects patients who did not have a card confirmed vaccination status. The head of vacc_status should look like this:\n\n\n  vacc_status\n1          No\n2  Yes - oral\n3          No\n4          No\n5          No\n6          No\n\n\nHint. Remember that you can use count() to check what the options were for vacc_status.\n\n\n\nGreater Than / Less Than\nThe other common question we have is whether a value was greater or less than a particular threshold. For example, how many patients were under 5 years old? Here we will use &lt; and &gt; to evaluate whether a variable is less than or greater than a particular value, respectively.\nFor example, to ask how many patients were less than 60 months old we can write:\n\ndf_raw |&gt;\n  filter(age &lt; 60)\n\n\nCreate a filter that selects all patients with severe accute malnutrition (ie: patients with a MUAC less than 110). The head of muac should look like this:\n\n\n  muac\n1   80\n2   88\n3   60\n4   85\n5   86\n6   68\n\n\nNow create another filter that selects patients who are over 15 years old. The head of your age column should look like this:\n\n\n  age\n1 348\n2 348\n3 312\n4 432\n5 444\n6 324\n\n\n\nSometimes, instead of asking if something is less or greater than a particular value, we want to ask if it is less than or equal to that value. Easy, we just need to add an equal sign! We write &lt;= for “less than or equal to” and &gt;= for “greater than or equal to”. Careful here, the = must come after &lt; or &gt;, not before.\nSo if we want to ask for how many patients were 10 years of age or younger, we can write:\n\ndf_raw |&gt;\n  filter(age &lt;= 120)\n\n\nCreate a filter that selects all patients with a normal nutrition status, ie: patients with a MUAC greater than or equal to 125. The head of muac should look like this:\n\n\n  muac\n1  244\n2  232\n3  210\n4  220\n5  152\n6  155\n\n\n\n\n\nFilters with Multiple Conditions\nWant to combine several logic statements in a single filter? Easy. We can create a filter with multiple conditions by simply separating each condition with a comma:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  filter([condition 1],\n         [condition 2],\n         [condition 3])\n\nSo for example, let’s say we want to select all patients under five who were hospitalized. In this case we can write:\n\ndf_raw |&gt;\n  filter(age &lt; 5,\n         hospitalised = \"true\")\n\n\nCreate a filter that selects all patients with severe accute malnutrition who were hospitalized in the Koumra health facility. The head of id, sub_prefecture, hospitalisation, and muac should look like this:\n\n\n    id sub_prefecture hospitalisation muac\n1 8624         KOUMRA             yes  103\n2 8939         KOUMRA             yes   67\n3 9957         KOUMRA             yes   71\n\n\nHint. This filter has a condition on both hospitalisation status, sub_prefecture, and muac.\n\n\n\nSummary of Basic Logic Statements\nGood job working through a quick tour of logic statements in R! Here is a handy table to help you remember the main logic statements we have learned so far:\n\n\n\nStatement\nR\n\n\n\n\nIs A the same as B?\nA == B\n\n\nIs A not the same as B\nA != B\n\n\nIs A greater than B?\nA &gt; B\n\n\nIs A greater than or equal to B?\nA &gt;= B\n\n\nIs A less than B?\nA &lt; B\n\n\nIs A less than or equal to B?\nA &lt;= B"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#recoding-with-case_when",
    "href": "sessions_core/04_data_verbs_conditional.html#recoding-with-case_when",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Recoding with case_when()",
    "text": "Recoding with case_when()\nAs we have seen, conditional logic statements are incredibly useful when trying to filter our data, but you will find that they have many other uses as well. One of their other major use cases for us as epidemiologists is when we need to recode our data. This is where the {dplyr} function case_when() is here to help us.\nThe syntax of case_when() is a little more advanced than what we have seen so far, but we will go slowly and break it down. Once you get the hang of it, case_when() will become a very powerful part of your R toolbelt.\nWe will almost always use case_when() inside of a mutate(), because we will use it either to recode an existing variable or to create a new one. The basic syntax works like this:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf |&gt;\n  mutate(column_name = case_when([first condition] ~ [value when condition is TRUE],\n                                 [second condition] ~ [value when second condition is TRUE],\n                                 .default = [default value])\n\nOk, that’s a lot. Let’s break it down.\nSo the first thing to notice is that, with the exception of the last line, each line inside of case_when() has the following format:\n\n[condition] ~ [value when condition is TRUE]\n\nSo for example, if we want our case_when() to say that anytime a patient had a MUAC less than 110 we want to have a value of \"SAM\", we would have something like this:\n\nmuac &lt; 110 ~ 'SAM'\n\nWe can add multiple possible outcomes by adding additional lines. In this case, our next condition might check if the patient is moderately but not severly malnourished using the statement muac &lt; 125 ~ 'MAM'.\nThe last line, with the argument .default gives the value we want case_when() to use when none of the above conditions have been met. In this case, we might give the value 'Normal'.\nTo put this together, if we wanted to create a variable that classifies the malnutrition status of patients using their MUAC, we would write:\n\ndf_raw |&gt;\n  mutate(malnut = case_when(muac &lt; 110 ~ 'SAM',\n                            muac &lt; 125 ~ 'MAM',\n                            .default = 'Normal'))\n\n\nTry running the above code to see if it successfully creates a new column malnut with the malnutrition status of each case. You should get something like this:\n\n\n  muac malnut\n1  244 Normal\n2  232 Normal\n3  123    MAM\n4  210 Normal\n5   80    SAM\n6  220 Normal\n\n\n\nBe careful. The order of your statements is important here. What case_when() will do is go through each statement from top to bottom and assign the first value that is TRUE. So in our above example, case_when() will ask the following questions in sequence:\n\nDoes this patient have SAM (is muac &lt; 110)? If so, assign the value \"SAM\"\nIf the patient didn’t have SAM, do they have MAM (is muac &lt; 125)? If so, assign the value `“MAM”\nIf none of the above conditions were true, assign the default value \"Normal\"\n\n\nTry reordering the first and second conditions in the above case_when() so that you first check if muac &lt; 125. The head of your new data frame should now look like this:\n\n\n  muac malnut\n1  244 Normal\n2  232 Normal\n3  123    MAM\n4  210 Normal\n5   80    MAM\n6  220 Normal\n\n\nNotice anything different? Save this new data frame to a tmp object and inspect it to see if we still have any patients classified as \"SAM\". Can you figure out why this no longer gives the correct classification?\n\n\n\n\n\n\n\nNote\n\n\n\nThe .default argument in case_when() is not obligatory. If you don’t include it then case_when() will use NA by default.\n\n\nAs we saw in our above example, case_when() is an easy way of creating new variables based on the values of an existing column. This can be used to classify status (as we saw with malnutrition) or to regroup variables into categories (like age groups).\n\nUse case_when() to create a new variable age_group with three categories: \"&lt; 5 Years\", \"5 - 15 Years\", and \"&gt; 15 Years\". Patients missing age data should be assigned a default value of \"Unknown\". Be careful with your ordering! The head of your new column should look like this:\n\n\n  age     age_group\n1  36     &lt; 5 Years\n2   5     &lt; 5 Years\n3 156 5 - 15  Years\n4   8     &lt; 5 Years\n5   7     &lt; 5 Years\n6   4     &lt; 5 Years\n\n\n\n\nThe %in% operator\nSo now we can regroup variables into categories, great. But we can also use case_when() to standardize the values we see in a variable.\n\nUsing count() inspect the categorical variables in df_raw to check if any have inconsistencies in their coding.\n\nIn our dataset, we see that there are some issues in the way sex was coded. For example, female patients are coded as f, female and femme. That simply won’t do. Thankfully, we can use case_when() to recode this variable. This time, instead of creating a new variable we will directly update sex:\n\ndf_raw |&gt;\n  mutate(sex = case_when(sex == \"f\" ~ \"Female\",\n                         sex == \"female\" ~ \"Female\",\n                         sex == \"femme\" ~ \"Female\",\n                         sex == \"m\" ~ \"Male\",\n                         sex == \"male\" ~ \"Male\",\n                         sex == \"homme\" ~ \"Male\",\n                         .default = \"Unknown\"))\n\nWell, that works, but it seems awfully repetitive. It would be easier if we could just list all the options that we want to reassign to “Female” and “Male” respectively. This is where the %in% operator is here to help. The %in% operator will check if a value is in a vector of options using the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\n[value] %in% [vector_of_options]\n\nSo, for example, we could check if the value \"f\" is in the options \"f\", \"female\" using the following:\n\n\"f\" %in% c(\"f\", \"female\")\n\n\nTry running the above statement. What is the data type of your outcome?\n\nSee how the outcome of the above statement is a boolean, ie: a logic outcome? That means we can use it as a condition in case_when()! This means that our verbose code above can now be written as:\n\ndf_raw |&gt;\n  mutate(sex = case_when(sex %in% c(\"f\", \"female\", \"femme\") ~ \"Female\",\n                         sex %in% c(\"m\", \"male\", \"homme\") ~ \"Male\",\n                         .default = \"Unknown\"))\n\nMuch nicer.\n\nUse case_when() and the %in% operator to create a new column vacc_status_strict that has the value \"Yes\" for cases with card confirmed vaccination status, \"No\" for cases who said they were unvaccinated, and \"Unverified\" otherwise. The head of your new column should look like this:\n\n\n  vacc_status_strict\n1         Unverified\n2                 No\n3         Unverified\n4                 No\n5                 No\n6                 No"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#a-last-bit-of-cleanup",
    "href": "sessions_core/04_data_verbs_conditional.html#a-last-bit-of-cleanup",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "A Last Bit of Cleanup",
    "text": "A Last Bit of Cleanup\nNow that we know how to leverage case_when() and conditional logic (in addition to what we learned in the last session, we can actually put together a decent cleaning pipeline. I hope you kept your code from last time handy…\n\nUsing what you have learned above and what you practiced in the last session, create a basic data cleaning pipe that creates a new data frame, df, after doing the following:\n\nRemove the variables full_name and age_unit\nRename the following variables:\n\nage becomes age_months\nsub_prefecture becomes prefecture\nvillage_commune becomes village\nhealth_facility_name becomes facility\n\nAdd a variable age_years with patient age in years\nUpdate region and prefecture to use title case\nUpdate all date columns to use Date type\nCreate a new variable age_group age to include the groups: &lt; 6 months, 6 - 11 months, 12 - 59 months, 5 - 15 years, and &gt; 15 years (patients with unknown age should have a value “Unknown”)\nRecode sex to have only the values: Female, Male, and Unknown\nRemove any duplicate observations\n\nThe head of your final data should look something like this:\n\n\n  id    sex age_months  region prefecture        village date_onset\n1  1 Female         36 Mandoul   Moissala Sangana Koïtan 2022-08-13\n2  2 Female          5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3 Female        156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6   Male          8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7   Male          7 Mandoul   Moissala      Tétindaya 2022-08-30\n6 10   Male          4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             yes     2022-08-14\n2        2022-08-25             yes     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25              no           &lt;NA&gt;\n5        2022-09-02              no           &lt;NA&gt;\n6        2022-09-02             yes     2022-09-02\n                         facility malaria_rdt fever rash cough red_eye\n1 Hôpital du District de Moissala    negative    No &lt;NA&gt;   Yes      No\n2 Hôpital du District de Moissala    negative    No   No   Yes      No\n3                      CS Silambi    negative   Yes &lt;NA&gt;    No      No\n4 Hôpital du District de Moissala    negative    No   No    No    &lt;NA&gt;\n5                      CS Silambi    negative  &lt;NA&gt;   No   Yes     Yes\n6                    Moissala Est    negative   Yes   No    No    &lt;NA&gt;\n  pneumonia encephalitis muac vacc_status vacc_doses   outcome date_outcome\n1        No           No  244        &lt;NA&gt;       &lt;NA&gt; recovered   2022-08-18\n2      &lt;NA&gt;           No  232          No       &lt;NA&gt;      &lt;NA&gt;   2022-08-28\n3        No         &lt;NA&gt;  123  Yes - oral       &lt;NA&gt; recovered         &lt;NA&gt;\n4        No           No  210          No       &lt;NA&gt; recovered         &lt;NA&gt;\n5        No           No   80          No       &lt;NA&gt; recovered         &lt;NA&gt;\n6        No           No  220          No       &lt;NA&gt; recovered   2022-09-03\n   age_years      age_group\n1  3.0000000 12 - 59 months\n2  0.4166667     &lt; 6 months\n3 13.0000000   5 - 15 years\n4  0.6666667  6 - 11 months\n5  0.5833333  6 - 11 months\n6  0.3333333     &lt; 6 months\n\n\n\nAmazing! Let’s look at how to save this (mostly) clean dataset. Here, we will use the function export() from {rio} and here() from {here} to specify where to save our output:\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.xlsx'))\n\nNotice here that we are putting our data in the appropriate clean subfolder of data.\n\n\n\n\n\n\nTip\n\n\n\nIn the above example we save our data as an xlsx, which is helpful if you want to be able to open the clean data in Excel. Often, however, we might prefer to use a file with the extension .rds instead. This is a file type specific to R and is more robust to issues related to encoding or date formatting than files like xlsx or csv. To save your above file as an rds all you need to do is change the extension:\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.rds'))"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#done",
    "href": "sessions_core/04_data_verbs_conditional.html#done",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Done!",
    "text": "Done!\nVery well done. You’ve learned how to use basic data verbs, conditional logic, and create a basic data cleaning pipeline.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.html#going-further",
    "href": "sessions_core/04_data_verbs_conditional.html#going-further",
    "title": "Data Manipulation, Filtering and Recoding",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html",
    "href": "sessions_core/03_data_verbs.html",
    "title": "Data Manipulation, Basics",
    "section": "",
    "text": "Learn basic data verbs from {dplyr} to:\n\nSelect specific columns (select())\nRename columns (rename())\nAdd new columns and change existing ones (mutate())\nRemove duplicate observations\n\nUnderstand the pipe operator |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#objectives",
    "href": "sessions_core/03_data_verbs.html#objectives",
    "title": "Data Manipulation, Basics",
    "section": "",
    "text": "Learn basic data verbs from {dplyr} to:\n\nSelect specific columns (select())\nRename columns (rename())\nAdd new columns and change existing ones (mutate())\nRemove duplicate observations\n\nUnderstand the pipe operator |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#setup",
    "href": "sessions_core/03_data_verbs.html#setup",
    "title": "Data Manipulation, Basics",
    "section": "Setup",
    "text": "Setup\nDependencies. This session assumes that you know how to use RStudio and that you are able to import data. If you need a refresher on either of these topics, we encourage you to review the first two sessions in the learning pathway.\n\nThis session will work with the raw Moissala linelist data, which can be downloaded here:\n\n\n\n  Download Data\n\n\n\n Make sure this dataset is saved into the appropriate subdirectory of your R project and create a new script called data_verbs_practice.R in your R directory. Add an appropriate header and load the following packages: {here}, {rio}, and {tidyverse}.  Finally, add an import section where you use {here} and {rio} to load your data into an object called df_raw."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#manipulating-data-with-dplyr",
    "href": "sessions_core/03_data_verbs.html#manipulating-data-with-dplyr",
    "title": "Data Manipulation, Basics",
    "section": "Manipulating Data with {dplyr}",
    "text": "Manipulating Data with {dplyr}\nNow that we know how to set up a project and import data, we can finally start to play around with it. Going forward we will be using several packages from the “tidyverse” to help us manipulate, summarize, and visualize our data. Today’s session will focus on data manipulation using a package called {dplyr}.\n\nWhat is {dplyr}\nData manipulation is the foundation of working with data in R and as such is foundational to the work we do as epidemiologists. In particular, data manipulation skills will be critical when trying to clean our data.\nIn R, the package {dplyr} provides a large number of functions to help us manipulate data frames and perform many of the tasks that we will need to use on a daily basis, for example:\n\nSubsetting our data to remove certain variables\nRenaming certain variables\nAdding or modifying a variable\nRemoving duplicate entries\n\nIn {dplyr} each of these actions can be done with a particular function, which typically have an intuitive verb for a name. For example, renaming columns will use the function rename().\nIn today’s session we will look at the “data manipulation verb”, ie the function, needed for each of the above tasks as well as how to chain them all together into an efficient data pipeline.\n\n\n\n\n\n\nNote\n\n\n\nYou may have noticed that we asked you to load a package called {tidyverse} rather than {dplyr} in the setup. Loading {tidyverse} will load several of the most useful packages from the broader tidyverse, including {dplyr} and a couple other packages that we will see later in the session."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#basic-data-verbs",
    "href": "sessions_core/03_data_verbs.html#basic-data-verbs",
    "title": "Data Manipulation, Basics",
    "section": "Basic Data Verbs",
    "text": "Basic Data Verbs\n\nSelecting Specific Columns\nA lot of the time when we receive a dataset it will have extra columns that we don’t need, either because those columns contain sensitive data or because our analysis will only focus on a subset of the data. This is where a function like select() comes in handy.\nHere is the basic syntax, note that this is pseudo-code and isn’t something you are intended to run yourself.\n\n# DO NOT RUN (PSEUDO-CODE)\nselect(df_raw, first_column_to_keep, second_column_to_keep)\n\nHere we see that the first argument is our dataset and each subsequent argument is the name of a column that we would like to keep. In the tidyverse, variables (ie column names) don’t need to be put into quotation marks. So for example, if we want to select the columns id, sex, and age we can use the following:\n\nselect(df_raw, id, sex, age)\n\n\nUse select() to select the following variables in your dataset: id, sex, age, sub_prefecture, date_onset, and outcome. The head of your output should look something like this:\n\n\n  id   sex age date_onset   outcome\n1  1 femme  36 2022-08-13 recovered\n2  2     f   5 2022-08-18      &lt;NA&gt;\n3  3     f 156 2022-08-17 recovered\n4  6 homme   8 2022-08-22 recovered\n5  7     m   7 2022-08-30 recovered\n6 10     m   4 2022-08-30 recovered\n\n\n Take a look at this output and then at df_raw. We can see that df_raw still contains all of the columns, which is what we want. But can you tell why it didn’t change?\n\nOften, we want to keep most of the variables in our dataset and only remove one or two. We can use the above syntax to do this, but it can become pretty tedious to write out every column name. In these cases, instead of telling select what to **keep**, we can use a subtraction sign (-) to tell it what to **remove**. For example, if we wanted to remove thevillage_commune` column from our dataframe we can use the following:\n\nselect(df_raw, -village_commune)\n\nWay easier!\n\nUse the - syntax in select() to select all of the columns in df_raw except: full_name and age_unit from your dataset.\n\n\n\nRenaming Columns\nAnother common issue when we get new datasets is that the variable names are inconvenient. In those cases, rename() can work wonders. Here’s the basic syntax:\n\n# DO NOT RUN (PSEUDO CODE)\nrename(df,\n       new_column_name = old_column_name,\n       another_new_name = another_old_name)\n\nAs in the case of select(), and indeed in essentially all {dplyr} verbs, the first argument is our daframe. Then each subsequent argument is a statement of new_column_name = old_column_name telling R which columns to rename and the new names that we want to use, with each pair given its own line to improve readability. If we wanted to change village_commune to simply be village, for example, we can write:\n\nrename(df_raw,\n       village = village_commune)\n\n\nUse rename() on df_raw to change the columns sub_prefecture, village_commune, and health_facility_name to be prefecture, village, and facility respectively.\n\nIn the above exercise it may have been difficult to check if the output looked correct because R would have printed out the full data frame. In these cases it can be helpful to create a temporary object just to check if everything looks alright. You can call this object whatever you want, but a common name is tmp.\n\nRepeat the last exercise but this time assign the output to an object called tmp and use names() to check that the column names changed as you expected. The output of names() should give you something like this:\n\n\n [1] \"id\"                \"full_name\"         \"sex\"              \n [4] \"age\"               \"age_unit\"          \"region\"           \n [7] \"prefecture\"        \"village\"           \"date_onset\"       \n[10] \"date_consultation\" \"hospitalisation\"   \"date_admission\"   \n[13] \"facility\"          \"malaria_rdt\"       \"fever\"            \n[16] \"rash\"              \"cough\"             \"red_eye\"          \n[19] \"pneumonia\"         \"encephalitis\"      \"muac\"             \n[22] \"vacc_status\"       \"vacc_doses\"        \"outcome\"          \n[25] \"date_outcome\"     \n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nTemporary objects, like the tmp data frame you just created are just that: temporary. They are usually used to test if something has worked and designed to be overwritten each time you need to test something else. As such, you should not use these temporary objects as the input for other parts of your code. If you want to make a data frame that will be reused, such as a clean version of df_raw, this should be done using an object with a proper name like df or df_clean.\n\n\n\n\nChanging and Adding Columns\nSo now we know how to select and rename columns, but how do we modify them? This is where mutate() comes into play. This function can be used both to add new columns and to change existing ones.\nLet’s start with the basic mutate() syntax needed to add a new column:\n\n# DO NOT RUN (PSEUDO-CODE)\nmutate(df,\n       new_column = action(existing_column),\n       another_new_column = another_action(another_existing_column))\n\nIn the above code, we are creating a new column (new_column) by performing some sort of action (action()) on an existing column in the dataframe (existing_column). This action could be anything, it could use a function or be a simple arithmetic operation and can use one or more columns. For example, if we wanted to create a new column expressing MUAC in cm we could use the following:\n\nmutate(df_raw,\n       muac_cm = muac / 100)\n\n\nUse mutate() to create a new column called age_years that expresses age in years rather than months. The head of your new age_years column should look like this:\n\n\n   age_years\n1  3.0000000\n2  0.4166667\n3 13.0000000\n4  0.6666667\n5  0.5833333\n6  0.3333333\n\n\n\nGreat! But what if instead of creating a new column we instead wanted to change an existing one? You just need to use the existing column name on the left side of the = instead of giving a new column name. For example, in the above MUAC code we would write:\n\nmutate(df_raw,\n       muac = muac / 100)\n\nWe might want to keep age in months as well as years, so we won’t reassign that column. But there are some other columns that could stand to be changed. There are a lot of reasons we might want to change a column, two of the most common ones are:\n\nThe format of a string needs changing\nThe data type of a column is incorrect\n\nOur dataset has both of these problems. For example, while it isn’t per se a problem that region and sub_prefecture are in all capitals, it also isn’t particularly nice. To fix this, we can use another function from the {tidyverse}, this time from a package called {stringr} to make these columns title case:\n\nmutate(df_raw,\n       region = str_to_title(region),\n       sub_prefecture = str_to_title(sub_prefecture))\n\n\nUse mutate() to update the format of malaria_rdt and outcome to use title case. The head of these two columns should now look something like this:\n\n\n  malaria_rdt   outcome\n1    Negative Recovered\n2    Negative      &lt;NA&gt;\n3    Negative Recovered\n4    Negative Recovered\n5    Negative Recovered\n6    Negative Recovered\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that we didn’t need to load {stringr} to do the above exercise. That’s because, like {dplyr} this package is loaded when we load the {tidyverse}.\n\n\nThat’s nicer. Now let’s consider the second issue, having variables with the wrong type.\n\nTake a look at the data type of your columns, do any of them look strange?  Hint. str() may be useful here.\n\nMost of the columns look ok, but it seems theres something strange with the dates. Some of them are character type and others are something called POSIXct. We would much rather have all of these columns use the simple Date type.\nTo convert to dates, we are going to call on yet another package from the the tidyverse, {lubridate}. In particular, we are going to use the function ymd(). For example:\n\nmutate(df_raw,\n       date_outcome = ymd(date_outcome))\n\n\nUse mutate() and ymd() to modify date_onset and date_admission to be Date type. Use a temporary data frame tmp to check that your code is doing what you want it to.\n\n\n\nRemoving Duplicates\nOk great! We know how to select, rename, and modify our data. Another task we will often need to do is removing duplicate entries. Fortunately this one is easily done using the function distinct(), which has the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\ndistinct(df)\n\nNotice that distinct only needs one argument by default, the dataset itself. This will look for and remove any duplicate observations in the data frame. There are some fancier ways of using distinct() that will look for duplication on certain variables only, but that’s outside of the scope of today’s session.\n\nUse distinct() to create a temporary data frame, tmp, that contains all the unique observations in df_raw. Compare the number of rows in tmp to that of df_raw. Did we have any duplicates?"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#the-pipe-operator",
    "href": "sessions_core/03_data_verbs.html#the-pipe-operator",
    "title": "Data Manipulation, Basics",
    "section": "The Pipe Operator",
    "text": "The Pipe Operator\nSo it looks like we have actually done quite a bit of cleaning while learning the core {dplyr} verbs. We should probably try to put some of the above steps together to start building a basic data cleaning pipeline. So far we haven’t been saving any of our changes, except perhaps to a temporary data frame. It would be nice to keep them in a new clean df object.\nFor example, if we want to effect the column renaming we did above to a reusable object we might write something like this:\n\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n\n\n\n\n\n\nTip\n\n\n\nIn general, it’s good practice to keep a raw version of your dataset, here df_raw, that remains unmodified in your code. This is so that you always have it available in your environment as a reference and is always available at the start of your cleaning pipeline to improve reproducibility.\n\n\nNow we have a new object, df that we can do more operations on. Brilliant. For example, if we now wanted to select everything except for full_name we could update the above code like this:\n\n# Step 1: Rename Variables\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n# Step 2: Select Variables to Keep\ndf &lt;- select(df,\n             -full_name)\n\nNotice that in this second step we are using df as the input of select() rather than df_raw because we want to continue working on our modified version of the data. Let’s say now we want to add a column of age in years:\n\n# Step 1: Rename Variables\ndf &lt;- rename(df_raw, \n             prefecture = sub_prefecture,\n             village = village_commune,\n             facility = health_facility_name)\n\n# Step 2: Select Variables to Keep\ndf &lt;- select(df,\n             -full_name)\n\n# Step 3: Add Age in Years\ndf &lt;- mutate(df,\n             age_years = age / 12)\n\nHm, ok well this is working but it is starting to get repetitive. With each step we are reusing the output of the last step and then updating the same data frame, df. It would be better if these actions could be chained together in a simpler way.\nThis is exactly what the pipe operator, |&gt; is for! The pipe has the following basic syntax:\n\n# DO NOT RUN (PSEUDO-CODE)\ninput |&gt; action()\n\nHere the input on the left side (input) is “piped into” the action on the right side (action()). So for example instead of writing:\n\nselect(df_raw, id, sex)\n\nWe could instead write:\n\ndf_raw |&gt;\n  select(id, sex)\n\n\nTry out the above code to see if it works.\n\nThis can be used to chain multiple actions together and you will often see tidyverse style code that uses pipes in the following way:\n\n# DO NOT RUN (PSEUDO-CODE)\ndf &lt;- df_raw |&gt;\n  first_action() |&gt;\n  second_action() |&gt;\n  third_action()\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that here each action in the pipe is given its own line. This is considered good practice as it makes your code easier to read and understand.\n\n\nSo, if we wanted to chain the example actions we saw above into a single pipe, we might write something like this:\n\ndf &lt;- df_raw |&gt;\n  rename(prefecture = sub_prefecture,\n         village = village_commune,\n         facility = health_facility_name) |&gt;\n  select(-full_name) |&gt;\n  mutate(age_years = age / 12)\n\nThat’s a lot easier than reassigning df after each step!\n\nLet’s see if we can put together what we learned above into a single pipeline! Use the pipe operator |&gt;, select(), rename(), mutate(), str_to_title(), ymd(), and distinct() to perform the following actions on df_raw and assign the output to a new data frame called df:\n\nRemove the variables full_name and age_unit\nRename the following variables:\n\nage becomes age_months\nsub_prefecture becomes prefecture\nvillage_commune becomes village\nhealth_facility_name becomes facility\n\nAdd a variable age_years with patient age in years\nUpdate region and prefecture to use title case\nUpdate all date columns to use Date type\nRemove any duplicate observations\n\nThe head of your final data should look something like this:\n\n\n  id   sex age_months  region prefecture        village date_onset\n1  1 femme         36 Mandoul   Moissala Sangana Koïtan 2022-08-13\n2  2     f          5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3     f        156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6 homme          8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7     m          7 Mandoul   Moissala      Tétindaya 2022-08-30\n6 10     m          4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             yes     2022-08-14\n2        2022-08-25             yes     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25              no           &lt;NA&gt;\n5        2022-09-02              no           &lt;NA&gt;\n6        2022-09-02             yes     2022-09-02\n                         facility malaria_rdt fever rash cough red_eye\n1 Hôpital du District de Moissala    negative    No &lt;NA&gt;   Yes      No\n2 Hôpital du District de Moissala    negative    No   No   Yes      No\n3                      CS Silambi    negative   Yes &lt;NA&gt;    No      No\n4 Hôpital du District de Moissala    negative    No   No    No    &lt;NA&gt;\n5                      CS Silambi    negative  &lt;NA&gt;   No   Yes     Yes\n6                    Moissala Est    negative   Yes   No    No    &lt;NA&gt;\n  pneumonia encephalitis muac vacc_status vacc_doses   outcome date_outcome\n1        No           No  244        &lt;NA&gt;       &lt;NA&gt; recovered   2022-08-18\n2      &lt;NA&gt;           No  232          No       &lt;NA&gt;      &lt;NA&gt;   2022-08-28\n3        No         &lt;NA&gt;  123  Yes - oral       &lt;NA&gt; recovered         &lt;NA&gt;\n4        No           No  210          No       &lt;NA&gt; recovered         &lt;NA&gt;\n5        No           No   80          No       &lt;NA&gt; recovered         &lt;NA&gt;\n6        No           No  220          No       &lt;NA&gt; recovered   2022-09-03\n   age_years\n1  3.0000000\n2  0.4166667\n3 13.0000000\n4  0.6666667\n5  0.5833333\n6  0.3333333\n\n\nHint. Be careful with your column names here! If you renamed something you will need to use the new names for any subsequent parts of the pipe.\n\nAmazing! That looks like a great start at a data cleaning pipeline. Keep this code handy, you will use it in the next session where we will look at another common part of data cleaning: recoding."
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#done",
    "href": "sessions_core/03_data_verbs.html#done",
    "title": "Data Manipulation, Basics",
    "section": "Done!",
    "text": "Done!\nWell done, you’ve learned the fundamentals of data manipulation and how to string multiple commands together into a data manipulation pipe. Moving forward, solution files will focus less on being “exercise by exercise” and rather provide an example of what a real script might look like in a real world context. In this case, the solutions will then focus only on the final pipe that is created at the end of the session.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/03_data_verbs.html#going-further",
    "href": "sessions_core/03_data_verbs.html#going-further",
    "title": "Data Manipulation, Basics",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nA a line to your mutate() to update the hospitalisation variable so that its text would be in title case as well.\nPerhaps you would prefer to use lower case for the region column rather than the title case, update your code to do this instead. Hint: you might want to check out str_to_lower() from {stringr}.\nCreate a delay_consultation column, that contains the number of days between the onset of symptoms and the consultation."
  },
  {
    "objectID": "sessions_core/02_import_data.html",
    "href": "sessions_core/02_import_data.html",
    "title": "Data Importation",
    "section": "",
    "text": "Create a RStudio Project\nSet up an organized and well documented code\nInstall and load packages\nWrite robust file paths\n\nImport and inspect data\n\n\n\n\n\n\n\nImportant\n\n\n\nThe principles you learned in the Introduction to R session will apply here as well: we should do our best to ensure that our projects won’t just work today but can also be reused and shared in the future. While doing this is not always easy, there are several best practices that can help us, and one of the most important is to start with a good, organized code base."
  },
  {
    "objectID": "sessions_core/02_import_data.html#objectives",
    "href": "sessions_core/02_import_data.html#objectives",
    "title": "Data Importation",
    "section": "",
    "text": "Create a RStudio Project\nSet up an organized and well documented code\nInstall and load packages\nWrite robust file paths\n\nImport and inspect data\n\n\n\n\n\n\n\nImportant\n\n\n\nThe principles you learned in the Introduction to R session will apply here as well: we should do our best to ensure that our projects won’t just work today but can also be reused and shared in the future. While doing this is not always easy, there are several best practices that can help us, and one of the most important is to start with a good, organized code base."
  },
  {
    "objectID": "sessions_core/02_import_data.html#setting-up-your-project",
    "href": "sessions_core/02_import_data.html#setting-up-your-project",
    "title": "Data Importation",
    "section": "Setting up your Project",
    "text": "Setting up your Project\n\nFolder Structure\n\nIf not done already, download and unzip the course folder. Save the uncompressed folder to a location that is not connected to OneDrive and navigate into it.\n\n\n\n  Course Folder\n\n\n\n\nThis folder gives an example of a typical (and highly recommended) structure for your code projects:\n\n📁 data\n\n📁 clean\n📁 raw\n\n📁 R\n📁 outputs\n\nThis folder will be you working directory for all the sessions of this course. You will create an Rstudio project in it (explanations below), and save all your scripts in /R. The course datasets are already in data/raw.\n\n\nDefinitions\nTo work through this session you need to understand the two following concepts:\nWorking directory. The working directory is the location (folder) where your R session is actively working. If you save a file, for example, it will be saved into this folder by default. Similarly, when you want to open a file, this folder will be shown by default. All relative paths will be relative to this working directory. By default, R usually picks the “Documents” folder as the working directory on Windows machines.\nRoot. The root refers to the top-most folder level of the working directory. If your course folder was called FETCHR, the root would then be directly inside it (as opposed to being inside one of its subfolders like R or Data).\n\n\nRStudio Projects\nAn RStudio Project can be used to make your life easier and help orient RStudio around the various files used in your code\nAs a quick reminder, your interface should look something like this:\n\n\n\n\n\n\nFigure 1: Screenshot of a typical Rstudio interface\n\n\n\n\nOpen RStudio and create a new project by clicking File &gt; New Project &gt; Existing Directory &gt; Browse, navigating into (opening) the course folder, and clicking Create Project.\n\n\nIn the Windows Explorer, look at the course folder. You should now see a new file with the extention .Rproj that has a small blue icon with an R in it.\n\n\n\n\nIcon associated with RStudio projects\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you don’t see this file, it’s probably because it is hidden by default on your computer. To change this setting in Windows Explorer, go into the View menu and select Filename Extensions.\n\n\nWhen you open an RStudio Project, RStudio starts a new R session, opens the associated project files, and sets your working directory to the root of the course folder. At this time, RStudio also displays the subfolders of this directory in the panel on the bottom right.\n\n\n\n\n\n\nTip\n\n\n\nIt is strongly recommended to set up a separate RStudio Project for each of your analyses to ensure that your project files remain organized and manageable.\n\n\nThere are several ways to open an RStudio Project:\n\nUse the RStudio menu File &gt; Open Project and then select the relevant .Rproj file\nClick on the Project: (none) button on the top right of the RStudio interface\nNavigate in the folder explorer to the analysis folder and double click on the file with the .Rproj extension\n\n\n\nRStudio Options\nBefore continuing, let’s update some of RStudio’s problematic default settings:\n\nOpen the global options (Tools &gt; Global Options) and open the tab General (left menu). Make sure that none of the boxes in the sections R Sessions, Workspace, or History are checked.\n\n\n\n\nScreenshot of the Rstudio options\n\n\nWhen checked, these options cause RStudio to save the objects in your environment and reload them as well as any files you previously had open when you open a new R session. While these default may seem like a good idea, it is better to always start your work from a fresh, empty R session to avoid bugs.\n\n\n\n\n\n\nImportant\n\n\n\nRemember that any commands or outputs that is needed for the cleaning and analysis should be saved explicitly in a script in the correct, functional order."
  },
  {
    "objectID": "sessions_core/02_import_data.html#creating-a-new-script",
    "href": "sessions_core/02_import_data.html#creating-a-new-script",
    "title": "Data Importation",
    "section": "Creating a New Script",
    "text": "Creating a New Script\n\nOpen a new script and save it in the R folder of your project under the name import_data.R.\nAdd some metadata to the top of the script as seen in the first session using comments. Be sure to include:\n\nTitle\nAuthor\nCreation Date\nDescription\n\n\nNow you’re ready to start coding!"
  },
  {
    "objectID": "sessions_core/02_import_data.html#sec-packages",
    "href": "sessions_core/02_import_data.html#sec-packages",
    "title": "Data Importation",
    "section": "Packages",
    "text": "Packages\nPackages are collections of functions that extend the functionality of R. You’ll use them a lot, both in this course and in your daily life. Fortunately, as an open source language, R packages can be downloaded and installed for free from the internet.\n\n\n\n\n\n\nNote\n\n\n\nIn R, packages are referenced using {}. For example {ggplot2} is the name of the ggplot2 package that contains new plotting functions such as ggplot(), geom_point() etc…\n\n\n\nInstallation\nWe can install a new package using the function install.packages(), which downloads and installs it into the package library on your computer. This is done once per computer.\n\ninstall.packages(\"here\") # install the {here} package\n\nDon’t forget to wrap the package name in quotation marks when using install.packages(). What happens if you don’t do this?\n\n\n\n\n\n\nNote\n\n\n\nIf you are following this session as part of a course, to avoid any potential internet connectivity issues during the training we already had you install most of the course packages.\nIf are following this tutorial on your own or have not installed the packages yet, you will have to manually install each new package that we encounter.\n\n\n\n\nUsage\nOnce a package is installed we can use it but we have to specify to R that we will be using it every single session. This process is called loading the package and is achieved using the function library().\n\nlibrary(here) # load the \"here\" package\n\n\nUse the library() function to load the packages here and rio, which will be used in the next section.\n\nBased on your computer’s set up and the package you are trying to load, you may get a warning message noting that some functions have been masked or that the current version of the package was built for a different version of R. These messages are not usually a problem but are still important to note.\n\nTry to run the following code. Can you work out what the error means?\n\nlibrary(ggplot)\n\n\nThe above code throws an error because you have asked for a library that doesn’t exist. Remember that R is fickle and case sensitive and many of your errors will come from small typos in the names of functions or objects. Here, for example, we wanted to load the package ggplot2 but wrote ggplot instead.\n\n\n\n\n\n\nTip\n\n\n\nMost of the time, you’ll need to load a number of packages for your script and it is recommended to have a section at the start of your code that loads everything you’ll need in one place:\n\n# Packages ----------------------------\nlibrary(tidyverse)   # data manipulation\nlibrary(lubridate)   # date manipulation\n\nThis practice makes it easy to tell which packages need to be installed to run a script.\n\n\n\nUse comments to create a “Packages” section to your script.\n\n\n\nUpdating Packages\nR has a very active community of developers and it’s pretty common for packages to be updated from time to time as their owners add in new functions and fix existing bugs. In order to update the packages in your library, you can go into the Packages tab of the bottom right panel and click Update. Don’t forget that you’ll need to be connected to the internet during this process.\n\n\n\n\n\n\nImportant\n\n\n\nSometimes packages are updated in a way that might remove or change a function that you used in some of your scripts, causing your code to no longer work. Don’t panic if this happens. The best practice is to adapt your code, although in the worst case scenario you can forcibly install an old version of a package. This is however out of the scope of this session."
  },
  {
    "objectID": "sessions_core/02_import_data.html#data-importation",
    "href": "sessions_core/02_import_data.html#data-importation",
    "title": "Data Importation",
    "section": "Data Importation",
    "text": "Data Importation\n\nUnderstanding File Paths\nTo open a file in R you need to provide a file path. A file path is simply a longer name for a file, that includes not only its name but also its location on your computer. There are several ways of defining these paths, including absolute and relative paths.\n\nAbsolute Paths\nAbsolute paths are specific to your computer and go all the way up to the level of your hard drive. For example, an absolute path may look something like this: D:/OneDrive - MSF/Documents/monitoring/cholera/fancy_project/data/raw/example_linelist.xlsx. Clearly, this path will only work on one specific computer.\nThe use of hard coded absolute paths is strongly discouraged as it makes your code inflexible and prone to break: the paths need to be updated every time your code is shared or the project folder is moved on your computer.\n\n\nRelative Paths\nRelative paths are defined relatively to your current working directory. For example, keeping in mind that our handy .Rproj file set our working directory to the root of our project folder, we could create a relative path that looked like data/raw/example_linelist.xlsx. This means that as long as we maintain the internal structure of our project folder and have an .Rproj file, our code would theoretically run on multiple computers.\n\n\nRobust Paths with the here() function\nThe {here} package has a here() function that really helps defining paths. It has two advantages:\n\nWhen used with RStudio projects, you can give it only the part of the path within the project, (the relative path in other words), and the function uses it to create the absolute path dynamically.\nIt does so using the separator adapted to you operating system, whether it’s /, \\, or //\n\n\nlibrary(here)\nhere(\"data\", \"raw\", \"example_linelist.xlsx\")\n\n[1] \"D:/MATHILDE_UNPLUGGED/3_TRAINING/FETCH/repicentre/data/raw/example_linelist.xlsx\"\n\n\nSee how we only defined the relative path and the function created an absolute path. This way of defining the path will work on your colleagues computer, even if they run on another operating system, as long as you both respect the internal structure of the working directory.\nWe strongly encourage you to use here() whenever you need to create a file path.\n\nRun the above code in the console. What file path does here(\"data\", \"raw\") give you?\n\n\nUsing here(), create a complete file path for the file Moissalla-measles-linelist-EN.xlsx. Keep this path around, we will use it soon.\n\n\n\n\n\n\n\nImportant\n\n\n\nhere() simply creates a file path, it doesn’t actually check if a file exists on your computer: if the file is absent or there is a typo in your code, the command will yield an error when the path is used. If you would like to use a function to check if a file exists, check out the file.exists() function.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe will often want to source multiple data files in a single project. To make that process easier, it can be helpful to create a section at the start of the script, after loading the packages to define paths and store them in variables.\n\n\n\n\n\nImport function\nIn R different file formats are often imported using different, often specialized functions. This can be tedious as it requires you to memorize and load a large number of functions just to get your data imported. To avoid this problem, we recommend that you use the import() function from the package {rio}. This function is able to open a large variety of files (including Excel, csv, Stata, and many others) by recognizing the file extension of your data and calling a relevant specialized function from another package so that you don’t have to.\nBecause import() is actually just calling other functions in the background, it is possible that it will need different arguments depending on the type of file you want to load.\n\n\n\n\n\n\nTip\n\n\n\nTo see the full list of all the file types you can load (and save!) with rio, check out the list of supported formats on their website. In the rest of the lesson we will focus on importing data from Excel .xlsx files.\n\n\n\nImporting from the First Sheet\nIn general, the usage of import() is pretty simple, at minima you need to pass the path of the file to the file argument\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"))\n\nNotice that we have nested the command here() inside the import() command. Nesting functions is absolutely allowed in R and is something you will do all the time. When functions are nested, R will evaluate them in the order of the innermost function (in this case here()) to the outermost (in this case import()). In this way, the output of here() is being used as the input of import().\n\nImport the file Moissalla-measles-linelist-EN.xlsx that is in your raw data subfolder into R using here() and import().\n\nIf your import worked correctly, R will print the data into the console but not save it into the environment because we have not assigned them to an object.\n\n\n\n\n\n\nTip\n\n\n\nYou may not want to have R print very large datasets into the console and assign them directly to an object.\n\n\n\nReimport your data but this time save it to an object called df_linelist.\n\n\n\nImporting Data from Any Sheet\nAs you just saw, R selects the first sheet by default. It is however possible to pass the number (or name) of a specific worksheet in your Excel data to import() using the argument which:\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"),\n       which = 2)  # imports the second sheet\n\nNote that the which argument is specific to the file types that have multiple sheets, such as Excel or .Rdata files. If you try to use it on a .csv file the argument will be ignored."
  },
  {
    "objectID": "sessions_core/02_import_data.html#taking-a-first-look-at-your-data",
    "href": "sessions_core/02_import_data.html#taking-a-first-look-at-your-data",
    "title": "Data Importation",
    "section": "Taking a First Look at your Data",
    "text": "Taking a First Look at your Data\nWe have now imported a dataset into R and assigned it to a dataframe (df_linelist). The natural next step is to inspect this dataset, to check that the import went well, get to know it a bit better, and assess if it requires any cleaning before analysis.\nWe can start by taking a quick look at the first few lines of the dataframe using the function head(). This function takes a dataframe as its first argument and optionally accepts a second argument n indicating the number of lines we would like to see.\n\nhead(df_linelist, n = 10) # Inspect 10 first lines\n\n\nUse head() to examine the 12 first lines of df_linelist.\n\nWe can also check out our data by looking at the Environment tab of the top-right panel. Here, we can see our dataframe in the environment, look at its structure, or open it in the data viewer of RStudio.\n\nClick on the round blue button next to df_linelist in your environment to see its structure. Then click on the name of the dataset to open it in the viewer.\n\nThe data viewer displays dataframes as tables and is a convenient way to quickly look at your data. You can even sort and filter your data in the “View”, though be aware that these actions will not make any changes to the actual object df_linelist. The View can also be opened by passing the dataframe to the function View()."
  },
  {
    "objectID": "sessions_core/02_import_data.html#done",
    "href": "sessions_core/02_import_data.html#done",
    "title": "Data Importation",
    "section": "Done!",
    "text": "Done!\nWell done and don’t forget to save your code.\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_core/02_import_data.html#going-further",
    "href": "sessions_core/02_import_data.html#going-further",
    "title": "Data Importation",
    "section": "Going Further",
    "text": "Going Further\n\nExtra Exercises\n\nUse dim() to take a look at the dimensions of your dataset.\nUse str() to check the data type of each column. Does anything look odd? Remember that you can also use functions like is.character() and is.numeric() if you’d like to test the type of a particular column.\nUsing a function learned in the first session, can you extract the names of the columns of the dataset? Do these results match what you see when you open the data in Excel?\nTry passing your dataframe to the function summary(). What does this function tell you?\n\n\n\nAdditional Resources\n\nThe {rio} website\nMore examples on importing data of various file types"
  },
  {
    "objectID": "sessions_core/01_introduction.html",
    "href": "sessions_core/01_introduction.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Familiarize yourself with RStudio\nLearn how to work with the console\nCreate and execute a script\nCreate basic R objects, including vectors and data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.html#objectives",
    "href": "sessions_core/01_introduction.html#objectives",
    "title": "Introduction to R",
    "section": "",
    "text": "Familiarize yourself with RStudio\nLearn how to work with the console\nCreate and execute a script\nCreate basic R objects, including vectors and data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.html#exercise-format",
    "href": "sessions_core/01_introduction.html#exercise-format",
    "title": "Introduction to R",
    "section": "Exercise Format",
    "text": "Exercise Format\nThese exercises are in the format of a self-paced tutorial containing short explanations of key concepts, examples, and exercises for you to follow. The course uses a “learning by doing” approach, and while this first session will start with a lot of time exploring the RStudio interface, future sessions will focus heavily on having you write your own code.\nInstructions for exercises will be given in the following formats:\n\nThis is a general action block. You will typically see it at the beginning of a session with instructions about the setup for that lesson.\n Example: Open a blank new script and name it my_first_script.R.\n\n\nThis is a code block, it indicates a coding exercise where you will actually write your own code.\n Example: Create an object called region that contains the value \"Mandoul\".\n\n\nThis is an observation block, it will have instructions about something that you are expected to look at or investigate.\n Example: Inspect the RStudio interface.\n\nAs you move through these exercises, you may run into some errors, which occur when R is unable to complete a command. This can happen for many reasons: maybe you misspelled the name of an object, asked R to look for a file that doesn’t exist, or provided the wrong type of data to a function. Whenever an error occurs, R will stop any ongoing calculation and give you a message explaining what went wrong. Having errors is completely normal and happens to all programmers, novice and expert. Much like a natural language, R is something you will get better at the more you practice and work through your mistakes."
  },
  {
    "objectID": "sessions_core/01_introduction.html#rstudio-and-r",
    "href": "sessions_core/01_introduction.html#rstudio-and-r",
    "title": "Introduction to R",
    "section": "RStudio and R",
    "text": "RStudio and R\nR is a functional programming language that can be used to clean and manipulate data, run analyses (especially statistical ones), visualize results, and much more.\nRStudio is a piece of software that provides a user-friendly interface for R (also called an IDE, for Integrated Development Environment). While using a graphical interface isn’t required, it is strongly recommended for beginners.\n\nGetting Started with RStudio\nLet’s get started!\n\nOpen RStudio using the start menu or desktop shortcut; if RStudio is already open, please close it and open it again.\n\nYou should see an interface that looks something like this:\n\n\n\nView of the Rstudio IDE interface at opening\n\n\n\nInspect the RStudio interface.\n\nYou will have either three or four panels, including:\n\nUpper Right Corner\nTo the upper right there will be a panel with several tabs. Many of these are beyond the scope of this course, but we will use the following two tabs during the course:\n\nEnvironment. A list of the objects saved by the user in the current session. Because you’ve just started a new session, your environment should be empty.\nHistory. A record of all the commands you have executed during the current session.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can think of an R session like you would think of starting up a computer. Whenever a session starts, everything is blank and ready for computation in the same way that there aren’t any programs open when you first turn on your computer. In general, we encourage you to stop and start your R sessions regularly, you may just find that turning it off an on again will fix some of your bugs.\n\n\n\n\nBottom Right Corner\nTo the bottom right there will be another multi tab panel, including:\n\nFiles. A file explorer for the working directory, which is the folder location where R is currently working.\nPlots. A location where RStudio will display static visualizations; this tab should be empty for the moment.\nPackages. A list of all the R packages installed on your computer. Packages are collections of functions that help extend the functionality of R, and we will discuss them in greater detail in the next lesson.\nHelp. A place to read help pages and documentation for functions and packages.\nViewer. A location where RStudio will display html outputs such as tables, interactive widgets, or even full on dashboards.\n\n\n\nLeft Side\n\nTo the left (or bottom left if you have four panels) you should see the console, where R itself is run.\nTo the top left (if you have four panels) will be any open scripts.\n\nIn the next two sections, let’s talk about the console and scripts in more detail.\n\n\n\nThe Console\nThe console is where R itself is run.\nWhenever you open a new session, R will start by printing a bit of information about your set up, such as your R version number. Below this there should be a line containing the &gt; symbol and a blinking cursor. To run a command in R, you simply need to type it in after this &gt; and press Enter. R will then process your code and print the result (if there is one). A new &gt; line will then appear ready for the next command.\n\n\n\n\n\n\nImportant\n\n\n\nIf the last line shown in the console starts with a + instead of a &gt; that means the console is not ready for a new command either because it is still processing a previous one or because it received a bit of incomplete code. If at any point you would like to cancel an ongoing or incomplete command, press Esc.\n\n\n\nRun the following commands in the console one line at a time and observe the output.\n\n5 + 90\n\n6 * 171\n\n189 / 36.6\n\n92^3\n\n(12 + 9)^4 / 1000\n\nNow, run the following command. Note that the final ) is missing, making the command incomplete. What happens when you do this?\n\n3 / (2 + 97\n\n\nYou may have noticed in the above examples that our code includes a lot of spaces between characters. This is not by accident. It is considered best practice to include spaces around most operators, such as +, -, *, /, &lt;, &gt;, =, and &lt;-. Not only do these spaces make your code easier for other people to read and understand, in some (rare) cases they may even be necessary to avoid errors. That said, do be aware that there are a small number of operators that should not be surrounded by spaces, such as ^, . and :.\n\n1+29+4.8/3*3           # BAD\n1 + 29 + 4.8 / 3 * 3   # GOOD\n\n1 ^ 2 # BAD\n1^2   # GOOD\n\nWe can also run functions in the console. We will discuss functions in more depth later in this lesson, but meanwhile know that the idea of functions in R is very similar to the one in Excel, where you no doubt are familiar with functions such as SUM or MEAN.\n\nRun the following commands in the console (one line at a time).\n\n# Find the minimum value\nmin(5, 10)\nmin(1, 8, 56, 0.3)\n\n# Find the maximum value\nmax(568, 258, 314)\n\n\n\n\nScripts\nScripts are text files that contain a series of commands for a particular programming language. The extension of the file indicates which language the commands were written in, and we will be using .R. Scripts allow us to create code that can be reused, shared, and even automated.\n\nWriting Your First Script\n\n\n\nSteps to create a new script in the RStudio IDE\n\n\nTo create a new script, follow the menu File &gt; New File &gt; R Script. Alternatively, you can click on the small green + sign just below the File menu or use the keyboard shortcut CTRL+SHIFT+N. This new and unsaved script will appear as a blank document in the top left panel.\nTo save your script, either use the menu File &gt; Save As or the keyboard shortcut CTRL+S.\n\nCreate and save a new script called discovery.R. Don’t forget to include the .R extension. For now, you can save it on your Desktop or any convenient location, but we will talk more about organizing your scripts in the next session.\n\n\n\nExecuting Code from a Script\nTo run code from a script simply place your cursor on the line you wish to run (or select multiple lines) and do one of the following:\n\nClick the Run icon at the top right of the script panel\nUse the shortcut CTRL+Enter (cursor will move to the next line afterwards)\nUse the shortcut ALT+Enter (cursor will stay on the current line afterwards)\n\n\nCopy the code you ran in the previous exercises into your script and run it using each of the above methods.\nFrom now on, you will write your code in your script and execute it from there, unless told otherwise in the instructions.\n\n\n\nComments\nIn R, any text prefaced by a # (until the end of a line) is called a comment. R does not consider comments to be code and will ignore them whenever you run your scripts. This makes comments an excellent way to document your code.\n\n# This is a comment\n\n2 + 3  # This is also a comment\n\nIt is helpful to future you and others to start your scripts with a few commented lines providing some information about the file.\n\n#### IMPORT & PREPARE DATA ####\n# Author :  Mathilde Mousset\n# Creation Date : 23/11/2024\n# Last Update : 30/11/2024\n# Description : Import and clean measles surveillance data from Moissala\n\n\nAdd some comments to the top of your script describing it.\n\nComments are also a handy way to split longer scripts into thematic sections, such as “Data Importation”, “Analysis”, “Visualization”, etc. For example:\n\n# NAME OF SECTION 1 -----------------------------------------------             \n\n# NAME OF SECTION 2 -----------------------------------------------             \n\n\nUse comments to create sections in your script that correspond to the main sections in this tutorial.\n\nFinally, comments allow us write helpful notes for our colleagues (and our future selves) that can help them understand the code and why we wrote it the way we did. The general guidance is to focus on comments that explain the “why” rather than the “what”. This is because the “what” of well written code should be relatively self explanatory.\nThis comment, for example, is completely superfluous:\n\n1 + 3  # Code to add one to three\n\nBy comparison, here are a few use cases that would warrant comments:\n\nYou define a constant, say a seroprevalence threshold value. You may want to add a comment providing the reference for where the value comes from.\nYour code contains a value or file name that needs to be updated every week. You should indicate this with a comment to ensure that anyone else using the code is aware.\nYou use a rare command or package that your colleague may not know or may find counter intuitive. You can use a comment to explain the rational behind that decision.\n\nThat being said, you are learning, and the scripts you are writing during this course are your notes, so feel free to us as many comments (of the “what” and “why” sort) as you need. You will naturally write less comments in the future, when some of the things that seem alien now become natural.\n\n\n\n\n\n\nTip\n\n\n\nYou can comment a selected line with the shortcut CTRL+SHIFT+C.\nYou can add a first level section with CTRL+SHIFT+R.\n\n\n\nAdd some comments to describe the code that you’ve written thus far in your script."
  },
  {
    "objectID": "sessions_core/01_introduction.html#data-types",
    "href": "sessions_core/01_introduction.html#data-types",
    "title": "Introduction to R",
    "section": "Data Types",
    "text": "Data Types\nR has several different data types. The ones we will see most often in this course include:\n\nnumeric\nstring (text)\nboolean (TRUE / FALSE)\ndate\nfactor\n\n\nNumerics\nThe numeric type includes both integers and doubles (numbers that include a decimal) and can be created by simply writing the “naked” value into your script or console.\n\n\nStrings\nStrings are the R version of text and can be created by surrounding text with single or double quotation marks, for example \"district\" or 'cases' (double quotations are typically considered best practice).\n\nCompare the output in the console for the following commands:\n\n28         # numeric\n\"28\"       # text\n28 + \"28\"  # produces an error\n\n\nThe last command above will give an error because we cannot perform arithmetic operations that combine text and numbers.\n\n\n\n\n\n\nImportant\n\n\n\nR is case sensitive, meaning that the string \"ABC\" is not the same as \"abc\".\n\n\n\nIf you would like to create a string that contains a quotation mark the best practice is to escape the character by putting a \\ in front of it, ie: \"She said \\\"Hello\\\" then left\" or 'it\\'s a beautiful day'. Equivalently, if you used a double quotation to create the string you can use single quotes inside of it freely (ie: \"it's a beautiful day\") and vice versa (i.e.: 'She said \"Hello\" then left').\n\n\n\nBoolean (Logical)\nThe boolean (or “logical”) type stores true/false values and is created by writing either TRUE or FALSE without quotation marks.\nInternally, R thinks of TRUE and FALSE as being a special version of 1 and 0 respectively, and boolean values can be easily translated to these numeric equivalents for arithmetic operations.\n\n\n\n\n\n\nNote\n\n\n\nYou may find people using T or F but this is discouraged as T and F can also be used as object or variable names. TRUE and FALSE, however, are protected in R, meaning they cannot be reassigned to another value.\n\n\n\n\nDetermining the Type of an Object\nThere are several functions to determine the type of an object (often called the class of the object in R).\n\nType the following commands in your script and run them:\n\n# Get the Type of an Object\nclass(28)  \nclass(\"Mandoul\")\n\n# Test the Type of an Object\nis.numeric(28)\nis.numeric(\"Mandoul\")\nis.character(\"Mandoul\")\n\nis.numeric(TRUE)\nis.character(TRUE)\nis.logical(FALSE)"
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-assignement-operator",
    "href": "sessions_core/01_introduction.html#sec-assignement-operator",
    "title": "Introduction to R",
    "section": "Creating an Object",
    "text": "Creating an Object\nIn R, pretty much everything is an object, including functions, scalar values, and other more complex data structures. Before introducing these structures, let’s take an important detour to discuss how objects are saved into your environment.\nOften, we will want to reuse the same values or data throughout a script and it is therefore very useful to store them as objects in our environment. To do this we use the assignment operator, &lt;-.\n\nLook at the environment panel on the top right, verifying that it is empty, then type the following command in your script and run it to save a variable called cases into your environment.\n\ncases &lt;- 28\n\nLook at the environment again. Is it still empty?\n\nIf you’d like to access the value of your new object, cases, you simply need to execute its name.\n\ncases\n\n[1] 28\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe reason we need to wrap strings in quotation marks is actually to allow R to differentiate between strings (\"cases\" and object names cases).\n\n\nOnce created, objects can be used in other commands:\n\ncases + 5\n\n[1] 33\n\n\n\nFrom your script, create an object called region that contains the value \"Mandoul\". Do you see it in your environment?\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget that we should always surround &lt;- with spaces to improve readability and avoid errors.\n\nx&lt;-3     # BAD\nx &lt;- 3   # GOOD\n\n\n\n\nUpdating an Object\nWe often want to update the value stored in an object. To do this, we simply assign a new value with the same syntax we used to create it in the first place:\n\ncases &lt;- 32\n\n\nUpdate the value of region to \"Moyen Chari\".\n\n\n\nObject Names\nWhen naming your objects, there are a few (relatively) hard rules:\n\nDon’t start with a number\nDon’t use spaces (use a _ instead)\nDon’t use protected values (like TRUE and FALSE) or function names (like mean)\nDon’t use capital letters\n\nBeyond these hard rules, there are also more subjective best practices and personal styles. In general aim for names that are short and descriptive:\n\na &lt;- 19                             # BAD (not informative)\nage_du_patient_a_l_admission &lt;- 19  # BAD (too long)\nage &lt;- 19                           # GOOD\n\nGiving your objects clear and informative names helps to make your code readable, making it easy for others to understand without the need for checking the data dictionary every two seconds."
  },
  {
    "objectID": "sessions_core/01_introduction.html#data-structures",
    "href": "sessions_core/01_introduction.html#data-structures",
    "title": "Introduction to R",
    "section": "Data Structures",
    "text": "Data Structures\nUp until now we have looked only at simple objects that store single values, let’s now turn our focus to more complex structures that can store entire datasets.\n\nVectors\nWe can collect multiple values (such as numerics or strings) into a single object, called a vector.\nTechnically, there are several types of vectors, for example:\n\nSimple vectors (or atomic vectors) can only contain one type of values. For example, a numeric vector 2, 4, 6 or a string vector \"Mandoul\", \"Moyen Chari\".\nRecursive vectors (usually called lists) are far more complex and can contain multiple dimensions and types of data. We will not learn about them in this lesson.\n\nThis course will not go into detail on the more abstract concepts behind these structures and instead focus only on those you will encounter most often in your daily work.\n\nSimple Vectors\nSimple vectors can contain one or more values of a single data type, they thus have two key properties: length and type. For the purpose of this class, we will use the terms “simple vector” and “vector” interchangeably (as is typical in the R community).\nYou’ve technically already created your first simple vector when you built cases and region. These were simply vectors with a length of one. To create a vector with more than one value, we will use the function c() (mnemonic):\n\ncases &lt;- c(2, 5, 8, 0, 4)\n\n\nUpdate cases with the above values and update region to create a string vector containing the values: Mandoul, Moyen-Chari, Logone Oriental, Tibesti, and Logone Occidental.\n\nWe can now use functions on the objects we have created:\n\nmean(cases)      # calculate the mean value of the cases vector\n\n[1] 3.8\n\ntoupper(region)  # convert all the values in region to upper case\n\n[1] \"MANDOUL\"           \"MOYEN-CHARI\"       \"LOGONE ORIENTAL\"  \n[4] \"TIBESTI\"           \"LOGONE OCCIDENTAL\"\n\n\n\nLet’s use some functions! Try to write code that does the following:\n\nCalculate the sum of cases using the function sum()\nConvert the text in region to lowercase using the function tolower()\n\n\n\n\n\nAccessing the Values of a Vector\nIt is possible to access the value of a vector using square brackets containing the index (position) of the desired value, ie: [3] or [189].\n\ncases[2]   # 2nd value of cases\n\n[1] 5\n\ncases[10]  # 10th value of cases\n\n[1] NA\n\n\nOoops it does not exist! We will come back to what this NA means in the Missing Values section.\nWe can also access a range of values, just as we might do in Excel. To create a range we use the : operator to separate the desired minimum and maximum index:\n\ncases[2:4]  # 2nd to 4th values of cases\n\n[1] 5 8 0\n\n\n\nGet the 3rd value of region.\nWrite code to access the values “Mandoul” and “Moyen-Chari” in the vector region.\n\n\n\nData frames\nData frames are tabular structures / 2D tables with rows and columns. It is very similar to a “table” structure in Excel. As epidemiologists, this type of data structure is perhaps the most useful and you will likely use them on a daily basis, to store linelist data for example.\n\nCreating a data frame\nWe can create a data frame using the function data.frame():\n\ndata.frame(col1 = c(1, 4, 2, 9),\n           col2 = c(\"a bit of text\", \"some more text\", \"hello\", \"epidemiologists!\"))\n\n  col1             col2\n1    1    a bit of text\n2    4   some more text\n3    2            hello\n4    9 epidemiologists!\n\n\nSee how col1 was created from a numeric vector, and col2 from a vector of strings. Here we chose the names of the columns (col1 and col2), which is the normal way, but you can run the code without to see how R handles names by default.\n\nIn your script, create a data frame called data_cases that contains cases in one column and region in the other.\n\n\n\nExploring a data frame\ndata_cases should now appear in your environment. You can click on the blue circle with a white triangle in to see some additional information, or click on its name to open the object in the same pane as the scripts to view it.\n\n\n\nThe data_case data frame now appears in the Environment pane\n\n\nThere are several handy functions we can use to explore a data frame:\n\nRun the following commands and try to determine what type of information they are returning.\n\nstr(data_cases)     # STRucture of the object\ndim(data_cases)     # DIMension of the object\nnrow(data_cases)    # Number of ROWs\nncol(data_cases)    # Number of COLumns\nnames(data_cases)   # column NAMES\n\n\nLet’s practice a bit more! R comes with several built in data sets that can be accessed directly, including one called iris. It is convenient today as we have not learned to import data in R yet (don’t worry, we will work on linelist data from the second session then onwards).\nWe can see the first few lines of this data frame using the function head():\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nHow many rows and columns are there in iris? What are the names of its columns?\n\n\n\nAccessing Data in a data frame\nIn R, there are several methods for accessing the rows and/or columns of a data frame. In this introductory session we will focus on the [ ] syntax.\nWe use square brackets to access single values or ranges within our data frame. To do this we must give R both a row number (or range of rows) and column number/name (or range of columns), using the syntax [row, column].\n\ndata_cases[1, 2]          # the value of row one, column 2\n\n[1] \"Mandoul\"\n\ndata_cases[1, \"region\"]   # first value in the region column\n\n[1] \"Mandoul\"\n\n\nIf we want to access all of the rows (or columns) we can simple leave a space in the place of the number/name:\n\ndata_cases[1, ]           # values of all columns in row one\n\n  cases  region\n1     2 Mandoul\n\ndata_cases[2:4, ]         # values of all columns for rows 2 through 4\n\n  cases         region\n2     5       Sud Kivu\n3     8 Kasai oriental\n4     0          Kasai\n\ndata_cases[ , \"region\"]   # values of all rows for the region column\n\n[1] \"Mandoul\"        \"Sud Kivu\"       \"Kasai oriental\" \"Kasai\"         \n[5] \"Haut Katanga\"  \n\n\nWe can even select multiple non-consecutive indices by using a numeric vector:\n\ndata_cases[c(1, 3), ]  # lines 1 and 3 (all columns)\n\n  cases         region\n1     2        Mandoul\n3     8 Kasai oriental\n\n\nDo be careful, as the type of output returned when extracting data from a data frame can sometimes depend on the style of indexing used:\n\nstr(data_cases[1 , ])   # returns a data frame\n\n'data.frame':   1 obs. of  2 variables:\n $ cases : num 2\n $ region: chr \"Mandoul\"\n\nstr(data_cases[ , 1])   # returns a simple vector\n\n num [1:5] 2 5 8 0 4\n\n\nAnother syntaxt to extract the various columns of a data frame:\n\ndata_cases[2]           # returns the second column (as a data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\ndata_cases[\"region\"]    # returns the region column (as a data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\n\nNotice that these commands returned single-column data frames.\n\nWrite some code to:\n\nextract the third value in the region column of your data frame\n\nextract the second and third values of the cases column\n\ncalculate the sum of the cases column of your data frame"
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-missing-values",
    "href": "sessions_core/01_introduction.html#sec-missing-values",
    "title": "Introduction to R",
    "section": "Missing Values",
    "text": "Missing Values\nAs epidemiologists, we work with missing data all the time. In R, missing values are coded using a special value: NA (meaning Not Available). NA is somewhat unique in R as it doesn’t per se have a fixed type, rather, it will take on the type of the values around it. For example, an NA in a numeric column will then take on the numeric type. We will discuss the idea of missing data in more depth in later sessions of the course."
  },
  {
    "objectID": "sessions_core/01_introduction.html#sec-functions",
    "href": "sessions_core/01_introduction.html#sec-functions",
    "title": "Introduction to R",
    "section": "Functions",
    "text": "Functions\nFunctions are objects that contain commands (instead of values) that are run whenever the function is called. You are without doubt familiar with functions in Excel such as SUM or MEAN and the idea of functions in R is exactly the same.\nMost functions require some sort of input, such as a dataset or parameter. These inputs are called arguments and are normally named. For example, when we ran sum(cases), we provided the vector cases as the first (and only) argument to the function sum().\nOften, a function will have a combination of both required and optional arguments. The first argument of a function is almost always required and is typically a dataset. As an obligatory and rather obvious argument, most people omit its name when calling a function; ie: i.e. people will write mean(cases) instead of mean(x = cases). Optional arguments on the other hand are usually added using their name, i.e.: mean(x = cases, na.rm = TRUE).\nOptional arguments typically have default values and we only include them when we want to change their defaults (and thus change the default behavior of the function). For example, the na.rm argument of mean() determines whether R will ignore missing values when calculating a mean. The default state of the na.rm argument is FALSE, so by default, the mean performed on data with missing values will always return NA as the result:\n\nmean(c(1, 3, NA))\n\n[1] NA\n\n\nThis is true for many arithmetic operations in R. If we want R to calculate the mean on whatever data is available (and ignore the missing values) we need to explicitly set na.rm = TRUE:\n\nmean(c(1, 3, NA), na.rm = TRUE)\n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that arguments are separated by commas. These commas should always be followed by a space and whenever a named argument is used the = should be surrounded by spaces:\n\nmean(cases,na.rm=TRUE)     # BAD\nmean(cases, na.rm = TRUE)  # GOOD\n\nAs you work with increasingly complex functions, you may start to have a lot of arguments. For readability, it is typically recommended to split each argument onto its own line:\n\nmean(cases, \n     na.rm = TRUE) \n\n\n\nWhat happens if we put the arguments in the wrong order? If you provided the name of the arguments in you command, the function will still work exactly as expected. That being said, doing this would make your code harder to read and we encourage you to stick with a standard order of putting obligatory arguments like data first.\n\n# technically functional but hard to read:\nmean(na.rm = TRUE,  \n     x = cases) \n\n# better:\nmean(cases,         \n     na.rm = TRUE)\n\nOf course, if you mess up the ordering of arguments and didn’t include their names your code will not work as expected, or even throw an error:\n\nmean(TRUE, cases)   # not what you expect"
  },
  {
    "objectID": "sessions_core/01_introduction.html#done",
    "href": "sessions_core/01_introduction.html#done",
    "title": "Introduction to R",
    "section": "Done!",
    "text": "Done!\nThat’s all for this session, congratulations on taking your first steps with R and RStudio!\n\n\n\n Solutions file"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "This page will (eventually) contain external resources to continue your R learning journey."
  },
  {
    "objectID": "pathway.html",
    "href": "pathway.html",
    "title": "Pathway",
    "section": "",
    "text": "These sessions can be followed in order to get a baseline level in R. The series assumes no prior experience in R and is suitable for beginners.\nLooking for more? Want more flexibility? Consider browsing the full session catalog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "{repicentre}",
    "section": "",
    "text": "Welcome to {repicentre}\nAn open source platform to learn R for humanitarian contexts. What would you like to do?\n\n\n\n\n\nLearn Follow a linear path starting with the basics  Start\n\n\n\n\n\nExplore Browse our full catelogue of self paced tutorisals  Start\n\n\n\n\n\nExpand Go even further with a list of external resouces  Start"
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore",
    "section": "",
    "text": "Choose your own adventure by browsing all available sessions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\nCore\n\n\nVisualization\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourbes épidémiques hebdomadaires\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nApprenez à tracer des courbes épidémiques hebdomadaires et à améliorer les étiquettes des axes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Exploration\n\n\n\nSatellite\n\n\nData Exploration\n\n\n\nExplore your data after importation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\nCore\n\n\nRStudio\n\n\nData Import\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\nLogic\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploration des données\n\n\n\nSatellite\n\n\nData Exploration\n\n\n\nExplorez vos données après l’importation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceting\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nCreate a plot with multiple subplots (facets)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphiques multiples (facetting)\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nApprenez à créer plusieurs mini graphiques “par catégorie” en une seule commande\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportation des données\n\n\n\nCore\n\n\nRStudio\n\n\nData Import\n\n\n\nCréez un projet Rstudio, installez les paquets utiles et importez des données pour travailler dans R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\nCore\n\n\nR Basics\n\n\nData Types\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to data visualization with ggplot2\n\n\n\nCore\n\n\nVisualization\n\n\n\nApprenez les bases de la visualisation avec ggplot2, et créez votre première épicurve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction à R\n\n\n\nCore\n\n\nR Basics\n\n\nData Types\n\n\n\nVos premiers pas dans R. Familiarisez-vous avec Rstudio et avec les objets courants de R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\nCore\n\n\nSummary Tables\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurveillance\n\n\n\nSatellite\n\n\nSurveillance\n\n\n\nCompanion satellite to the surveillance Fetch-R module\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTableaux récapitulatifs\n\n\n\nCore\n\n\nTableaux de resumé\n\n\n\nCréer des tableaux récapitulatifs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraitement de données, les bases\n\n\n\nCore\n\n\nManipulation des données\n\n\nNettoyage des données\n\n\n\nUne introduction à la manipulation et au nettoyage des données à l’aide du paquet {dplyr}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraitement de données, recoder et filtrer\n\n\n\nCore\n\n\nManipulation des données\n\n\nNettoyage des données\n\n\nLogique\n\n\n\nApprenez à recoder vos variables avec {dplyr} et comment sélectionner les lignes d’un data frame suivant certains critères\n\n\n\n\n\n\nMar 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeekly Epicurves\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nPlot weekly epicurves and improve date labels on the x-axis\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#hey-there",
    "href": "about.html#hey-there",
    "title": "About",
    "section": "Hey There",
    "text": "Hey There\nWelcome to {repicentre}, an open source site developed by Epicentre to support folks learning R for humanitarian contexts. The site is composed of self paced tutorials and has two main options for learning:\n\nLinear. Designed for people with zero prior experience in R, the linear course will walk you through core R concepts using a case study about measles in Chad. The course covers the following concepts:\n\nData Structures and the RStudio Interface\nData Importation\nData Manipulation\nData Cleaning\nData Aggregation\nData Visualization\n\nChoose Your Own Adventure. If you have a bit more experience or if you are looking for a particular subject, feel free to explore the full range of tutorials. Tutorials are tagged with categories and designed to be self contained."
  },
  {
    "objectID": "about.html#recommendations-and-requests",
    "href": "about.html#recommendations-and-requests",
    "title": "About",
    "section": "Recommendations and Requests",
    "text": "Recommendations and Requests\nIs there a topic that you would like to see a tutorial on that isn’t currently available? Great! Feel free to let us know by opening an issue on the GitHub repository associated with this website. If you aren’t familiar with how to open an issue, please get in touch with Cat Eisenhauer instead."
  },
  {
    "objectID": "about.html#contributing",
    "href": "about.html#contributing",
    "title": "About",
    "section": "Contributing",
    "text": "Contributing\nWould you like to help write or maintain some tutorials? Increadible! Please get in touch with Cat."
  },
  {
    "objectID": "about.fr.html#salut",
    "href": "about.fr.html#salut",
    "title": "À Propos",
    "section": "Salut",
    "text": "Salut\nBienvenue sur {repicentre}, un site open source développé par Epicentre pour vous aider à apprendre R pour les contextes humanitaires. Le site est composé de tutoriels autodidactes et propose deux options principales d’apprentissage :\n\nLinéaire. Conçu pour les personnes n’ayant aucune expérience préalable de R, le cours linéaire vous guidera à travers les concepts de base de R en utilisant une étude de cas sur la rougeole au Tchad. Le cours couvre les concepts suivants :\n\nStructures de données et l’interface RStudio\nImportation de données\nManipulation de données\nNettoyage des données\nAgrégation de données\nVisualisation des données\n\nExploration. Si vous avez un peu plus d’expérience ou si vous recherchez un sujet particulier, n’hésitez pas à explorer la gamme complète des tutoriels. Les tutoriels sont classés par catégories et sont conçus pour être autonomes."
  },
  {
    "objectID": "about.fr.html#recommandations-et-demandes",
    "href": "about.fr.html#recommandations-et-demandes",
    "title": "À Propos",
    "section": "Recommandations et demandes",
    "text": "Recommandations et demandes\nY a-t-il un sujet sur lequel vous aimeriez voir un tutoriel qui n’est pas encore disponible ? C’est très bien ! N’hésitez pas à nous le faire savoir en ouvrant un “issue” sur le repo GitHub associé à ce site web. Si vous ne savez pas comment ouvrir un issue, veuillez contacter Cat Eisenhauer."
  },
  {
    "objectID": "about.fr.html#contribuer",
    "href": "about.fr.html#contribuer",
    "title": "À Propos",
    "section": "Contribuer",
    "text": "Contribuer\nVous souhaitez contribuer à la rédaction ou à la maintenance de tutoriels ? Incroyable ! Veuillez contacter Cat."
  },
  {
    "objectID": "explore.fr.html",
    "href": "explore.fr.html",
    "title": "Explorer",
    "section": "",
    "text": "Choisissez votre propre aventure en parcourant toutes les sessions disponibles.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\nCore\n\n\nVisualization\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourbes épidémiques hebdomadaires\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nApprenez à tracer des courbes épidémiques hebdomadaires et à améliorer les étiquettes des axes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Exploration\n\n\n\nSatellite\n\n\nData Exploration\n\n\n\nExplore your data after importation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\nCore\n\n\nRStudio\n\n\nData Import\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\nCore\n\n\nData Manipulation\n\n\nData Cleaning\n\n\nLogic\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploration des données\n\n\n\nSatellite\n\n\nData Exploration\n\n\n\nExplorez vos données après l’importation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceting\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nCreate a plot with multiple subplots (facets)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphiques multiples (facetting)\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nApprenez à créer plusieurs mini graphiques “par catégorie” en une seule commande\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportation des données\n\n\n\nCore\n\n\nRStudio\n\n\nData Import\n\n\n\nCréez un projet Rstudio, installez les paquets utiles et importez des données pour travailler dans R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\nCore\n\n\nR Basics\n\n\nData Types\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to data visualization with ggplot2\n\n\n\nCore\n\n\nVisualization\n\n\n\nApprenez les bases de la visualisation avec ggplot2, et créez votre première épicurve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction à R\n\n\n\nCore\n\n\nR Basics\n\n\nData Types\n\n\n\nVos premiers pas dans R. Familiarisez-vous avec Rstudio et avec les objets courants de R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\nCore\n\n\nSummary Tables\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurveillance\n\n\n\nSatellite\n\n\nSurveillance\n\n\n\nCompanion satellite to the surveillance Fetch-R module\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTableaux récapitulatifs\n\n\n\nCore\n\n\nTableaux de resumé\n\n\n\nCréer des tableaux récapitulatifs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraitement de données, les bases\n\n\n\nCore\n\n\nManipulation des données\n\n\nNettoyage des données\n\n\n\nUne introduction à la manipulation et au nettoyage des données à l’aide du paquet {dplyr}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraitement de données, recoder et filtrer\n\n\n\nCore\n\n\nManipulation des données\n\n\nNettoyage des données\n\n\nLogique\n\n\n\nApprenez à recoder vos variables avec {dplyr} et comment sélectionner les lignes d’un data frame suivant certains critères\n\n\n\n\n\n\nMar 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeekly Epicurves\n\n\n\nSatellite\n\n\nVisualization\n\n\n\nPlot weekly epicurves and improve date labels on the x-axis\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.fr.html",
    "href": "index.fr.html",
    "title": "{repicentre}",
    "section": "",
    "text": "Bienvenue à {repicentre}\nUne plateforme open source pour apprendre R dans les contextes humanitaires. Qu’aimeriez-vous faire ?\n\n\n\n\n\nApprendre Parcours linéaire en commençant par les bases  Start\n\n\n\n\n\nExplorer Catalogue complet de cours d’autoformation  Start\n\n\n\n\n\nRessources Ressources externes pour aller plus loin  Start"
  },
  {
    "objectID": "pathway.fr.html",
    "href": "pathway.fr.html",
    "title": "Cours",
    "section": "",
    "text": "Ces sessions peuvent être suivies afin d’obtenir un niveau de base dans R. La série suppose aucune expérience préalable dans R et convient bien aux débutants.\nVous en voulez plus ? Vous voulez plus de flexibilité ? Consultez le catalogue complet des sessions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\n\n\nYour first steps in R. Learn your way around Rstudio, and meet some common R objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Importation\n\n\n\n\n\nCreate an Rstudio project, install useful packages and start importing data to work in R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Basics\n\n\n\n\n\nAn introduction to data manipulation and cleaning using {dplyr}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation, Filtering and Recoding\n\n\n\n\n\nUsing {dplyr} and conditional logic to filter and recode data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Tables\n\n\n\n\n\nCreate summary tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Data Visualization\n\n\n\n\n\nLearn the basics of buidling plots with ggplot2, and create your first epicurve\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resources.fr.html",
    "href": "resources.fr.html",
    "title": "Ressources",
    "section": "",
    "text": "Cette page contiendra (éventuellement) des ressources externes pour poursuivre votre parcours d’apprentissage du R."
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html",
    "href": "sessions_core/01_introduction.fr.html",
    "title": "Introduction à R",
    "section": "",
    "text": "Se familiariser avec RStudio\nApprendre le fonctionnement de la console\nCréer et exécuter un script\nCréer des objets de base dans R, tels que des vecteurs et des data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#objectifs",
    "href": "sessions_core/01_introduction.fr.html#objectifs",
    "title": "Introduction à R",
    "section": "",
    "text": "Se familiariser avec RStudio\nApprendre le fonctionnement de la console\nCréer et exécuter un script\nCréer des objets de base dans R, tels que des vecteurs et des data frames"
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#format-des-exercices",
    "href": "sessions_core/01_introduction.fr.html#format-des-exercices",
    "title": "Introduction à R",
    "section": "Format des exercices",
    "text": "Format des exercices\nCes exercices sont dans un format tutoriel contenant de brèves explications sur les concepts clés, des exemples et des instructions à suivre. Notre approche est très orientée sur la pratique, et à l’exception de cette première session partiellement axée sur l’interface, vous aurez beaucoup d’occasions de coder.\nLes instructions pour les exercices seront données dans les formats suivants :\n\nCet encadré contient des instructions généralistes. Vous le trouverez en général au début d’une session, avec des instructions de mise en place.\n Exemple : Ouvrez un script vide et nommez-le mon_premier_script.R.\n\n\nCet encadré contient des instructions de code que vous devez écrire dans votre script ou la console.\n Exemple : Créez un objet region qui contient la valeur \"Mandoul\".\n\n\nCet encadré vous demande d’observer ou étudier quelque chose.\n Exemple : Inspectez l’interface de RStudio.\n\nAu cours de ces exercices, vous rencontrerez certainement des erreurs, qui se produisent lorsque R n’est pas en mesure d’exécuter une commande. Cela peut se produire pour de nombreuses raisons : une faute d’orthographe dans le nom d’un objet ou d’une fonction, le mauvais type de données fournis etc. Lorsqu’une erreur se produit, R arrête les calculs en cours et affiche un message expliquant ce qu’il s’est passé. Il est tout à fait normal d’avoir des erreurs, ça arrive tout le temps, à tous les programmeurs, qu’ils soient novices ou experts. Comme lorsque vous apprenez une langue (non informatique), vous vous améliorerez avec la pratique, en faisant des erreurs et en apprenant à les corriger."
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#rstudio-et-r",
    "href": "sessions_core/01_introduction.fr.html#rstudio-et-r",
    "title": "Introduction à R",
    "section": "RStudio et R",
    "text": "RStudio et R\nR est un langage de programmation fonctionnel qui peut être utilisé pour nettoyer et manipuler des données, effectuer des analyses (en particulier des analyses statistiques), visualiser des résultats, et bien plus encore.\nRStudio est un logiciel qui fournit une interface facile à utiliser pour R (également appelé IDE, pour “Integrated Development Environment”). Son utilisation n’est pas obligatoire, mais très fortement recommandée pour les débutants.\n\nPremiers pas avec RStudio\n\nOuvrez RStudio en utilisant le menu de démarrage de votre ordinateur ou le raccourci créé par défaut sur le bureau ; si RStudio était déjà ouvert, fermez-le et ouvrez-le à nouveau.\n\nVous devriez voir une interface qui ressemble à ceci :\n\n\n\nVue de l’interface de l’IDE Rstudio à l’ouverture\n\n\n\nInspectez l’interface de RStudio.\n\nVous verrez trois ou quatre panneaux.\n\nPanneau supérieur droit\nEn haut à droite se trouve un panneau avec plusieurs onglets. La plupart d’entre eux dépassent le cadre de ce cours, mais nous utiliserons les deux onglets suivants :\n\nEnvironment : liste les objets enregistrés par l’utilisateur dans la session en cours. Comme vous venez de démarrer une nouvelle session, votre environnement devrait être vide.\nHistory : comprend l’historique de toutes les commandes que vous avez exécutées au cours de la session actuelle.\n\n\n\n\n\n\n\nNote\n\n\n\nOuvrir une nouvelle session R, c’est comme redémarer son ordinateur : tout est vide et prêt pour le calcul, de la même manière qu’il n’y a aucun programme ouvert lorsque vous allumez votre ordinateur pour la première fois.\nNous vous encourageons à arrêter et à re-démarrer vos sessions R régulièrement. Parfois cela corrigera certains de vos problèmes !\n\n\n\n\nPanneau inférieur droit\nEn bas à droite se trouve un autre panneau comprenant les onglets suivants :\n\nFiles : un explorateur de fichiers pour le répertoire de travail, qui est l’emplacement du dossier dans lequel R travaille actuellement.\nPlots : là où RStudio affichera les graphiques statiques. Cet onglet devrait être vide pour le moment.\nPackages : liste de tous les paquets R installés sur votre ordinateur. Les paquets sont des collections de fonctions qui permettent d’étendre les fonctionnalités de R. Nous les aborderons plus en détail dans la prochaine leçon.\nHelp : un endroit pour lire les pages d’aide et la documentation pour les fonctions et les paquets.\nViewer : un emplacement où RStudio affichera des sorties html telles que des tableaux, des widgets interactifs ou même des tableaux de bord.\n\n\n\nPartie gauche\n\nA gauche (ou en bas à gauche si vous avez déjà quatre panneaux), vous devriez voir l’onglet console, où le code R est exécuté.\nEn haut à gauche (si vous avez quatre panneaux) se trouvent les scripts R ouverts.\n\n\n\n\nLa console\nLa console est l’endroit où le code R s’exécute.\nAu début d’une nouvelle session, un texte d’information sur votre cofiguration apparaît tout en haut de la console, dont le numéro et nom de la version de R. En dessous de ces informations, il y a une ligne avec le symbole &gt; et un curseur clignotant.\nPour exécuter une commande dans R, tapez-la à la suite du &gt; et pressez Entrée. R traitera alors votre code et affichera le résultat (s’il y en a un). Un nouveau &gt; s’affichera alors sur la ligne suivante, indiquant que la console est prête pour la commande suivante.\n\n\n\n\n\n\nImportant\n\n\n\nSi la dernière ligne est préfacée d’un + au lieu d’un &gt;, cela signifie que la console n’est pas prête. Soit elle attend qu’un calcul d’une commande précédente finisse, soit elle attend la fin d’une commande incomplète. A tout moment, vous pouvez interrompre l’exécution en pressant la touche Echap.\n\n\n\nExécutez les commandes suivantes dans la console, une ligne à la fois, et observez les résultats.\n\n5 + 90\n\n6 * 171\n\n189 / 36.6\n\n92^3\n\n(12 + 9)^4 / 1000\n\nExécutez maintenant la commande suivante. Notez que le ) fermant est manquant, ce qui rend la commande incomplète. Que se passe-t-il ?\n\n3 / (2 + 97\n\n\nVous avez peut-être noté dans les exemples précédents que notre code contient beaucoup d’espaces. C’est en effet une bonne pratique que d’inclure des espaces autour de la plupart des opérateurs, tels que +, -, *, /, &lt;, &gt;, = et &lt;-. Ces espaces facilitent la lecture et la compréhension de votre code, et dans certains cas (rares) ils permettent d’éviter des erreurs. Néanmoins, certains opérateurs ne doivent pas être entourés d’espaces, tels que ^, . et :.\n\n1+29+4.8/3*3           # Mauvais\n1 + 29 + 4.8 / 3 * 3   # Bien\n\n1 ^ 2  # Mauvais\n1^2    # Bien\n\nNous pouvons également exécuter des fonctions dans la console. Nous aborderons les fonctions plus en détail plus tard mais sachez que les fonctions dans R sont similaires aux fonctions dans Excel (telles que SOMME ou MOYENNE).\n\nExécutez les commandes suivantes dans la console (une ligne à la fois).\n\n# Trouvez la valeur minimale\nmin(5, 10)\nmin(1, 8, 56, 0.3)\n\n# Trouvez la valeur maximale\nmax(568, 258, 314)\n\n\n\n\nScripts\nLes scripts sont des fichiers texte qui contiennent une série de commandes pour un langage de programmation particulier. L’extension du fichier indique le langage dans lequel les commandes sont écrites. Ici nous utiliserons l’extension .R. Les scripts nous permettent de créer du code qui peut être réutilisé, partagé et même automatisé.\n\nÉcrire son premier script\nPour créer un nouveau script, allez dans le menu File &gt; New File &gt; R Script. Alternativement, cliquez sur la petite icône avec un + vert sur une page blanche située en dessous du menu File. Ou encore, utilisez le raccourci clavier CTRL + MAJ + N. Ce nouveau script non sauvegardé apparaîtra sous la forme d’un document vierge dans le panneau supérieur gauche.\n\n\n\nEtapes pour créer un nouveau script dans RStudio\n\n\nPour enregistrer votre script, utilisez le menu File &gt; Save As ou le raccourci clavier CTRL + S.\n\nCréez un script et enregistrez-le sous le nom decouverte.R(n’oubliez l’extension !). Pour l’instant, vous pouvez l’enregistrer sur votre bureau ou à tout autre endroit pratique, mais nous aborderons l’organisation des scripts dans la prochaine session.\n\n\n\nExécuter du code à partir d’un script\nPour exécuter du code à partir d’un script, placez votre curseur sur la ligne que vous souhaitez exécuter (ou sélectionnez plusieurs lignes) et effectuez l’une des opérations suivantes :\n\nCliquez sur le bouton Run en haut à droite de la fenêtre de script\nUtilisez le raccourci CTRL + Entrée (le curseur passera ensuite à la ligne suivante)\nUtiliser le raccourci ALT + Entrée (le curseur restera sur la ligne actuelle)\n\n\nCopiez le code que vous aviez exécuté dans la console lors des exercices précédents dans votre script et exécutez-le en testant les différentes méthodes ci-dessus.\nA partir de maintenant, vous écrirez votre code dans votre script et l’exécuterez à partir de là, sauf indication contraire de notre part.\n\n\n\nCommentaires\nDans R, le code qui est précédé d’un # (dièse) n’est pas exécuté, il est juste ignoré jusqu’à la fin de la ligne. C’est donc un bon moyen de documenter votre code.\n\n# Ceci est un commentaire\n\n2 + 3  # Ceci est aussi un commentaire\n\nIl est utile pour vous et vos collègues de commencer vos scripts par quelques lignes commentées fournissant des informations importantes sur le contenu de votre script.\n\n# IMPORT & PREPARATION DES DONNEES #\n# Auteure :  Mathilde Mousset\n# Date de création : 23/11/2024\n# Dernière mise à jour : 28/01/2024\n# Description : Importat et nettoyage des données de surveillance rougeole de Moissala\n\n\nAjoutez quelques commentaires au début de votre script pour le décrire.\n\nLes commentaires sont également un moyen pratique de diviser les scripts longs en sections thématiques, telles que “Import des données”, “Analyse”, “Visualisation”, etc. Par exemple :\n\n# NOM DE LA SECTION 1 -----------------------------------------------             \n\n# NOM DE LA SECTION 2 -----------------------------------------------             \n\n\nUtilisez les commentaires pour créer des sections dans votre script qui correspondent aux sections principales de ce tutoriel.\n\nEnfin, les commentaires permettent de prendre des notes sur votre code pour aider à la compréhension (celle de votre “moi futur” et celle de vos collègues). On entend souvent le conseil de se focaliser sur les commentaires qui expliquent le “pourquoi” plutôt que le “quoi”, car le “quoi” d’un code bien écrit devrait être clair.\nPar exemple, ce commentaire est superflu :\n\n1 + 3  # Code pour additionner un et trois\n\nEn comparaison, voici quelques cas où un commentaire est mérité :\n\nVous définissez une constante, une valeur seuil de séroprévalence par exemple. Ajoutez un commentaire indiquant la référence d’où provient la valeur.\nVotre code contient une valeur ou un nom de fichier qui doit être mis à jour chaque semaine. Indiquez le dans un commentaire afin que toute personne utilisant le code en soit informée.\nVous utilisez une commande contre-intuitive de premier abord, ou un paquet rare que votre collègue ne connaît peut-être pas. Commentez pour expliquer vos raisons.\n\nCeci étant dit, vous êtes en plein apprentissage, et les scripts que vous écrivez pendant ce cours sont l’équivalent de vos notes de cours, alors n’hésitez pas à utiliser autant de commentaires que vous le souhaitez pour expliquer les commandes et vous rappeler de ce qu’elles font. Vous écrirez naturellement moins de commentaires avec la pratique, lorsque les choses qui nouvelles aujourd’hui deviendront naturelles.\n\n\n\n\n\n\nTip\n\n\n\nCommentez une ligne sélectionnée avec le raccourci CTRL + MAJ + C.\nAjoutez une section de premier niveau avec CTRL + MAJ + R.\n\n\n\nAjoutez quelques commentaires pour décrire le code que vous avez écrit jusqu’à présent dans votre script."
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#types-de-données",
    "href": "sessions_core/01_introduction.fr.html#types-de-données",
    "title": "Introduction à R",
    "section": "Types de données",
    "text": "Types de données\nR dispose de plusieurs types de données. Ceux que nous verrons le plus souvent dans ce cours sont les suivants :\n\nnumérique [numeric en anglais]\nchaîne de caractères (texte) [string en anglais]\nbooléen (VRAI / FAUX) [boolean en anglais]\ndate [date]\nfacteur [factor]\n\n\nNumérique\nLe type numérique englobe les entiers [integers en anglais] et les doubles (nombres décimaux). Les nombres en R n’ont pas de signalétique, tapez simplement la valeur brute dans votre script ou votre console.\n\n\nChaînes de caractères\nLes chaînes de caractères [strings] représentent le texte en R. Elles sont tapées en entourant votre texte de guillemets simples ou doubles, \"district\" ou 'cas' par exemple (les guillemets doubles sont généralement considérés comme la meilleure pratique).\n\nComparez la sortie dans la console pour les commandes suivantes :\n\n28         # numérique\n\"28\"       # texte\n28 + \"28\"  # donne une erreur\n\n\nLa dernière commande ci-dessus a renvoyé une erreur car nous ne pouvons pas effectuer d’opérations arithmétiques combinant du texte et des nombres.\n\n\n\n\n\n\nImportant\n\n\n\nR est sensible à la casse (majuscules ou minuscules), ce qui signifie que \"ABC\" n’est pas équivalent à \"abc\".\n\n\n\nSi vous souhaitez créer une chaîne de caractères contenant des guillemets, il faut échapper les guillements les faisant précéder d’un \\. Par exemple : \"Elle dit \\\"Bonjour\\\" et s'en alla\" ou 'C\\'est une belle journée'. Si vous avez utilisé des guillements doubles pour créer votre chaîne de caractères, vous pouvez utiliser des guillemets simples à l’intérieur de celle-ci (par exemple : \"C'est une belle journée\") et vice versa (par exemple : 'Elle dit \"Bonjour\" et s'en alla').\n\n\n\nBooléen (logique)\nLe type booléen (ou logique) stocke des valeurs vrai/faux et est créé en écrivant soit TRUE [VRAI] ou FALSE [FAUX] sans guillemets.\nEn interne, R traduit TRUE et FALSE en équivalents numériques 1 et 0 respectivement, ce qui peut être utile pour des opérations arithmétiques.\n\n\n\n\n\n\nNote\n\n\n\nVous verrez peut-être des personnes qui utilisent T ou F mais c’est déconseillé car T et F peuvent également être utilisés comme noms d’objets ou de variables. En revanche, les valeurs TRUE et FALSE sont réservées (protégées), ce qui signifie qu’elles ne peuvent pas être réaffectés à une autre valeur.\n\n\n\n\nDéterminer le type d’un objet\nIl existe plusieurs fonctions permettant de déterminer le type d’un objet (souvent appelé la classe de l’objet en R [class].\n\nTapez les commandes suivantes dans votre script et exécutez-les :\n\n# Obtenir le type\nclass(28)  \nclass(\"Mandoul\")\n\n# Test du type\nis.numeric(28)\nis.numeric(\"Mandoul\")\nis.character(\"Mandoul\")\n\nis.numeric(TRUE)\nis.character(TRUE)\nis.logical(FALSE)"
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#sec-assignement-operator",
    "href": "sessions_core/01_introduction.fr.html#sec-assignement-operator",
    "title": "Introduction à R",
    "section": "Enregistrer un objet",
    "text": "Enregistrer un objet\nEn R, presque tout est un objet y compris les fonctions, les vecteurs et les structures plus complexes. Souvent, nous souhaitons réutiliser certains objets tout au long d’un script (un jeu de données par exemple). Il est donc très utile de les stocker dans notre environnement (la mémoire de R). Pour ce faire, nous utilisons l’opérateur d’assignation &lt;-.\n\nRegardez le panneau environnement en haut à droite. Il devrait être vide. Tapez la commande suivante dans votre script et exécutez-la. Elle enregistre une variable appelée cas dans votre environnement.\n\ncas &lt;- 28\n\nInspectez à nouveau l’environnement. Est-il toujours vide ?\n\nSi vous souhaitez accéder à la valeur de votre nouvel objet, cas il vous suffit d’exécuter son nom.\n\ncas\n\n[1] 28\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous écrivons les chaînes de caractères entre guillements pour permettre à R de faire la différence entre un objet cas et le texte \"cas\".\n\n\nUne fois créés, les objets peuvent être utilisés dans d’autres commandes :\n\ncas + 5\n\n[1] 33\n\n\n\nDans votre script, créez un objet appelé region qui contient la valeur \"Mandoul\". Est-il bien apparu dans votre environnement ?\n\n\n\n\n\n\n\nTip\n\n\n\nN’oubliez pas que nous devons toujours entourer l’opérateur &lt;- par des espaces afin d’améliorer la lisibilité et d’éviter les erreurs.\n\nx&lt;-3     # MAUVAIS\nx &lt;- 3   # BIEN\n\n\n\n\nMettre à jour d’un objet\nNous souhaitons souvent mettre à jour la valeur stockée dans un objet. Pour ce faire, il suffit d’assigner une nouvelle valeur avec la même syntaxe que celle utilisée lors de la création de l’objet :\n\ncas &lt;- 32\n\n\nMettez à jour l’objet region avec la valeur \"Moyen Chari\".\n\n\n\nNoms d’objets\nPour nommer vos objets, il existe quelques règles (relativement) strictes :\n\nNe pas commencer par un chiffre\nNe pas utiliser d’espaces (utiliser un _ à la place)\nNe pas utiliser de valeurs réservées (comme TRUE et FALSE) ou des noms de fonctions (comme mean)\nNe pas utiliser de majuscules (c’est plus une convention qu’une règle dure)\n\nAu-delà de ces règles, il existe également des bonnes pratiques plus subjectives et des styles personnels. En règle générale, les noms doivent être courts et descriptifs :\n\na &lt;- 19                              # Pas informatif\nage_du_patient_a_l_admission &lt;- 19   # Trop long\nage &lt;- 19                            # Concis et précis\n\nDes noms clairs et informatifs contribuent à rendre votre code plus lisible, ce qui permet aux autres de le comprendre facilement sans avoir à constamment consulter le dictionnaire de données."
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#structures-de-données",
    "href": "sessions_core/01_introduction.fr.html#structures-de-données",
    "title": "Introduction à R",
    "section": "Structures de données",
    "text": "Structures de données\nJusqu’à maintenant, nous avons créé des objets simples qui contenaient une seule valeur. A présent nous allons nous intéresser à des structures plus complexes qui peuvent contenir des jeux de données.\n\nVecteurs\nIl est possible de rassembler plusieurs valeurs (telles que des valeurs numériques ou des chaînes de caractères) en un seul objet, appelé vecteur.\nTechniquement, il existe plusieurs types de vecteurs, dont :\n\nles vecteurs simples (ou vecteurs atomiques) ne peuvent contenir qu’un seul type de valeurs. Par exemple, un vecteur d’entiers contenant 2, 4, 6 ou un vecteur de texte contenant \"Mandoul\", \"Moyen Chari\".\nles vecteurs récursifs (généralement appelés listes) sont plus complexes et peuvent contenir plusieurs dimensions et types de données. Nous ne les aborderons pas dans cette leçon.\n\nCette leçon n’entrera pas dans les détails abstraits de ces structures et se concentrera sur celles que vous rencontrerez le plus souvent dans votre travail.\n\nVecteurs simples\nLes vecteurs simples peuvent contenir une ou plusieurs valeurs d’un seul type de données. Ils ont donc deux propriétés essentielles : une longueur et un type. Dans le cadre de ce cours, nous utiliserons indifféremment les termes “vecteur simple” et “vecteur”, comme c’est généralement le cas dans la communauté R.\nTechniquement, vous avez déjà créé vos premiers vecteurs simples lorsque vous avez construit les objets cas et region. Il s’agissait de vecteurs avec une longueur de taille une. Pour créer un vecteur avec plus d’une valeur, nous utiliserons la fonction c() (moyen mnémotechnique) :\n\ncas &lt;- c(2, 5, 8, 0, 4)\n\n\nMettez à jour cas avec les valeurs ci-dessus et mettez à jour region pour créer un vecteur de chaînes de caractères contenant les valeurs suivantes : Mandoul, Moyen-Chari, Logone Oriental, Tibesti et Logone Occidental.\n\nNous pouvons maintenant utiliser des fonctions sur les objets que nous avons créés :\n\nmean(cas)  # Calcule la moyenne des valeurs stockées dans le vecteur\n\n[1] 3.8\n\ntoupper(region)  # Convertit les valeurs du vecteur en majuscules\n\n[1] \"MANDOUL\"           \"MOYEN-CHARI\"       \"LOGONE ORIENTAL\"  \n[4] \"TIBESTI\"           \"LOGONE OCCIDENTAL\"\n\n\n\nEcrivez des commandes dans votre script pour effectuer les actions suivantes :\n\ncalculer la somme des valeurs de cas avec la fonction sum()\nconvertir le texte de region en minuscules à l’aide de la fonction tolower()\n\n\n\n\n\nAccès aux valeurs d’un vecteur\nIl est possible d’accéder à une valeur d’un vecteur en donnant son indice (i.e. sa position dans le vecteur) entre crochets :\n\ncas[2]   # Deuxième valeur de cas\n\n[1] 5\n\ncas[10]  # Dixième valeur de cas\n\n[1] NA\n\n\nOups il n’y a pas de dixième valeur dans cas ! Nous reviendrons sur ce que ce NA signifie dans la section valeurs manquantes.\nNous pouvons également accéder à une plage de valeurs, comme nous pourrions le faire dans Excel. Nous utilisons l’opérateur : entre la position minimum et maximum de la plage :\n\ncas[2:4]  # de la deuxième à la quatrième valeur\n\n[1] 5 8 0\n\n\n\nAffichez la 3ème valeur du vecteur region.\nAccédez aux valeurs “Mandoul” et “Moyen-Chari” du vecteur region.\n\n\n\nData frames\nLes data frames sont des structures tabulaires / tableaux en 2D avec des lignes et des colonnes. Il s’agit d’une structure très similaire à celle d’un “tableau” dans Excel. En tant qu’épidémiologistes, ce type d’objet est l’un des plus utiles et vous l’utiliserez quotidiennement pour stocker des jeux de données (des listes linéaires par exemple).\n\nCréation d’un data frame\nNous créons un data frame avec la fonction data.frame() :\n\ndata.frame(col1 = c(1, 4, 2, 9),\n           col2 = c(\"un peu de texte\", \"plus de text\", \"Salut !\", \"les epidemiologistes !\"))\n\n  col1                   col2\n1    1        un peu de texte\n2    4           plus de text\n3    2                Salut !\n4    9 les epidemiologistes !\n\n\nIci, on a crée col1 à partir d’un vecteur numérique, et col2 à partir d’un vecteur de chaînes de caractères. Nous avons choisi les noms des colonnes (col1 et col2), ce qui est normal, mais vous pouvez exécuter le code sans nommer les colonnes pour voir comment R crée lui même des noms.\n\nDans votre script, créez un data frame nomé data_cas qui contient cas dans une colonne et region dans l’autre.\n\n\n\nExploration d’un data frame\nL’objet data_cas devrait maintenant apparaître dans votre environnement. Vous pouvez cliquer sur le cercle bleu avec un triangle blanc pour dérouler des informations supplémentaires, ou cliquer sur son nom pour le visualiser dans un onglet dans le même volet que votre script.\n\n\n\nLe data frame data_cas apparaît désormais dans l’onglet Environnement.\n\n\nIl existe plusieurs fonctions pratiques pour explorer un data frame :\n\nExécutez les commandes suivantes et essayez de déterminer le type d’informations qu’elles renvoient.\n\nstr(data_cas)     # STRucture de l'object\ndim(data_cas)     # DIMension de l'object\nnrow(data_cas)    # Nombre de lignes (row = ligne)\nncol(data_cas)    # Nombre de COLonnes\nnames(data_cas)   # noms des colonnes\n\n\nPratiquons un peu plus ! R est livré avec quelques data frames intégrés auxquels il est possible d’accéder directement, dont un appelé iris. C’est pratique pour cette session car nous n’avons pas encore appris à importer des données dans R (ne vous inquiétez pas, nous travaillerons sur des données de liste linéaire dès la prochaine session !).\nNous pouvons afficher les premières lignes de ce data frame grâce à la fonction head() [head = la tête en anglais] :\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nCombien de lignes et de colonnes y a-t-il dans iris? Quels sont les noms des colonnes de ce data frame ?\n\n\n\nAccéder aux données d’un data frame\nEn R, il existe plusieurs méthodes pour accéder aux lignes et/ou colonnes d’un data frame. Dans cette session d’introduction, nous nous concentrerons sur la syntaxe [row, column].\nNous pouvons utiliser un numéro (ou un intervalle) de ligne pour extraire des lignes, et des numéros (ou un intervalle) de colonnes pour extraire les colonnes. Ont peut également utiliser le nom des colonnes pour y accéder.\n\ndata_cas[1, 2]    # Afficher la valeur de la ligne 1, deuxième colonne\n\n[1] \"Mandoul\"\n\ndata_cas[1, \"region\"]   # Afficher la valeur de la lignbe 1, pour la colonne région\n\n[1] \"Mandoul\"\n\n\nSi nous voulons isoler toutes les lignes (ou colonnes), nous pouvons simplement laisser un espace à la place du numéro/nom :\n\ndata_cas[1, ]  # Extrait la première ligne (garde toutes les colonnes)\n\n  cas  region\n1   2 Mandoul\n\ndata_cas[2:4, ]   # Valeurs des lignes 2 à 4, pour toutes les colonnes\n\n  cas         region\n2   5       Sud Kivu\n3   8 Kasai oriental\n4   0          Kasai\n\ndata_cas[ , \"region\"]   # Garde toutes les lignes mais que la colonne région\n\n[1] \"Mandoul\"        \"Sud Kivu\"       \"Kasai oriental\" \"Kasai\"         \n[5] \"Haut Katanga\"  \n\n\nNous pouvons même sélectionner plusieurs indices non consécutifs en utilisant un vecteur :\n\ndata_cas[c(1, 3), ]  # Ligne 1 et 3 (toutes les colonnes)\n\n  cas         region\n1   2        Mandoul\n3   8 Kasai oriental\n\n\nSoyez attentifs, le type de l’objet renvoyé par [ ] dépend de l’indexation utilisée :\n\nstr(data_cas[1 , ])   # Renvoit un data frame\n\n'data.frame':   1 obs. of  2 variables:\n $ cas   : num 2\n $ region: chr \"Mandoul\"\n\nstr(data_cas[ , 1])   # Renvoit un vecteur\n\n num [1:5] 2 5 8 0 4\n\n\nUne syntaxe simplifiée existe pour extraire des colonnes d’un data frame :\n\ndata_cas[2]           # Renvoit la deuxième colonne (format data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\ndata_cas[\"region\"]    # Renvoit la colonne région (format data frame)\n\n          region\n1        Mandoul\n2       Sud Kivu\n3 Kasai oriental\n4          Kasai\n5   Haut Katanga\n\n\n\nEcrivez le code pour :\n\nextraire la troisième valeur de la colonne region de votre data frame\nextraire les deuxième et troisième valeurs de la colonne cas\ncalculer la somme des valeurs de la colonne cas"
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#sec-missing-values",
    "href": "sessions_core/01_introduction.fr.html#sec-missing-values",
    "title": "Introduction à R",
    "section": "Valeurs manquantes",
    "text": "Valeurs manquantes\nEn tant qu’épidémiologistes, nous sommes constamment confrontés aux données manquantes. Dans R, celles-ci sont codées à l’aide d’une valeur spéciale : NA [signifiant Not Available]. La valeur NA n’a pas de type fixe, elle prend celui des valeurs qui l’entourent. Par exemple, un NA dans une colonne numérique est traitée comme une valeur numérique. Nous aurons des occasions de manipuler les NA dans la suite du cours."
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#sec-functions",
    "href": "sessions_core/01_introduction.fr.html#sec-functions",
    "title": "Introduction à R",
    "section": "Fonctions",
    "text": "Fonctions\nLes fonctions sont des objets qui contiennent des commandes (au lieu de valeurs) qui sont exécutées chaque fois que la fonction est lancée. Vous êtes sans doute familiers avec les fonctions dans Excel, telles que la fonction SOMME() ou la fonction MOYENNE(). Bonne nouvelle, les fonctions sont similaires dans R !\nLa majorité des fonctions que vous allez utiliser ont besoin d’informations complémentaires : a minima des données, mais aussi d’autres paramètres. On appelle ces informations des arguments. Les arguments sont normalement nommés.\nPar exemple, lorsque nous avons exécuté la commande sum(cas), nous avons fourni le vecteur cas comme premier (et seul) argument de la fonction sum().\nParmis les arguments d’une fonction, certains peuvent être obligatoires, d’autres facultatifs. Le premier argument est presque toujours obligatoire et est souvent un data frame ou un vecteur de données. Comme c’est un argument évident, on omet souvent son nom (il vous a sans doute semblé naturel de taper mean(cas) au lieu de mean(x = cas)).\nLes arguments facultatifs, en revanche, sont généralement utilisés avec neur nom. Par exemple : mean(cas, na.rm = TRUE). Les arguments facultatifs sont souvent fournis avec des valeurs par défaut raisonnables, ce qui fait que l’utilisateur ne les spécifie que lorsqu’il a besoin de changer ces valeurs par défaut. Par exemple, l’argument na.rm de la fonction mean() controle comment les valeurs manquantes sont gérées lors du calcul de la moyenne [“na” en référence aux valeurs manquantes NA, et “rm” comme raccourci de “ReMove”, que l’on peut traduire dans ce contexte par enlever ou ignorer]. Par défault, la valeur de na.rm est FALSE Ainsi, par défaut, la moyenne de données avec des valeurs manquantes renverra toujours NA :\n\nmean(c(1, 3, NA))\n\n[1] NA\n\n\nCeci est vrai pour de nombreuses opérations arithmétiques dans R. Si l’on veut que que R calcule la moyenne sur toutes les données disponibles et ignore les valeurs manquantes, nous devons explicitement fournir l’argument na.rm = TRUE:\n\nmean(c(1, 3, NA), na.rm = TRUE)\n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nLes arguments sont séparés par des virgules.\nCes virgules doivent toujours être suivies d’un espace\nChaque fois qu’un argument nommé est utilisé, l’attribut = doit être entouré d’espaces :\n\n\nmean(cas,na.rm=TRUE)     # MAUVAIS\nmean(cas, na.rm = TRUE)  # BON\n\nSi vous écrivez une commande avec de nombreux arguments, séparez chaque argument sur sa propre ligne pour améliorer la lisibilité :\n\nmean(cas, \n     na.rm = TRUE) \n\n\n\nQue se passe-t-il si l’on fournit plusieurs arguments dans le désordre ? Si vous avez nommé les arguments la fonction s’exécutera correctement, mais le code sera contre-intuitif et peu lisible. Nous vous conseillons de respecter l’ordre standard, en plaçant les arguments obligatoires tels que les données en premier.\n\n# Fonctionnel mais dur à lire\nmean(na.rm = TRUE,  \n     x = cas) \n\n# mieux\nmean(cas,         \n     na.rm = TRUE)\n\nEn revanche, si vous ne nommez pas les arguments et les passez dans le désordre, alors la fonction ne fonctionnera pas comme prévu, voire renverra une erreur :\n\nmean(TRUE, cas)  # Pas ce que vous attendez"
  },
  {
    "objectID": "sessions_core/01_introduction.fr.html#terminé",
    "href": "sessions_core/01_introduction.fr.html#terminé",
    "title": "Introduction à R",
    "section": "Terminé !",
    "text": "Terminé !\nC’est tout pour cette session, bravo pour vos débuts avec R et RStudio !\n\n\n\n Solutions exercices"
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html",
    "href": "sessions_core/02_import_data.fr.html",
    "title": "Importation des données",
    "section": "",
    "text": "Créer un projet RStudio\nMettre en place un code organisé et bien documenté\nInstaller et charger des paquets dans la session\nEcrire des chemins d’accès aux fichiers robustes\nImporter et inspecter des données dans R\n\n\n\n\n\n\n\nImportant\n\n\n\nLes principes vus dans le module FETCH sur la gestion des données s’appliquent aussi à votre code : on souhaite écrire un script qui fonctionne maintenant, mais également dans le futur, et qui soit partageable. Il existe quelques bonnes pratiques qui peuvent nous aider à aller dans cette direction, et la première est d’avoir un code source propre et bien organisé."
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#objectifs",
    "href": "sessions_core/02_import_data.fr.html#objectifs",
    "title": "Importation des données",
    "section": "",
    "text": "Créer un projet RStudio\nMettre en place un code organisé et bien documenté\nInstaller et charger des paquets dans la session\nEcrire des chemins d’accès aux fichiers robustes\nImporter et inspecter des données dans R\n\n\n\n\n\n\n\nImportant\n\n\n\nLes principes vus dans le module FETCH sur la gestion des données s’appliquent aussi à votre code : on souhaite écrire un script qui fonctionne maintenant, mais également dans le futur, et qui soit partageable. Il existe quelques bonnes pratiques qui peuvent nous aider à aller dans cette direction, et la première est d’avoir un code source propre et bien organisé."
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#mise-en-place-du-projet",
    "href": "sessions_core/02_import_data.fr.html#mise-en-place-du-projet",
    "title": "Importation des données",
    "section": "Mise en place du projet",
    "text": "Mise en place du projet\n\nStructure des dossiers\n\nSi ce n’est pas déjà fait, téléchargez le dossier du cours décompressez-le. Sauvegardez le dossier non compressé à un endroit non connecté à OneDrive et ouvrez-le.\n\n\n\n  Dossier du cours\n\n\n\n\nCe dossier illustre une structure typique et recommandée pour vos projets de code :\n\n📁 data\n\n📁 raw\n📁 clean\n\n📁 R\n📁 outputs\n\nCe dossier sera votre répertoire de travail pour toutes les sessions de ce cours. Vous y créerez un projet RStudio (explications ci-dessous), et y enregistrerez tous vos scripts (sous dossier R). Les données brutes se trouvent déjà dans data/raw.\n\n\nDéfinitions\nVoici deux concepts importants que nous allons rencontrer dans cette session :\nRépertoire de travail. Le répertoire de travail est l’emplacement (dossier) où votre session R en cours travaille. Si vous enregistrez un fichier, par exemple, il sera enregistré dans ce dossier par défaut. De même, Si vous ouvrez un fichier, ce dossier sera affiché par défaut. Tous les chemins relatifs auront ce dossier pour origine. Par défaut, R choisit généralement votre dossier “Documents” comme répertoire de travail sur les machines Windows.\nRacine. La racine fait référence au niveau de dossier le plus élevé du répertoire de travail. Si le dossier de votre cours s’appelle FETCHR la racine se trouverait directement à l’intérieur de celui-ci (et non dans l’un de ses sous-dossiers comme R ou data).\n\n\nProjets RStudio\nUn projet RStudio est outil qui va faciliter votre vie et aider RStudio à trouver les différents fichiers.\nPour rappel, votre interface doit ressembler à ceci :\n\n\n\n\n\n\nFigure 1: Capture d’écran d’une interface RStudio typique\n\n\n\n\nOuvrez RStudio et suivez ces étapes pour créer un nouveau projet :\n\ncliquez sur File &gt; New Project &gt; Existing Directory &gt; Browse,\nnaviguez jusqu’au dossier du cours (en l’ouvrant)\ncliquez sur Create Project.\n\n\n\nDans l’explorateur Windows, examinez le dossier du cours. Vous devriez maintenant voir un nouveau fichier avec l’extension .Rproj qui a une petite icône bleue avec un R au milieu\n\n\n\n\nIcône associée aux projets RStudio\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi vous ne voyez pas ce fichier, c’est probablement parce qu’il est caché par défaut sur votre ordinateur. Pour modifier ce paramètre dans l’explorateur Windows, allez dans le menu Afficher et sélectionnez Extensions de noms de fichier.\n\n\nLorsque vous ouvrez un projet RStudio, RStudio démarre une nouvelle session R spécifique à ce projet, ouvre les fichiers associés et définit la racine de votre dossier comme répertoire de travail. Une conséquence immédiate est que le panneau Files en bas à droite de l’interface montre les sous dossiers présents dans le répertoire de travail, i.e. votre dossier de cours.\n\n\n\n\n\n\nTip\n\n\n\nIl est fortement recommandé de mettre en place un projet RStudio distinct pour chacune de vos analyses afin de garantir que les fichiers de vos projets restent organisés.\n\n\nIl existe plusieurs façons d’ouvrir un projet RStudio :\n\nUtilisez le menu RStudio File &gt; Open Project puis sélectionnez le fichier .Rproj approprié\nCliquez sur le bouton Project: (none) en haut à droite de l’interface RStudio\nNaviguez dans l’explorateur de fichiers Windows jusqu’à votre dossier de cours et double-cliquez sur le fichier avec l’extension .Rproj\n\n\n\nLes options de RStudio\nAvant de poursuivre, allons modifier certaines des options de RStudio qui peuvent causer des problèmes.\n\nOuvrez les options globales (Tools &gt; Global Options) et ouvrez l’onglet General (menu de gauche). Déselectionnez toutes les cases des sections R Sessions, Workspace et History.\n\n\n\n\nCapture d’écran des options de RStudio\n\n\nLorsque ces options sont activées, RStudio enregistre les objets de votre environnement et les charge à chaque fois que vous ouvrez une nouvelle session R. Ca semble être une bonne idée, mais il est en fait préférable de toujours commencer votre travail à partir d’une session R vide afin d’éviter les erreurs.\n\n\n\n\n\n\nImportant\n\n\n\nN’oubliez pas que toutes les commandes nécessaires au nettoyage et à l’analyse de vos données doivent être enregistrées explicitement dans un script, dans le bon ordre. Faire retourner le script devrait arriver aux mêmes résultats que précédement.\n\n\n\n\nCréation d’un nouveau script\n\nOuvrez un nouveau script et enregistrez-le dans le sous-dossier R de votre projet sous le nom import_data.R.\nAjoutez des métadonnées au début du script, comme recommandé lors première session, en utilisant des commentaires. Veillez à inclure :\n\nLe titre\nL’auteur du script\nLa date de création\nUne description rapide de ce que fait le script\n\n\nNous sommes prêts à commencer à coder"
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#sec-packages",
    "href": "sessions_core/02_import_data.fr.html#sec-packages",
    "title": "Importation des données",
    "section": "Paquets",
    "text": "Paquets\nLes paquets [packages] sont des collections de fonctions qui étendent les fonctionalités de R. Vous en utiliserez un grand nombre pendant ce cours et dans votre travail quotidien. R étant open-souce, les packages sont téléchargeable et utilisable gratuitement.\n\n\n\n\n\n\nNote\n\n\n\nDans ce cours, nous utiliserons une convention commune qui est de référencer les paquets entre {}. Par exemple {ggplot2} est le nom du paquet ggplot2 qui contient des fonctions pour créer des graphes, telles que ggplot(), geom_point() etc…\n\n\n\nInstallation\nLa fonction install.packages() télécharge et installe un nouveau paquet sur votre ordinateur, dans la bibliothèque de paquets associée à R. Vous n’avez à faire cette opération qu’une seule fois par paquet et ordinateur.\n\ninstall.packages(\"here\") # installe le paquet {here} \n\nN’oubliez pas de mettre le nom du paquet entre guillemets lorsque vous utilisez la commande install.packages(). Que se passe-t-il si vous ne le faites pas ?\n\n\n\n\n\n\nNote\n\n\n\nSi vous suivez cette session dans le cadre d’un cours, pour éviter tout problème potentiel de connectivité internet pendant la formation, nous vous avons déjà fait installer la plupart des paquets du cours.\nSi vous suivez ce tutoriel seul ou si vous n’avez pas encore installé les paquets, vous devrez installer manuellement chaque nouveau paquet que nous rencontrerons avec la fonction install.packages().\n\n\n\n\nUtilisation\nUne fois qu’un paquet est installé, il faut indiquer à R que nous souhaitons l’utiliser pour une session donnée en le chargeant dans la session avec la fonction library().\n\nlibrary(here) # charge le paquet {here} dans la session\n\n\nUtilisez la fonction library() pour charger les paquets here et rio qui seront utilisés aujourd’hui.\n\nIl se peut que vous obteniez parfois un message d’avertissement signalant que certaines fonctions ont été masquées ou que la version actuelle du paquet a été construite pour une version différente de R. Ces messages ne doivent pas vous inquiéter, mais il faut les lire et essayer de comprendre ce qui se passe.\n\nExécutez le code suivant. Comprenez-vous le message d’erreur ?\n\nlibrary(ggplot)\n\n\nLe code ci-dessus génère une erreur car il y a une faute de frappe dans le nom du paquet, et vous avez donc essayé de charger un paquet qui n’existe pas. Rappelez-vous que R est pénible, et en particulier est sensible à la casse : beaucoup de vos erreurs viendront de petites fautes dans les noms de fonctions ou d’objets. Ici, par exemple, nous voulions charger le paquet ggplot2 mais nous avons écrit ggplot à la place.\n\n\n\n\n\n\nTip\n\n\n\nIl est recommandé d’avoir une section au début de votre script qui charge tous les paquets dont vous aurez besoin dans votre script en un seul endroit :\n\n# Packages ----------------------------\nlibrary(tidyverse)   # manipulation de données\nlibrary(lubridate)   # manipulation des dates\n\nCelà permet de savoir rapidement quels paquets doivent être installés pour exécuter un script.\n\n\n\nCréez une section “Paquets” dans votre script à l’aide de commentaires\n\n\n\nMettre à jour les paquets\nR dispose d’une communauté de développeurs très active et il est assez courant que les paquets soient mis à jour, avec de nouvelles fonctionalités ou des corrections de bugs. Pour mettre à jour les paquets de votre bibliothèque, rendez-vous dans l’onglet Packages du panneau inférieur droit et cliquez sur Update. N’oubliez pas que vous devez être connecté à internet pendant ce processus.\n\n\n\n\n\n\nImportant\n\n\n\nLa mise à jour de certains paquets peut parfois changer le comportement de certaines fonctions, ce qui peut casser votre code. Pas de panique. La meilleure pratique consiste à adapter votre code mais, dans le pire des cas, vous pouvez installer une ancienne version du paquet incriminé."
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#importation-de-données",
    "href": "sessions_core/02_import_data.fr.html#importation-de-données",
    "title": "Importation des données",
    "section": "Importation de données",
    "text": "Importation de données\n\nTrouver son chemin…\nPour ouvrir un fichier dans R, vous devez fournir un chemin d’accès au fichier. Un chemin d’accès est simplement un (long) nom pour un fichier qui inclut son emplacement sur votre ordinateur. Les chemins d’accès peuvent être absolus ou relatifs.\n\nChemins d’accès absolus\nLes chemins d’accès absolus sont spécifiques à votre ordinateur et vont jusqu’au niveau de votre disque dur. Par exemple : D:/OneDrive - MSF/Documents/monitoring/cholera/fancy_project/data/raw/example_linelist.xlsx. Il est clair que ce chemin ne fonctionne que sur un ordinateur particulier.\nL’utilisation de chemins absolus encodés en dur est fortement déconseillé car cela rend votre code fragile et augmente la maintenance : en effet, les chemins devront tous être mis à jour chaque fois quelqu’un d’autre exécute votre code, ou que le dossier du projet est déplacé sur votre ordinateur.\n\n\nChemins d’accès relatifs\nLes chemins relatifs sont définis par rapport à votre répertoire de travail. Comme l’emplacement du fichier .Rproj définit le répertoire de travail, les chemins sont relatifs à cette racine. Pour vous, un chemin relatif ressemblera à ça : data/raw/example_linelist.xlsx.\nCela signifie que tant que la structure interne du dossier contenant votre projet est préservée, le chemin d’accès relatif sera valable quelque soit l’ordinateur.\n\n\nChemins d’accès robustes avec la fonction here()\nLe paquet {here} dispose d’une fonction here() qui aide à créer des chemins d’accès. Elle présente deux avantages :\n\nElle détecte la présence d’un fichier .Rproj et est capable de construire un chemin absolu à partir d’un chemin relatif dans votre projet RStudio.\nElle choisit automatiquement le séparateur adapté à votre système d’exploitation : /, \\ ou //.\n\n\nlibrary(here)\nhere(\"data\", \"raw\", \"example_linelist.xlsx\")\n\n[1] \"D:/MATHILDE_UNPLUGGED/3_TRAINING/FETCH/repicentre/data/raw/example_linelist.xlsx\"\n\n\n\nlibrary(here)\nhere(\"data\", \"raw\", \"example_linelist.xlsx\")\n\n[1] \"D:/MATHILDE_UNPLUGGED/3_TRAINING/FETCH/repicentre/data/raw/example_linelist.xlsx\"\n\n\nVoyez comme nous n’avons défini que le chemin relatif et la fonction a reconstitué le chemin absolu. Celà marchera donc sur l’ordinateur d’un collègue, y compris sur un autre système d’exploitation, du moment que la structure du répertoire de travail est intacte.\nNous vous encourageons fortement à utiliser here() chaque fois que vous devez créer un chemin d’accès à un fichier.\n\nExécutez le code ci-dessus dans la console. Quel chemin d’accès here(\"data\", \"raw\") vous donne-t-il ?\n\n\nUtilisez here() pour créer le chemin vers le fichier Moissalla-rougeole-liste-lineaire-FR.xlsx.\n\n\n\n\n\n\n\nImportant\n\n\n\nhere() crée une chaîne de caractères contenant l’adresse d’un fichier, mais ne vérifie pas si ce fichier existe réellement sur votre ordinateur. Si le fichier est absent ou s’il y a une faute de frappe dans votre code, vous obtiendrez une erreur lors de l’utilisation du chemin ainsi créé. Vous pouvez tester si un fichier existe à cette adresse avec la fonction file.exists().\n\n\n\n\n\n\n\n\nTip\n\n\n\nOn veut souvent définir plusieurs chemins dans un projet (données brutes, données propres, où sauver les graphes etc.). C’est une bonne pratique que de créer une nouvelle section au début de votre script, après le chargement des paquets, pour définir et stocker les chemins d’accès dans des objets.\n\n\n\n\n\nImporter les données\nDans R, différents formats de fichiers sont importés par différentes fonctions spécialisées, ce qui est fastidieux à mémoriser et à charger. La fonction import() du paquet {rio} nous fait gagner du temps en reconnaissant l’extension des fichier et en appelent automatiquement une fonction spécialisée pour charger les données.\nComme import() ne fait qu’appeler d’autres fonctions en arrière-plan, il est possible qu’elle ait besoin d’arguments optionnels spécifiques pour certains types de fichier.\n\n\n\n\n\n\nTip\n\n\n\nLa (longue) liste des types de fichiers pris en charge par {rio} est sur le site du paquet. Dans la suite de la leçon, nous nous concentrerons sur l’importation de données à partir de fichiers Excel .xlsx.\n\n\n\nImport de la première feuille\nAu minimum la fonction import() a besoin qu’on lui donne le chemin du fichier avec l’argument file :\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"))\n\nNotez que nous avons imbriqué la commande here() à l’intérieur de la commande import(). L’imbrication de fonctions est autorisée et même courrante en R. R évalue les fonctions imbriquées de l’intérieur (here()) à l’extérieur (import()). La valeur renvoyée par here() est donc utilisée comme valeur d’entrée d’import().\n\nImportez le fichier Moissalla-rougeole-liste-lineaire-FR.xlsx en utilisant here() et import().\n\nSi votre importation a fonctionné correctement, R affichera les données dans la console mais ne les enregistrera pas dans l’environnement car nous ne les avons pas assignées à un objet.\n\nRéimportez vos données, mais cette fois-ci, sauvegardez-les dans un objet appelé df_linelist.\n\n\n\n\n\n\n\nTip\n\n\n\nSi votre jeu de données est très gros, il vaut mieux éviter de l’afficher dans la console…\n\n\n\n\nImport d’une autre feuille\nComme vous venez de le voir, la fonction import() importe la première feuille d’un fichier Excel par défaut. Il est cependant possible de passer le numéro de la feuille ou son nom (en chaîne de caractères) à l’argument which :\n\nimport(file = here(\"data\", \"raw\", \"example_linelist.xlsx\"),  # chemin\n       which = 2)                                            # spécifie la deuxième feuille\n\nNotez que l’argument which est spécifique aux types de fichiers comportant plusieurs feuilles, tels que les fichiers Excel ou .Rdata. Si vous essayez de l’utiliser sur un fichier .csv l’argument sera ignoré."
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#aperçu-des-données",
    "href": "sessions_core/02_import_data.fr.html#aperçu-des-données",
    "title": "Importation des données",
    "section": "Aperçu des données",
    "text": "Aperçu des données\nNous avons importé un jeu de données dans R et l’avons assigné à un objet (df_linelist). Nous pouvons maintenant inspecter le data frame créé pour vérifier que l’export s’est bien passé, et commencer à évaluer le nettoyage à faire.\nNous pouvons commencer par jeter un coup d’œil rapide aux premières lignes du data frame à l’aide de la fonction head(). Son premier argument est le data frame à inspecter et le second, n, accepte un nombre de lignes à afficher (optionnel).\n\nhead(df_linelist, n = 10) # Affiche les 10 premières lignes\n\n\nUtilisez head() pour examiner les 12 premières lignes de df_linelist.\n\nNous pouvons inspecter la structure du data frame à partir de l’onglet Environnement dans le panneau supérieur droit. Nous pouvons également visualiser le data frame dans le le visualiseur de données de RStudio (en haut à gauche).\n\nCliquez sur le bouton rond bleu à côté de df_linelist dans votre environnement pour examiner sa structure. Cliquez ensuite sur le nom du data frame pour le visualiser.\n\nLe visualiseur permet d’afficher le data frame comme dans un tableur et est un moyen pratique d’examiner rapidement vos données. Vous pouvez trier et filtrer vos données dans cet onglet mais ces actions ne modifieront pas l’objet df_linelist. Le visualiseur peut également être ouvert en utilisant directement la fonction View() sur le data frame."
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#cest-fini",
    "href": "sessions_core/02_import_data.fr.html#cest-fini",
    "title": "Importation des données",
    "section": "C’est fini !",
    "text": "C’est fini !\nBravo et n’oubliez pas de sauvegarder votre code !\n\n\n\n Solutions exercices"
  },
  {
    "objectID": "sessions_core/02_import_data.fr.html#pour-aller-plus-loin",
    "href": "sessions_core/02_import_data.fr.html#pour-aller-plus-loin",
    "title": "Importation des données",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\n\nExercices supplémentaires\n\nUtilisez dim() pour examiner les dimensions de votre data frame.\nUtilisez str() pour vérifier le type de données de chaque colonne. Voyez-vous quelque chose d’étrange ? N’oubliez pas que vous pouvez également utiliser des fonctions telles que is.character() et is.numeric() si vous souhaitez tester le type d’une colonne particulière.\nEn utilisant une fonction apprise lors de la première session, pouvez-vous extraire les noms des colonnes du data frame ? Ces résultats correspondent-ils à ce que vous voyez lorsque vous ouvrez les données dans Excel ?\nEssayez d’exécuter la fonction summary() sur votre data frame. Qu’est ce que le résultat vous apprend sur les variables ?\n\n\n\nRessources complémentaires\n\nLe site web de {rio}\nPlus d’exemples sur l’importation de données de différents types de fichiers"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html",
    "href": "sessions_core/03_data_verbs.fr.html",
    "title": "Traitement de données, les bases",
    "section": "",
    "text": "Découvrir les fonctions de {dplyr} pour effectuer les actions essentielles sur les données :\n\nSélectionner des colonnes avec select()\nRenommer des colonnes avec rename()\nCréer de nouvelles colonnes ou modifier des colonnes existantes avec mutate()\nSupprimer les doublons avec distinct()\n\nEnchaîner ces actions avec l’opérateur “pipe” |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#objectifs",
    "href": "sessions_core/03_data_verbs.fr.html#objectifs",
    "title": "Traitement de données, les bases",
    "section": "",
    "text": "Découvrir les fonctions de {dplyr} pour effectuer les actions essentielles sur les données :\n\nSélectionner des colonnes avec select()\nRenommer des colonnes avec rename()\nCréer de nouvelles colonnes ou modifier des colonnes existantes avec mutate()\nSupprimer les doublons avec distinct()\n\nEnchaîner ces actions avec l’opérateur “pipe” |&gt;"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#mise-en-place",
    "href": "sessions_core/03_data_verbs.fr.html#mise-en-place",
    "title": "Traitement de données, les bases",
    "section": "Mise en place",
    "text": "Mise en place\nPrérequis : cette leçon part du principe que vous savez comment utiliser RStudio et que vous êtes capable d’importer des données. Rafraîchissez-vous si besoin avec les deux premières leçons.\n\nNous utiliserons la linelist avec des données brutes que vous avez importée lors de la leçon précédente, et qui peut être téléchargée ici :\n\n\n\n Télécharger les données\n\n\n\n Si ce n’est pas déjà fait, enregistrez le jeu de données dans le sous-dossier approprié de votre projet RStudio puis créez un nouveau script appelé fonctions_donnees.R dans votre sous-dossier R. Ajoutez un en-tête approprié et chargez les paquets suivants : {here}, {rio} et {tidyverse}.  Enfin, ajoutez une section dédiée à l’import des données, utilisez {here} et {rio} pour importer vos données dans R, et assignez-les à un objet que nous appellerons df_brut."
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#traiter-ses-données-avec-dplyr",
    "href": "sessions_core/03_data_verbs.fr.html#traiter-ses-données-avec-dplyr",
    "title": "Traitement de données, les bases",
    "section": "Traiter ses données avec {dplyr}",
    "text": "Traiter ses données avec {dplyr}\nLa mise en place est terminée et nous pouvons maintenant nous focaliser sur nos données ! Cette leçon et les suivantes s’appuieront lourdement sur plusieurs paquets de la collection de paquets tidyverse pour manipuler des data frames, résumer et visualiser les données, et en particulier paquet {dplyr} pour aujourd’hui.\nLe traitement des données (aussi appelé manipulation des données) est un ensemble d’actions essentielles pour préparer et nettoyer les données avant une analyse (que ce soit dans R ou Excel). {dplyr} fournit un grand nombre de fonctions qui nous aident à manipuler les data frames et à réaliser de nombreuses tâches quotidiennes telles que :\n\ncréer des sous-ensembles de nos données en ne gardant que les variables d’intérêt\nrenommer des colonnes\najouter ou modifier des colonnes\nsupprimer les doublons\n\nCes fonctions ont en général un nom intuitif, qui correspond à un verbe. Par exemple, pour renommer des colonnes, on utilisera la fonction rename().\nAujourd’hui nous nous focaliserons sur les quatre verbes (fonctions !) qui permettent d’effectuer les tâches mentionnées précédemment, et que vous utiliserez en permanence. Nous vous montrerons également comment enchaîner les actions dans un “pipeline” pour plus de fluidité.\n\n\n\n\n\n\nNote\n\n\n\nPeut-être avez-vous noté que nous vous parlons du paquet {dplyr} mais nous vous avons fait charger le paquet {tidyverse} lors de la mise en place. C’est que le {tidyverse} est un méta-paquet, et le charger charge automatiquement plusieurs des paquets les plus utiles de l’univers du tidyverse, dont fait partie {dplyr} et d’autres paquets que nous verrons dans la session."
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#actions-de-base-sur-les-données",
    "href": "sessions_core/03_data_verbs.fr.html#actions-de-base-sur-les-données",
    "title": "Traitement de données, les bases",
    "section": "Actions de base sur les données",
    "text": "Actions de base sur les données\n\nSélectionner des colonnes\nIl est fréquent de souhaiter écarter des variables d’un jeu de données, soit car ces colonnes contiennent des données sensibles, soit parce que nous n’avons pas besoin d’elles pour une analyse donnée. Nous utiliserons pour cela la fonction select(), qui la syntaxe suivante :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\nselect(un_dataframe, colonne_a_garder, autre_colonne_a_garder)\n\nIci, le premier argument est le data frame contenant les données. Les arguments suivants sont les noms des colonnes que nous voulons conserver. Dans le tidyverse, les noms de colonnes n’ont pas besoin d’être écrits entre guillemets.\nLa commande suivante nous permet de sélectionner les colonnes id, sex et age, par exemple :\n\nselect(df_brut, id, sexe, age)\n\n\nUtilisez la fonction select() pour sélectionner les variables suivantes de votre data frame : id, sexe, age, sous_prefecture, date_debut et issue. L’en-tête du data frame renvoyé par la fonction ressemble à ceci :\n\n\n  id  sexe age date_debut issue\n1  1 femme  36 2022-08-13 gueri\n2  2     f   5 2022-08-18  &lt;NA&gt;\n3  3     f 156 2022-08-17 gueri\n4  6 homme   8 2022-08-22 gueri\n5  7     h   7 2022-08-30 gueri\n6 10     h   4 2022-08-30 gueri\n\n\n Comparez ce résultat à df_brut. Ce dernier contient toujours toutes les colonnes importées (ce qui est le comportement désiré). Comprenez-vous pourquoi c’est le cas ?\n\nIl arrive que nous ne voulions supprimer que quelques colonnes d’un jeu de données et si le jeu de données est large ça serait fastidieux d’écrire toutes les colonnes à garder comme nous l’avons fait ci-dessus… Heureusement, nous pouvons préfacer un nom de colonne par l’opérateur soustraction (-) pour indiquer à R de la supprimer.\nPar exemple, pour créer un data frame sans la colonne village_commune :\n\nselect(df_brut, -village_commune)\n\n\nUtilisez cette syntaxe pour créer un data frame qui conserve toutes les colonnes de df_brut à l’exception de nom_complet et unite_age.\n\n\n\nRenommer les colonnes\nIl arrive souvent que nous souhaitions renommer des colonnes d’un jeu de données. La fonction rename() est alors votre meilleure amie.\n\n# NE PAS EXÉCUTER (PSEUDO CODE)\nrename(un_dataframe,\n       nouveau_nom_1 = nom_tout_moche,\n       nouveau_nom_2 = autre_nom_pas_fou)\n\nComme pour select(), le premier argument est le data frame qui contient les données (ce sera le cas pour la majorité des verbes de {dplyr}). Ensuite, chaque nouvel argument est une paire nouveau_nom = ancien_nom indiquant à R les colonnes à renommer et leurs nouveaux noms. Nous vous conseillons d’aller à la ligne pour chaque nouvelle paire pour aider à la lisibilité.\nRenommons la colonne village_commune en village par exemple :\n\nrename(df_brut,\n       village = village_commune)\n\n\nUtilisez la fonction rename() sur df_brut pour renommer les colonnes :\n\nsous_prefecture en prefecture\nvillage_commune en village\nnom_structure_sante en structure\n\n\nIl peut être difficile de vérifier si une commande fonctionne car R affiche le data frame en entier. Dans ce cas, une première solution consiste à créer un objet temporaire plus facile à manipuler. Vous pouvez le nommer comme vous voulez, mais un nom commun est temp (ou tmp en anglais).\n\nRépétez le dernier exercice en assignant la sortie de la commande à un objet appelé temp. Vous pouvez alors utiliser la fonction names() pour vérifier que les noms des colonnes ont bien changé. La sortie de names() devrait être :\n\n\n [1] \"id\"                \"nom_complet\"       \"sexe\"             \n [4] \"age\"               \"unite_age\"         \"region\"           \n [7] \"prefecture\"        \"village\"           \"date_debut\"       \n[10] \"date_consultation\" \"hospitalisation\"   \"date_admission\"   \n[13] \"structure\"         \"tdr_paludisme\"     \"fievre\"           \n[16] \"eruption\"          \"toux\"              \"yeux_rouges\"      \n[19] \"pneumonie\"         \"encephalite\"       \"pb\"               \n[22] \"statut_vaccinal\"   \"doses_vaccin\"      \"issue\"            \n[25] \"date_issue\"       \n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLes objets comme le data frame temp sont généralement utilisés pour tester si quelque chose a fonctionné et peuvent donc être écrasés lorsque vous testez autre chose. Ils ne doivent pas être utilisés comme entrée pour d’autres parties de votre code. Utilisez des noms clairs et appropriés pour vos data frames destinés à être réutilisés, tels que df_linelist ou df_propre.\n\n\n\n\nModifier et ajouter des colonnes\nUne autre tâche essentielle du traitement de données est de modifier des colonnes ou d’en créer de nouvelles. La fonction mutate() permet de faire les deux [to mutate veut dire muter en anglais], avec la syntaxe suivante :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\nmutate(un_dataframe,\n       nouvelle_colonne_1 = action(colonne_existante),\n       nouvelle_colonne_2 = autre_action(une_autre_colonne_existante))\n\nDans le code ci-dessus nous créons une nouvelle colonne (nouvelle_colonne_1) en effectuant une action (des calculs par exemple) sur une colonne existante (colonne_existante) dans le data frame un_dataframe. Puis nous créons une autre colonne (nouvelle_colonne_2) sur le même principe. L’action en question peut être variée et plus ou moins complexe : calcul arithmétique, application d’une fonction sur une colonne (ou même plusieurs !) etc.\nPar exemple, nous pourrions créer une nouvelle colonne exprimant le périmètre brachial en cm :\n\nmutate(df_brut,\n       pb_cm = pb / 100) # une opération arithmétique simple\n\n\nUtilisez mutate() pour créer une nouvelle colonne age_ans qui exprime l’âge en années plutôt qu’en mois. L’en-tête de la colonne ressemble à ceci :\n\n\n   age_years\n1  3.0000000\n2  0.4166667\n3 13.0000000\n4  0.6666667\n5  0.5833333\n6  0.3333333\n\n\n\nPour modifier une colonne existante il suffit d’utiliser le nom de la colonne existante à gauche du = au lieu de fournir un nouveau nom.\nPar exemple, si nous voulions remplacer la colonne pb qui contenait des valeurs en mm par une colonne pb contenant les valeurs en cm :\n\nmutate(df_brut,\n       pb = pb / 100)\n\nNous voulons souvent conserver la colonne originelle, mais il existe des cas raisonnables où nous souhaitons écraser les données par une nouvelle version. Par exemple :\n\nmodifier des chaînes de caractères (format, correction de typos etc.)\ncorriger le type de données d’une colonne\n\nNotre jeu de données présente ces deux cas. Par exemple les colonnes region et sous_prefecture sont en majuscules, ce qui n’est pas un problème en soi, mais peut être améliorable. Pour corriger cela nous pouvons utiliser la fonction str_to_title() du paquet {stringr} (qui fait également partie du {tidyverse}) pour passer les valeurs en casse “titre”.\n\nmutate(df_brut,\n       region = str_to_title(region),\n       sous_prefecture = str_to_title(sous_prefecture))\n\n\nUtilisez la fonction mutate() pour mettre à jour le format de tdr_paludisme et issue afin d’utiliser la casse “titres”. L’en-tête de la sortie pour ces deux colonnes devrait maintenant être :\n\n\n  tdr_paludisme issue\n1       Negatif Gueri\n2       Negatif  &lt;NA&gt;\n3       Negatif Gueri\n4       Negatif Gueri\n5       Negatif Gueri\n6       Negatif Gueri\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNous n’avons pas eu besoin de charger {stringr} car comme {dplyr}, ce paquet est chargé automatiquement lorsque nous chargeons{tidyverse}.\n\n\nPassons maintenant au problème des variables avec le mauvais type.\n\nVérifiez le type de vos colonnes. Y a-t-il des problèmes ?  Indice : str() peut être utile ici.\n\nLes classes semblent raisonnables sauf pour les dates : certaines colonnes ont la classe caractère et d’autres sont POSIXct. Nous préférerions que toutes ces colonnes utilisent le type Date.\nNous allons utiliser la fonction ymd() du paquet {lubridate} pour faire la conversion en Date. “ymd” est l’abréviation de year month day, c’est à dire année-mois-jour. Cela veut dire que la fonction attend une date fournie dans cet ordre-là (les séparateurs peuvent varier).\nPour corriger la date de décharge :\n\nmutate(df_brut,\n       date_issue = ymd(date_issue))\n\n\nUtilisez mutate() et ymd() pour modifier les colonnes date_debut et date_admission afin qu’elles soient de type Date.\nAstuce : n’hésitez pas à stocker la sortie de la fonction dans un data frame temporaire temp pour vérifier le type des variables modifiées.\n\n\n\nSupprimer les doublons\nNous connaissons désormais les fonctions pour sélectionner, renommer et modifier nos variables. Il est temps à présent de passer à une autre tâche essentielle du nettoyage : la suppression doublons.\nLa fonction distinct() permet de rapidement enlever les lignes identiques d’un data frame avec la syntaxe suivante :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndistinct(un_dataframe)\n\nPar défaut, nous n’avons besoin que d’un seul argument : le jeu de données lui-même. Cela supprime alors toutes les lignes qui sont complètement en double en ne gardant qu’une seule copie. Il existe des usages plus sophistiqués de distinct() pour chercher des doublons partiels, mais leur correction dépasserait du cadre de cette session…\n\nUtilisez la fonction distinct() et créez un data frame temporaire, temp qui contient toutes les observations uniques dans df_brut. Comparez le nombre de lignes de temp à celui de df_brut. Avions-nous des doublons ?"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#lopérateur-pipe",
    "href": "sessions_core/03_data_verbs.fr.html#lopérateur-pipe",
    "title": "Traitement de données, les bases",
    "section": "L’opérateur “pipe”",
    "text": "L’opérateur “pipe”\nNous avons profité de la présentation des fonctions essentielles de {dplyr} pour commencer le nettoyage du jeu de données. Il est temps de rassembler les commandes écrites dans les exercices en un ensemble cohérent pour créer un data frame contenant les données netoyées (au moins en partie) que nous appelerons df_linelist.\n\n\n\n\n\n\nTip\n\n\n\nEn général, il est recommandé de conserver une version brute de votre ensemble de données, ici df_brut, qui reste inchangée dans votre code. Ainsi, vous l’avez toujours à disposition dans votre environnement comme référence et elle est toujours disponible au début de votre pipeline de nettoyage pour améliorer la reproductibilité.\n\n\nIl y a plusieurs manières d’enchaîner les différentes étapes que nous avons vues. Intuitivement, nous pourrions commencer comme ceci :\n\ndf_linelist &lt;- rename(df_brut, \n                      prefecture = sous_prefecture,\n                      village    = village_commune,\n                      structure  = nom_structure_sante)\n\nPuis mettre à jour df_linelist :\n\n# Étape 1 : Renommer les variables\ndf_linelist &lt;- rename(df_brut, \n                      prefecture = sub_prefecture,\n                      village    = village_commune,\n                      structure  = nom_structure_sante)\n\n# Étape 2 : Sélectionner les variables à conserver\ndf_linelist &lt;- select(df_linelist,\n                      -nom_complet)\n\nNotez que dans cette deuxième étape, nous utilisons df_linelist comme entrée de select() plutôt que df_brut car nous voulons continuer à travailler sur la version modifiée des données.\nPuis nous ajoutons l’âge en années :\n\n# Étape 1 : Renommer les variables\ndf_linelist &lt;- rename(df_brut, \n                      prefecture = sub_prefecture,\n                      village    = village_commune,\n                      structure  = nom_structure_sante)\n\n# Étape 2 : Sélectionner les variables à conserver\ndf_linelist &lt;- select(df_linelist,\n                      -nom_complet)\n\n# Étape 3 : Ajouter l'âge en années\ndf &lt;- mutate(df_linelist,\n             age_ans = age / 12)\n\nEt caetera. Ce code est tout à fait fonctionnel, mais devient lourd et répétitif si de nombreuses étapes s’enchaînent : à chaque étape nous utilisons en entrée le data frame renvoyé par l’étape précédente pour le mettre à jour…\nIl existe un raccourcis ! L’opérateur pipe (|&gt;) permet d’enchainer des actions de manière plus fluide avec cette syntaxe :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\nune_entree |&gt; une_action\n\n# En particulier :\nun_dataframe |&gt; une_fonction()\n\nIci, le pipe prend l’entrée fournie à gauche et la transmet à la fonction à droite. Ainsi, par exemple, au lieu d’écrire\n\nselect(df_brut, id, sexe)\n\nnous pouvons écrire\n\ndf_brut |&gt; select(id, sexe)\n\n\nTestez le code ci-dessus de votre côté.\n\nOn peut se servir de l’opérateur pipe pour enchaîner plusieurs actions. C’est le style de code dit “du tidyverse”, qui ressemble à ceci :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf_linelist &lt;- df_brut |&gt;\n  action_1() |&gt;\n  action_2() |&gt;\n  action_3() |&gt;\n  ...\n\n\n\n\n\n\n\nTip\n\n\n\nAller à la ligne entre chaque action est considéré comme une bonne pratique pour rendre le code plus facile à lire et à comprendre.\n\n\nNous pourrions donc remplacer le code précédent par ceci :\n\ndf_linelist &lt;- df_brut |&gt;\n  rename(prefecture = sub_prefecture,\n         village    = village_commune,\n         facility   = health_facility_name) |&gt;\n  select(-full_name) |&gt;\n  mutate(age_years = age / 12)\n\nC’est beaucoup plus fluide que de réaffecter df_linelist après chaque étape !\n\nA votre tour ! Rassemblez maintenant toutes les étapes de nettoyage de la leçon en une seule commande en un seul pipeline.\nUtilisez l’opérateur pipe |&gt;, les fonctions select() rename(), mutate(), str_to_title(), ymd() et distinct() pour créer un data frame df_linelist partiellement nettoyé.  Rappel des étapes :\n\nSupprimer les variables nom_complet et unite_age\nRenommer les variables suivantes :\n\nage devient age_ans\nsous_prefecture devient prefecture\nvillage_commune devient village\nnom_structure_sante devient structure\n\nAjouter une variable age_ans avec l’âge du patient en années\nMettre à jour region et prefecture pour utiliser la casse de titre\nMettre à jour toutes les colonnes contenant des dates pour utiliser le type Date\nSupprimer toutes les lignes en double\n\nL’en-tête de vos données finales devrait ressembler à ceci :\n\n\n  id  sexe age_mois  region prefecture        village date_debut\n1  1 femme       36 Mandoul   Moissala Sangana Koïtan 2022-08-13\n2  2     f        5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3     f      156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6 homme        8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7     h        7 Mandoul   Moissala      Tétindaya 2022-08-30\n6 10     h        4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             oui     2022-08-14\n2        2022-08-25             oui     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25             non           &lt;NA&gt;\n5        2022-09-02             non           &lt;NA&gt;\n6        2022-09-02             oui     2022-09-02\n                        structure tdr_paludisme fievre eruption toux\n1 Hôpital du District de Moissala       negatif     No     &lt;NA&gt;  Yes\n2 Hôpital du District de Moissala       negatif     No       No  Yes\n3                      CS Silambi       negatif    Yes     &lt;NA&gt;   No\n4 Hôpital du District de Moissala       negatif     No       No   No\n5                      CS Silambi       negatif   &lt;NA&gt;       No  Yes\n6                    Moissala Est       negatif    Yes       No   No\n  yeux_rouges pneumonie encephalite  pb statut_vaccinal doses_vaccin issue\n1          No        No          No 244            &lt;NA&gt;         &lt;NA&gt; gueri\n2          No      &lt;NA&gt;          No 232             Non         &lt;NA&gt;  &lt;NA&gt;\n3          No        No        &lt;NA&gt; 123      Oui - oral         &lt;NA&gt; gueri\n4        &lt;NA&gt;        No          No 210             Non         &lt;NA&gt; gueri\n5         Yes        No          No  80             Non         &lt;NA&gt; gueri\n6        &lt;NA&gt;        No          No 220             Non         &lt;NA&gt; gueri\n  date_issue    age_ans\n1 2022-08-18  3.0000000\n2 2022-08-28  0.4166667\n3       &lt;NA&gt; 13.0000000\n4       &lt;NA&gt;  0.6666667\n5       &lt;NA&gt;  0.5833333\n6 2022-09-03  0.3333333\n\n\nAstuce :  soyez attentifs à vos noms de colonne. Si vous rennomez une colonne, il faudra utiliser le nouveau nom dans les étapes suivantes du pipeline.\n\nFantastique ! C’est un excellent début de pipeline de nettoyage de vos données. Sauvegardez ce code, car nous le complèterons lors de la prochaine session, durant laquelle nous apprendron une autre étape essentielle du traitement de données : recoder les variables !"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#cest-fini",
    "href": "sessions_core/03_data_verbs.fr.html#cest-fini",
    "title": "Traitement de données, les bases",
    "section": "C’est fini !",
    "text": "C’est fini !\nBravo, vous avez appris les bases de la manipulation de données et comment enchaîner plusieurs commandes dans un pipeline. À partir de maintenant, les fichiers contenant les solutions des exercices fourniront le code final plutôt qu’une correction par exercice, afin d’avoir un script plus réaliste. Par exemple, la solution fournira le pipe final créé à la fin de la session d’aujourd’hui.\n\n\n\n Solutions exercices"
  },
  {
    "objectID": "sessions_core/03_data_verbs.fr.html#aller-plus-loin",
    "href": "sessions_core/03_data_verbs.fr.html#aller-plus-loin",
    "title": "Traitement de données, les bases",
    "section": "Aller plus loin",
    "text": "Aller plus loin\n\nExercices supplémentaires\n\nAjoutez une ligne à votre mutate() pour mettre à jour la variable hospitalisation afin que son texte soit également en casse “titre”\nPeut-être préféreriez-vous utiliser des minuscules pour la colonne region plutôt que la casse “titre” ? Mettez votre code à jour pour le faire. Astuce : vous pouvez utiliser la fonction apprises dans la première session ou tester la fonction str_to_lower() de {stringr}.\nCréez une colonne delai_consultation, qui contient le nombre de jours entre l’apparition des symptômes et la consultation."
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html",
    "href": "sessions_core/04_data_verbs_conditional.fr.html",
    "title": "Traitement de données, recoder et filtrer",
    "section": "",
    "text": "Dans la session précédente vous avez appris les bases du traitement de données en R avec les fonctions du {tidyverse}, en particulier comment sélectionner et modifier les colonnes d’un data frame. Dans cette session nous allons allez plus loin sur la modification des data frame et apprendre à :\n\nÉcrire des conditions logiques basiques, ce qui va nous permettre de :\nSélectionner des lignes d’un data frame avec filter()\nRecoder des variables avec case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#objectifs",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#objectifs",
    "title": "Traitement de données, recoder et filtrer",
    "section": "",
    "text": "Dans la session précédente vous avez appris les bases du traitement de données en R avec les fonctions du {tidyverse}, en particulier comment sélectionner et modifier les colonnes d’un data frame. Dans cette session nous allons allez plus loin sur la modification des data frame et apprendre à :\n\nÉcrire des conditions logiques basiques, ce qui va nous permettre de :\nSélectionner des lignes d’un data frame avec filter()\nRecoder des variables avec case_when()"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#mise-en-place",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#mise-en-place",
    "title": "Traitement de données, recoder et filtrer",
    "section": "Mise en place",
    "text": "Mise en place\nPrérequis : cette leçon part du principe que vous connaissez les bases de la manipulation de données avec {dplyr}, et en particulier la fonction mutate(). Aller vous rafraîchir si besoin.\n\nNous utiliserons la liste linéaire avec les données brutes qui peut être téléchargée ici :\n\n\n\n Télécharger les données\n\n\n\n Si ce n’est pas déjà fait, enregistrez la dans le sous-dossier approprié de votre projet RStudio puis créez un nouveau script appelé filtrer_recoder.R dans votre sous-dossier R. Ajoutez un en-tête approprié et chargez les paquets suivants : {here}, {rio} et {tidyverse}.  Enfin, ajoutez une section dédiée à l’import des données, utilisez {here} et {rio} pour importer vos données dans R, et assignez-les à un objet que nous appellerons df_brut"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#filtrer-des-données-avec-des-conditions-logiques",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#filtrer-des-données-avec-des-conditions-logiques",
    "title": "Traitement de données, recoder et filtrer",
    "section": "Filtrer des données avec des conditions logiques",
    "text": "Filtrer des données avec des conditions logiques\nNous avons appris précédemment comment comment sélectionner les colonnes d’un data frame. Nous allons à présent apprendre la tâche complémentaire, qui est la sélection des lignes d’un data frame. C’est une tâche particulièrement courante du travail d’épidémiologiste qui permet de sélectionner des observations qui satisfont à certains critères. Le paquet {dplyr} possède bien évidement une fonction pour ça, la fonction filter().\nAvant de pouvoir l’utiliser nous allons néanmoins devoir apprendre à écrire des conditions logique, qui sont également un prérequis pour recoder des variables. Les conditions logiques sont des questions (ou tests) auxquelles R va répondre par TRUE ou FALSE (ou NA).\n\nEgalité\nLa syntaxe de filter() est assez simple :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf_brut |&gt;\n  filter([condition_logique])\n\nCette syntaxe permet de conserver les lignes où condition_logique est vraie. Ici, la condition logique va demander si quelque chose est égale à autre chose. Par exemple, si telle variable est égale à telle valeur (est ce que patient a été hospitalisé ?). En R, nous testons l’égalité avec l’opérateur ==.\nEn pratique, pour créer un filtre qui ne garde que les patients hospitalisés nous écrivons :\n\ndf_brut |&gt;\n  filter(hospitalisation == \"oui\")\n\nIci, filter() parcourt chaque ligne de notre data frame et teste si la valeur d’hospitalisation dans cette ligne est égale à \"oui\". La fonction ne renvoie alors que les lignes où la réponse à la question est TRUE [vrai].\n\nFiltrez vos données pour ne conserver que les patients qui avaient de la fièvre (c’est à dire les patients contenant la valeur \"Yes\" dans la colonne fievre. Le début de la colonne fievre dans la sortie filtrée est :\n\n\n  fievre\n1    Yes\n2    Yes\n3    Yes\n4    Yes\n5    Yes\n6    Yes\n\n\nInspectez la sortie et df_brut. Pourquoi df_brut contient-il encore les patients qui n’avaient pas de fièvre ?\n\n\n\nInégalité\nParfois, nous préférons tester l’inégalité plutôt que l’égalité ; pour examiner les patients qui ne se sont pas rétablis, par exemple, qu’ils soient décédés ou sorti contre avis médical. Dans ce cas nous utiliserons l’opérateur !=, ce qui donne ce code :\n\ndf_brut |&gt;\n  filter(issue != 'gueri') # Garde les lignes avec patients NON guéris\n\n\nFiltrez votre data frame pour ne montrer que les patients qui n’ont pas de carte confirmant leur statut vaccinal. Le début de la colonne filtrée ressemble à :\n\n\n  statut_vaccinal\n1             Non\n2             Non\n3             Non\n4             Non\n5             Non\n6             Non\n\n\nAstuce : Rappelez-vous que vous pouvez utiliser count() pour vérifier les modalités de statut_vaccinal.\n\n\n\nSupérieur à / Inférieur à\nDans le cas des variables numériques, on sera souvent intéressé par savoir si une valeur est supérieure ou inférieure à un seuil. Par exemple, quels sont les patients de moins de 5 ans. Ici, nous utiliserons les opérateurs &lt; et &gt; pour évaluer si une variable est inférieure à ou supérieure à une valeur donnée, respectivement.\nNous pouvons par exemple filtrer les patients de moins de 60 mois :\n\ndf_brut |&gt;\n  filter(age &lt; 60)\n\n\nAffichez un data frame ne contenant que les patients souffrant de malnutrition aiguë sévère. Le début de la colonne concernée est :\n\n\n    pb\n1  244\n2  232\n3  123\n4  210\n5   80\n6  220\n7  152\n8  155\n9  232\n10 135\n\n\nEcrivez un autre filtre qui sélectionne les patients âgés de plus de 15 ans. L’en-tête de votre colonne d’âge doit ressembler à ceci :\n\n\n  age\n1 348\n2 348\n3 312\n4 432\n5 444\n6 324\n\n\n\nSi nous ne voulons pas l’égalité stricte nous pouvons ajouter un signe égal aux opérateurs précédents, ce qui donne &lt;= pour “inférieur ou égal à” et &gt;= pour “supérieur ou égal à”. Attention, le = doit venir après les opérateurs &lt; et &gt;, pas avant.\nPour filtrer les patients avec 10 ans ou moins :\n\ndf_brut |&gt;\n  filter(age &lt;= 120)\n\n\nSélectionnez tous les patients avec un état nutritionnel normal, c’est-à-dire les patients dont le PB est supérieur ou égal à 125mm. L’en-tête du pb devrait ressembler à ceci :\n\n\n    pb\n1  244\n2  232\n3  210\n4  220\n5  152\n6  155\n7  232\n8  135\n9  146\n10 202\n\n\n\n\n\nConditions multiples\nIl est possible de combiner plusieurs conditions logiques dans un même filtre ! Il suffit de séparer plusieurs conditions logiques par une virgule.\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf_brut |&gt;\n  filter([condition 1],\n         [condition 2],\n         [condition 3])\n\nPar exemple, nous pourrions sélectionner tous les patients hospitalisés de moins de cinq ans :\n\ndf_brut |&gt;\n  filter(age &lt; 5,\n         hospitalisation == \"oui\")\n\n\nCréez un filtre qui sélectionne tous les patients de la sous-préfecture de Koumra hospitalisés et sévèrement malnutris Cela donne :\n\n\n    id sous_prefecture hospitalisation  pb\n1 8624          KOUMRA             oui 103\n2 8939          KOUMRA             oui  67\n3 9957          KOUMRA             oui  71\n\n\nIndice :  if faut une condition sur le statut d’hospitalisation, une sur la sous-préfecture et une sur le PB.\n\n\n\nRésumé des conditions logiques\nNous avons fait le tour des conditions logiques les plus basiques en R. Les voici rassemblées dans un tableau pour références futures :\n\n\n\nCondition\nR\n\n\n\n\nA identique à B ?\nA == B\n\n\nA pas identique à B ?\nA != B\n\n\nA supérieur à B ?\nA &gt; B\n\n\nA supérieur ou égal à B ?\nA &gt;= B\n\n\nA inférieur à B ?\nA &lt; B\n\n\nA inférieur ou égal à B ?\nA &lt;= B"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#recoder-des-variables-avec-case_when",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#recoder-des-variables-avec-case_when",
    "title": "Traitement de données, recoder et filtrer",
    "section": "Recoder des variables avec case_when()",
    "text": "Recoder des variables avec case_when()\nL’utilité des conditions logiques dans le traitement de données va bien plus loin que la sélection de lignes ! Elles sont par exemple très utiles quand nous voulons recoder des variables. Nous utiliserons les conditions logiques à l’intérieur de la fonction case_when() (également du paquet {dplyr}) pour recoder les variables.\nLa fonction case_when() est un peu plus complexe que ce que l’on a vu jusqu’à présent, mais très puissante (et va donc vous être très utile). Nous allons décomposer sa syntaxe pas à pas.\nVous utiliserez presque toujours case_when() dans un mutate() pour recoder une variable existante ou en créer une nouvelle, avec cette syntaxe :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf_brut |&gt;\n  mutate(nouvelle_colonne = case_when(\n    [condition_1] ~ [valeur_si_condition_1_est TRUE],\n    [condition_2] ~ [valeur_si_condition_2_est TRUE],\n    .défaut = [valeur_par_défaut]))\n\nDécomposons-la commande.\nA l’exception de la dernière ligne, chaque ligne à l’intérieur de la fonction case_when() a le format suivant :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\n[condition] ~ [valeur si condition est VRAIE]  # Les crochets sont là pour la lisibilité\n\nAinsi, pour recoder les patients avec un PB inférieur à 110mm comme \"MAS\", nous écrivons la commande suivante dans notre case_when() :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\n# [condition] ~ [valeur si VRAIE]\n   pb &lt; 110   ~ \"MAS\"\n\nIl y a en général plus d’une condition ! Dans notre exemple, une autre condition logique testerait si le patient est modérément malnutri avec l’instruction pb &lt; 125 ~ \"MAM\".\nLa dernière ligne de notre pseudo code contient l’argument .default et sert à fournir la valeur à utiliser lorsqu’aucune des conditions n’est remplie. Dans notre exemple, ça pourrait être \"Normal\".\nPour résumer, pour résumer, pour créer une variable contenant le statut nutritionnel à partir du PB :\n\ndf_brut |&gt;\n  mutate(malnut = case_when(\n    pb &lt; 110 ~ \"MAS\",\n    pb &lt; 125 ~ \"MAM\",\n    .default = \"Normal\"))\n\n\nExécutez le code ci-dessus pour créer une variable malnut contenant le statut nutritionnel des patients. Le haut des deux colonnes concernées renvoie :\n\n\n   pb malnut\n1 244 Normal\n2 232 Normal\n3 123    MAM\n4 210 Normal\n5  80    MAS\n6 220 Normal\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nL’ordre des conditions logiques est important ! case_when() teste les conditions dans l’ordre que vous lui donnez et attribue une valeur dès qu’une condition est TRUE.\nAinsi, dans l’exemple ci-dessus, case_when() pose ces questions suivantes dans l’ordre :\n\nEst-ce que pb &lt; 110 pour ce patient ? Si oui, attribuer la valeur \"MAS\"\nSi le patient n’est pas MAS, est-ce que pb &lt; 125 ? Si oui, attribuer la valeur \"MAM\"\nSi aucune des conditions précédentes n’est vraie, attribuer la valeur \"Normal\"\n\n\n\n\nIntervertissez l’ordre des deux premières conditions dans le case_when()précédent (pb &lt; 125 testé en premier). Le haut des deux colonnes concernées est maintenant :\n\n\n   pb malnut\n1 244 Normal\n2 232 Normal\n3 123    MAM\n4 210 Normal\n5  80    MAM\n6 220 Normal\n\n\nVous pouvez enregistrer le data frame crée dans un objet temporaire temp pour l’inspecter plus facilement. Où sont les patients MAS ? Comprenez-vous ce qui s’est passé ?\n\n\n\n\n\n\n\nNote\n\n\n\nL’argument .default dans case_when() n’est pas obligatoire. Si vous ne l’incluez pas, case_when() utilisera la valeur NA par défaut.\n\n\nDans notre exemple, nous avons utilisé case_when() pour créer une variable catégorique (le statut nutritionnel) à partir d’une variable continue (le PB). Un autre exemple typique et similaire est de créer une colonne contenant les classes d’âge.\n\nUtilisez case_when() pour créer une variable groupe_age avec les catégories suivantes :\n\n\"&lt; 5 Ans\"\n\"5 - 15 Ans\"\n\"&gt; 15 Ans\".\nsi l’âge est manquant, attribuer la valeur \"Inconnu\".\n\nFaites attention à l’ordre ! L’en-tête des colonnes concernées doit ressembler à ceci :\n\n\n   age  age_group\n1   36    &lt; 5 Ans\n2    5    &lt; 5 Ans\n3  156 5 - 15 Ans\n4    8    &lt; 5 Ans\n5    7    &lt; 5 Ans\n6    4    &lt; 5 Ans\n7    2    &lt; 5 Ans\n8   48    &lt; 5 Ans\n9  156 5 - 15 Ans\n10 348   &gt; 15 Ans\n\n\n\n\nL’opérateur %in%\nNous savons maintenant recoder les variables en catégories, ce qui vous arrivera très souvent en épidémiologie. Un autre cas d’usage majeur est d’utiliser case_when() pour standardiser les valeurs d’une variable.\n\nUtilisez count() pour inspecter les variables catégorielles de votre jeu de données. Lesquelles devraient être standardisées ?\n\nVous avez dû voir que la variable sexe présente quelques problèmes d’encodage. Par exemple, les patientes sont codées comme f, female et femme. Utilisons case_when() pour recoder cette variable. Ici, nous ne créerons pas une nouvelle variable, mais remplacerons la variable existante :\n\ndf_brut |&gt;\n  mutate(sexe = case_when(sexe == \"f\"      ~ \"Femme\",\n                          sexe == \"female\" ~ \"Femme\",\n                          sexe == \"femme\"  ~ \"Femme\",\n                          sexe == \"h\"      ~ \"Homme\",\n                          sexe == \"male\"   ~ \"Homme\",\n                          sexe == \"homme\"  ~ \"Homme\",\n                          .default = \"Inconnu\"))\n\nCe code fonctionne correctement mais est terriblement répétitif et verbeux. Heureusement il y a un raccourci pour lister toutes les options à réaffecter à “Femme” (et celles à “Homme”), l’opérateur %in% ! L’opérateur %in% permet de tester la condition “est ce que la valeur existe dans ce vecteur ?”.\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\n[valeur] %in% [vector_des_options]\n\nAinsi, par exemple, nous pourrions vérifier si la valeur “f” est dans les options “f” et “femme” :\n\n\"f\" %in% c(\"f\", \"femme\")\n\n\nExécutez l’instruction ci-dessus. Quel est le type de données de votre résultat ?\n\nLa commande renvoie un bolléen, c’est-à-dire un résultat logique. C’est donc une condition logique valide à utiliser dans un case_when() (ou un filter()) ! On peut donc simplifier notre code :\n\ndf_brut |&gt;\n  mutate(sexe = case_when(\n    sexe %in% c(\"f\", \"female\", \"femme\") ~ \"Femme\",\n    sexe %in% c(\"h\", \"male\", \"homme\") ~ \"Homme\",\n    .default = \"Inconnu\"))\n\nC’est plus court comme ça…\n\nUtilisez case_when() et l’opérateur %in% pour créer une nouvelle colonne vacc_status_strict qui a la valeur :\n\n\"Oui\" si le statut vaccinal est confirmé\n\"Non\" pour les cas non vaccinés\n\n\"Non vérifié\" sinon.\n\nLa tête de la nouvelle colonne ressemble à ceci :\n\n\n  statut_vaccinal statut_vaccinal_strict\n1            &lt;NA&gt;            Non vérifié\n2             Non                    Non\n3      Oui - oral            Non vérifié\n4             Non                    Non\n5             Non                    Non\n6             Non                    Non"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#pipeline-de-nettoyage-des-données",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#pipeline-de-nettoyage-des-données",
    "title": "Traitement de données, recoder et filtrer",
    "section": "Pipeline de nettoyage des données",
    "text": "Pipeline de nettoyage des données\nMaintenant que vous savez utiliser les conditions logiques pour recoder colonnes avec case_when(), nous pouvons reprendre le pipeline de nettoyage que nous avions commencé dans la session précédente.\n\nReprenez, le code de la session précédente, amendez-le et complétez le pour créer un gros pipeline de nettoyage des données, qui crée un data frame df_linelist en effectuant les opérations suivantes :\n\nSupprimer les variables nom_complet et unite_age\nRenommer les variables suivantes :\n\nage devient age_ans\nsous_prefecture devient prefecture\nvillage_commune devient village\nnom_structure_sante devient structure\n\nAjouter une variable age_ans avec l’âge du patient en années\nMettre à jour region et prefecture pour utiliser la casse de titre\nMettre à jour toutes les colonnes contenant des dates pour utiliser le type Date\nCréer une nouvelle variable groupe_age avec les groupes &lt; 6 mois, 6 - 11 mois, 12 - 59 mois, 5 - 15 ans et &gt; 15 ans (les patients dont l’âge est inconnu sont Inconnu)\nRecoder le sexe pour n’avoir que les valeurs : Femme, Homme et Inconnu\n\nSupprimer toutes les lignes en double\n\nLe début de vos données finales devrait ressembler à ceci :\n\n\n  id  sexe age_mois  region prefecture        village date_debut\n1  1 Femme       36 Mandoul   Moissala Sangana Koïtan 2022-08-13\n2  2 Femme        5 Mandoul   Moissala      Mousdan 1 2022-08-18\n3  3 Femme      156 Mandoul   Moissala     Djaroua Ii 2022-08-17\n4  6 Homme        8 Mandoul   Moissala     Monakoumba 2022-08-22\n5  7 Homme        7 Mandoul   Moissala      Tétindaya 2022-08-30\n6 10 Homme        4 Mandoul   Moissala      Danamadja 2022-08-30\n  date_consultation hospitalisation date_admission\n1        2022-08-14             oui     2022-08-14\n2        2022-08-25             oui     2022-08-25\n3        2022-08-20            &lt;NA&gt;           &lt;NA&gt;\n4        2022-08-25             non           &lt;NA&gt;\n5        2022-09-02             non           &lt;NA&gt;\n6        2022-09-02             oui     2022-09-02\n                        structure tdr_paludisme fievre eruption toux\n1 Hôpital du District de Moissala       negatif     No     &lt;NA&gt;  Yes\n2 Hôpital du District de Moissala       negatif     No       No  Yes\n3                      CS Silambi       negatif    Yes     &lt;NA&gt;   No\n4 Hôpital du District de Moissala       negatif     No       No   No\n5                      CS Silambi       negatif   &lt;NA&gt;       No  Yes\n6                    Moissala Est       negatif    Yes       No   No\n  yeux_rouges pneumonie encephalite  pb statut_vaccinal doses_vaccin issue\n1          No        No          No 244            &lt;NA&gt;         &lt;NA&gt; gueri\n2          No      &lt;NA&gt;          No 232             Non         &lt;NA&gt;  &lt;NA&gt;\n3          No        No        &lt;NA&gt; 123      Oui - oral         &lt;NA&gt; gueri\n4        &lt;NA&gt;        No          No 210             Non         &lt;NA&gt; gueri\n5         Yes        No          No  80             Non         &lt;NA&gt; gueri\n6        &lt;NA&gt;        No          No 220             Non         &lt;NA&gt; gueri\n  date_issue    age_ans   groupe_age\n1 2022-08-18  3.0000000 12 - 59 mois\n2 2022-08-28  0.4166667     &lt; 6 mois\n3       &lt;NA&gt; 13.0000000   5 - 15 ans\n4       &lt;NA&gt;  0.6666667  6 - 11 mois\n5       &lt;NA&gt;  0.5833333  6 - 11 mois\n6 2022-09-03  0.3333333     &lt; 6 mois\n\n\n\nTop ! Nous pouvons maintenant exporter ce data frame (presque) propre hors de R. Pour cela nous utiliserons la fonction export() de {rio} (et notre fidèle compagnon, la fonction here() de {here} pour gérer les chemins d’accès) :\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.xlsx'))\n\nNotez ici que nous plaçons nos données dans le sous-dossier clean dans data.\n\n\n\n\n\n\nTip\n\n\n\nEnregistrer les données au format .xlsx est utile pour pouvoir les ouvrir dans Excel pour les inspecter ou les partager. Cependant, nous préférerons souvent utiliser un fichier avec l’extension .rds. Ce type de fichier est spécifique à R et est plus robuste aux problèmes liés à l’encodage ou au formatage des dates que les fichiers de type .xlsx ou .csv.\nPour exporter votre data frame vers un fichier .rds, il suffit de modifier l’extension :\n\ndf |&gt;\n  export(here('data', 'clean', 'measles_linelist_clean.rds')) # TADAM !"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#cest-fini",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#cest-fini",
    "title": "Traitement de données, recoder et filtrer",
    "section": "C’est fini !",
    "text": "C’est fini !\nBravo. Lors des deux dernières sessions vous avez appris à utiliser les fonctions qui forment le socle du traitement de données, mais aussi les conditions logiques et comment organiser votre code en un pipeline de nettoyage !\n\n\n\n Solutions exercices"
  },
  {
    "objectID": "sessions_core/04_data_verbs_conditional.fr.html#aller-plus-loin",
    "href": "sessions_core/04_data_verbs_conditional.fr.html#aller-plus-loin",
    "title": "Traitement de données, recoder et filtrer",
    "section": "Aller plus loin",
    "text": "Aller plus loin\n\nExercices supplémentaires"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html",
    "href": "sessions_core/05_summary_table.fr.html",
    "title": "Tableaux récapitulatifs",
    "section": "",
    "text": "Créer des tableaux de contingence avec count()\nCalculer des statistiques récapitulatives par groupe à l’aide de summarize()\nRéviser comment sélectionner les lignes en utilisant filter() et créer/modifier des variables avec mutate()\nCréer des variables catégorielles ordonnées"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#objectifs",
    "href": "sessions_core/05_summary_table.fr.html#objectifs",
    "title": "Tableaux récapitulatifs",
    "section": "",
    "text": "Créer des tableaux de contingence avec count()\nCalculer des statistiques récapitulatives par groupe à l’aide de summarize()\nRéviser comment sélectionner les lignes en utilisant filter() et créer/modifier des variables avec mutate()\nCréer des variables catégorielles ordonnées"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#setup",
    "href": "sessions_core/05_summary_table.fr.html#setup",
    "title": "Tableaux récapitulatifs",
    "section": "Setup",
    "text": "Setup\nDépendances. Cette session suppose que vous savez utiliser RStudio, que vous êtes capable d’importer des données et que vous connaissez les verbes de base de manipulation des données que nous avons vus dans les sessions de base jusqu’à présent. Si vous avez besoin d’un rappel sur l’un de ces sujets, nous vous encourageons à revoir les sessions de base du parcours d’apprentissage.\n\nCette session utilisera la version nettoyée de l’ensemble de données Moissala sur la rougeole.\n\n\n\n Linelist rougeole nettoyée\n\n\n\n Ouvrez votre projet RStudio et créez un nouveau script dans le sous-dossier R appelé tables.R avec les métadonnées appropriées et une section “Packages” qui importe : {rio}, {here} et {tidyverse}. Ajoutez une section “Import Data” qui charge la version nettoyée de la linelist de la rougeole dans R."
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#introduction-agrégation-des-données",
    "href": "sessions_core/05_summary_table.fr.html#introduction-agrégation-des-données",
    "title": "Tableaux récapitulatifs",
    "section": "Introduction : agrégation des données",
    "text": "Introduction : agrégation des données\nRécapitulons. Vous venez d’effectuer l’une des tâches les [plus importantes]{.hovertip bs-toggle=‘tooltip’ bs-title=’Certains considèrent que cela représente 80 % du travail !} d’un épidémiologiste : le nettoyage des données. Maintenant que vous disposez de données propres et normalisées, vous pouvez vous mettre au travail et commencer à les analyser. Les analyses commencent généralement par des tableaux et des résumés qui décrivent nos données :\n\nTableaux de fréquence univariés pour compter les occurrences de différentes valeurs\nStatistiques sommaires des variables numériques (moyenne, médiane, écart-type)\nTableaux croisés pour examiner les relations entre les variables catégorielles\nRésumés par groupe pour comparer les statistiques entre différents sous-ensembles de données"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#compter-plusieurs-colonnes-tableaux-de-contingence",
    "href": "sessions_core/05_summary_table.fr.html#compter-plusieurs-colonnes-tableaux-de-contingence",
    "title": "Tableaux récapitulatifs",
    "section": "Compter plusieurs colonnes (tableaux de contingence)",
    "text": "Compter plusieurs colonnes (tableaux de contingence)\nAu cours de la session d’exploration des données, vous avez appris à créer un tableau de fréquence pour une variable catégorielle unique à l’aide de la fonction count(). C’est bien, mais nous voulons souvent compter le nombre d’observations en fonction de deux variables (ou plus !).\nCes tableaux sont appelés tableaux de contingence. Par exemple, connaître le nombre de patients par sous-préfecture est très utile, mais nous pourrions vouloir stratifier à la fois par sous-préfecture et par groupe d’âge pour voir si certaines zones ont des patients anormalement âgés. Ce type de stratification est un moyen utile d’essayer de trouver des zones qui pourraient être de bons candidats pour des campagnes de rattrapage. C’est facile, il suffit de passer plusieurs noms de colonnes à count() :\n\ndf_linelist |&gt;\n  count(sous_prefecture, age_groupe)\n\n\nCréez un nouveau tableau récapitulatif en comptant le nombre de patients stratifiés par sous_prefecture et hospitalisation. Que se passe-t-il si vous modifiez l’ordre des arguments donnés à count() ?\nMaintenant, en utilisant count(), réponds aux questions suivantes :\n\nCombien de patients étaient des femmes ? Quelle est la proportion ?\nQuelles sont toutes les valeurs possibles de la variable statut_sortie ?\nCombien de patients âgés de 1 à 4 ans se sont rétablis ?"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#filtrer-les-valeurs-na",
    "href": "sessions_core/05_summary_table.fr.html#filtrer-les-valeurs-na",
    "title": "Tableaux récapitulatifs",
    "section": "Filtrer les valeurs NA",
    "text": "Filtrer les valeurs NA\nEn examinant les catégories du statut_sortie, vous devriez avoir remarqué que certaines patientes ont des valeurs manquantes (NA):\n\ndf_linelist |&gt;\n  count(statut_sortie) |&gt;\n  mutate(prop = n / sum(n))\n\n\nObservez le résultat du code ci-dessus. Comment pouvez-vous également calculer la proportion de patients décédés ? Êtes-vous satisfait de ce calcul ?\n\nLa proportion de cas décédés est également appelée taux de létalité. Pour calculer précisément le CFR, nous devons nous assurer que le dénominateur ne comprend que les patients dont nous sommes sûrs du résultat (c’est-à-dire que nous devons supprimer tous les cas avec “NA” ou “contre avis médical”).\nRappelons que nous pouvons le faire en utilisant filter(). Pour garder les valeurs manquantes (NA) dans une variable, nous pouvons utiliser la petite fonction is.na(statut_sortie). L’ajout d’un ! devant fera l’inverse : supprimer les valeurs manquantes de statut_sortie :\n\ndf_linelist |&gt;\n  filter(statut_sortie != \"sortie contre avis medical\", \n         !is.na(statut_sortie)) |&gt;\n  count(statut_sortie)\n\n\nQuelle autre instruction conditionnelle pourriez-vous utiliser dans filter() pour obtenir les mêmes résultats ?\n\nMaintenant que nous avons supprimé les patients dont l’issue est inconnue, nous pouvons ajouter ceci avant de créer notre tableau de fréquence pour obtenir le CFR correct.\n\nÀ l’aide de votre filtre, mettez à jour votre code pour résumer le nombre observé de patients qui ont survécu et sont décédés ainsi que le taux de létalité (proportion de décès). Stockez ce nouveau dataframe dans un objet, cfr_df.\n\n\n\n\n\n\n\nTip\n\n\n\nBonus. Une fonction de “raccourci” utile est drop_na() du package {tidyr} qui équivaut à filter(!is.na()).\n\ndf_linelist |&gt;\n  drop_na(statut_sortie) |&gt;\n  count(statut_sortie)\n\ndrop_na() est particulièrement utile car vous pouvez lui donner plusieurs noms de colonnes pour filtrer. Mais attention, cela supprimera toutes les lignes où une ou plusieurs de ces colonnes ont une valeur manquante."
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#tableau-récapitulatif-statistiques-par-sous-préfecture",
    "href": "sessions_core/05_summary_table.fr.html#tableau-récapitulatif-statistiques-par-sous-préfecture",
    "title": "Tableaux récapitulatifs",
    "section": "Tableau récapitulatif : statistiques par sous-préfecture",
    "text": "Tableau récapitulatif : statistiques par sous-préfecture\nMaintenant que nous avons produit quelques tableaux de fréquence et de contingence simples, nous pouvons augmenter la complexité. Une tâche courante en épidémiologie consiste à examiner les statistiques résumées dans des sous-ensembles de données.\nPar exemple, on peut nous demander de produire des statistiques sur les patients au niveau des sous-préfectures, c’est-à-dire que pour chaque sous-préfecture dans les données, nous devons répondre aux questions suivantes :\n\nCombien de patients ont été consultés ?\nQuel est leur âge moyen ?\nQuelle a été la date d’admission la plus ancienne ?\nCombien de patients ont été hospitalisés ?\nParmi les enfants de moins de 6 mois, combien sont décédés ?\n\nC’est exactement pour cela que la fonction summarize() a été créée ! Elle nous permet de calculer des statistiques résumées sur un ensemble de données, et la syntaxe est similaire à celle de mutate() :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf |&gt;\n  mutate(new_col = function_to_create(existing_col))\n\ndf |&gt;\n  summarize(.by = grouping_variable,\n            new_col = summary_function(existing_col))\n\nConsidérons le code suivant, où nous résumons les données pour calculer l’âge moyen de tous les patients.\n\ndf_linelist |&gt;\n  summarize(moy_age = mean(age))\n\n# A tibble: 1 × 1\n  moy_age\n    &lt;dbl&gt;\n1    6.82\n\n\nNotez que ce code donne une seule valeur pour l’âge moyen. Aucune variable de regroupement n’a été fournie, donc summarize() a renvoyé une statistique récapitulative pour l’ensemble du jeu de données. Pour calculer l’âge moyen par strate spécifique, nous devons spécifier une variable de regroupement en utilisant l’argument .by :\n\ndf_linelist |&gt;\n  summarize(.by = sexe, # Faire le résumé (ici, la moyenne) par sexe\n            moy_age = mean(age))\n\n# A tibble: 2 × 2\n  sexe  moy_age\n  &lt;chr&gt;   &lt;dbl&gt;\n1 f        6.77\n2 m        6.87\n\n\n\nJetez un œil aux résultats ci-dessus. Comment les interprétez-vous ?\n\nMaintenant que nous pouvons utiliser summarize(), nous pouvons l’utiliser pour calculer des statistiques récapitulatives appropriées par sous-préfecture. Commençons par appeler un summarize() vide et regrouper les données sur sous_prefecture.\n\nExécutez le code suivant :\n\ndf_linelist |&gt;\n  summarize(.by = sous_prefecture)\n\nQue se passe-t-il lorsque vous exécutez ces lignes ?\n\n\nComptages\nNous voulons d’abord examiner le nombre de cas dans chaque sous_prefecture. Cela peut être fait en utilisant la fonction d’aide n() :\n\ndf_linelist |&gt;\n  summarize(.by = sous_prefecture,\n            n_patients = n()  # pour compter\n)\n\n\nOk, maintenant construisons un tableau récapitulatif pour chaque sous-préfecture. Commençons par reproduire les lignes ci-dessus.\n\n\n\nRécapitulatifs des variables continus\nNous pouvons ensuite utiliser les fonctions mean(), median(), min(), max() (et autres) pour produire des récapitulatifs pour les variables continues. Par exemple, l’âge moyen :\n\ndf_linelist |&gt;\n  summarize(.by = sous_prefecture,\n            n_patients = n(),\n            mean_age = mean(age))\n\n\nAjoutez la date d’admission minimale à votre tableau pour chacune des sous_prefecture ? Êtes-vous satisfait des résultats ?\n\n\n\n\n\n\n\nTip\n\n\n\nN’oubliez pas qu’avec les fonctions arithmétiques telles que mean(), median(), min(), max(), vous devez indiquer explicitement à R de supprimer NA.\n\n\n\n\nComptage avec une condition\nNous pouvons également être intéressés par le nombre de patients (lignes) qui répondent à une condition : le nombre de patients de sexe féminin. Le comptage par condition logique peut être effectué avec la syntaxe suivante :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\nsummarize(sum_category = sum(LOGIC_TEST, na.rm = TRUE))\n\nCette somme nous permet de compter toutes les lignes où notre condition a été remplie (retourne TRUE). Par exemple :\nCette somme nous permet de compter toutes les lignes où notre condition a été remplie (retourne TRUE). Par exemple :\n\ndf_linelist |&gt;\n  summarize(.by = sous_prefecture,\n            n_female = sum(sexe == \"f\", na.rm = TRUE))\n\n\nAjoutez une variable à votre tableau qui compte le nombre de patients qui ont été hospitalisés. (c’est-à-dire : les lignes qui ont “oui” dans la variable “hospitalisation”)\n\n\n\nAutres statistiques\nParfois, nous voulons produire une statistique plus compliquée, par exemple l’âge moyen de tous les patients hospitalisés. Ici, la syntaxe est un peu différente :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf |&gt;\n  summarize(mean_category = mean(col_to_use[LOGIC_TEST], na.rm = TRUE))\n\nIci, nous avons : - Indiqué quelle statistique de synthèse nous voulons utiliser (mean()) - Indiqué sur quelle colonne nous voulons calculer cette statistique (col_to_use) - Création d’une condition indiquant les observations de cette colonne à utiliser dans le calcul ([LOGIC_TEST])\nPour donner un exemple concret, si nous voulions calculer la moyenne de la variable age mais uniquement pour les patients hospitalisés (c’est-à-dire dans les lignes où hospitalisation == \"oui\") nous écririons :\n\ndf_linelist |&gt;\n  summarize(.by = sous_prefecture,\n            n_patients = n(),\n            moy_age_hosp = mean(age[hospitalisation == \"oui\"], na.rm = TRUE))\n\nL’utilisation d’un test logique dans l’exemple ci-dessus est appelée indexation logique, où une condition est essentiellement utilisée pour filtrer les observations que vous souhaitez prendre en compte lors d’un calcul. L’indexation logique est très puissante, mais elle peut aussi demander un certain temps d’adaptation, alors ne vous inquiétez pas trop si ce n’est pas parfaitement clair à ce stade.\n\nPouvez-vous utiliser cette syntaxe pour calculer l’âge moyen des patientes dans votre tableau ?\n\nC’est très bien ! Nous commençons à obtenir un tableau récapitulatif groupé assez exhaustif avec beaucoup d’informations utiles par “sous-préfecture” ! Un défi supplémentaire pour vous :\n\nDÉFI : Pourriez-vous ajouter une variable à votre tableau qui compte le nombre de patients décédés parmi ceux qui ont &lt; 6 mois.\n Note. Vous voulez compter les lignes (donc utiliser sum()) qui remplissent une condition spécifique pour le résultat (statut_sortie == \"deces\"), mais uniquement lorsque age_group == \"&lt; 6 months\"\n\n\n\nUtiliser la sortie\nEnfin, n’oubliez pas que summarize() renvoie un dataframe que nous pouvons ensuite manipuler davantage (par exemple : avec filter() et mutate()).\n\nAjoutez un mutate() après avoir produit votre tableau récapitulatif pour calculer :\n\nLa proportion de patients hospitalisés par sous-préfecture\nLa proportion de patientes par sous-préfecture\n\n\nL’en-tête de votre tableau final devrait ressembler à ceci :\n\n\n# A tibble: 6 × 11\n  sous_prefecture n_patients moy_age min_admission n_femme n_hosp moy_age_hosp\n  &lt;chr&gt;                &lt;int&gt;   &lt;dbl&gt; &lt;date&gt;          &lt;int&gt;  &lt;int&gt;        &lt;dbl&gt;\n1 Moissala              1808    6.84 2022-08-14        923    612         5.49\n2 Bouna                 1376    6.56 2023-01-11        669    412         5.67\n3 Bedjondo               534    7.07 2023-06-09        251    184         5.21\n4 Bekourou               496    6.84 2023-06-17        251    164         6.04\n5 Bedaya                 435    7.10 2023-07-04        209    147         6.16\n6 Koumra                 253    7.11 2023-08-14        138     84         6.26\n# ℹ 4 more variables: moy_age_femme &lt;dbl&gt;, n_deces_moins_6m &lt;int&gt;,\n#   prop_female &lt;dbl&gt;, prop_hosp &lt;dbl&gt;"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#cest-fait",
    "href": "sessions_core/05_summary_table.fr.html#cest-fait",
    "title": "Tableaux récapitulatifs",
    "section": "C’est fait !",
    "text": "C’est fait !\nVous devriez être fiers de vous, la création de tableaux récapitulatifs est une compétence importante pour un épidémiologiste, et le faire en R est très efficace ! N’oubliez pas de sauvegarder votre code !\n\n\n\n Solutions exercices"
  },
  {
    "objectID": "sessions_core/05_summary_table.fr.html#pour-aller-plus-loin",
    "href": "sessions_core/05_summary_table.fr.html#pour-aller-plus-loin",
    "title": "Tableaux récapitulatifs",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\n\nExercices supplémentaires\n\nCréez un tableau récapitulatif qui calcule les statistiques suivantes par groupes d’âge :\n\n\nLe nombre de patients\nLa proportion d’hommes\nLe nombre de décès\nLe CFR\nLe nombre de décès parmi les patients atteints de pneumonie\n\n\nFaites un tableau qui montre la proportion de patients par âge ayant reçu un vaccin contre la rougeole (par rappel oral ou par carte) et ceux qui ont reçu 1 ou 2 doses.\nFaites un tableau comparant la proportion de patients hospitalisés et non hospitalisés présentant un TDR positif pour le paludisme, de la fièvre, une éruption cutanée, une toux, des yeux rouges, une pneumonie, une encéphalite et un MUAC « rouge » ou « jaune » (moins de 125 mm).\nCalculer le nombre moyen de jours entre l’apparition des premiers symptômes et la consultation par sous-préfecture.\nCalculer le temps moyen passé à l’hôpital (i.e. jours entre l’admission et le résultat) par résultat (i.e. chez ceux qui ont guéri et ceux qui sont décédés).\n\n\n\nRessources supplémentaires\n\nLe chapitre du manuel EpiR sur le regroupement des données\nUne fois que vous avez des tableaux, vous pouvez les personnaliser en profondeur pour l’affichage/la publication à l’aide du paquetage {gt} :\n\nSite web de gt\nLivre sur gt"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html",
    "href": "sessions_core/06_epicurves.fr.html",
    "title": "Introduction to data visualization with ggplot2",
    "section": "",
    "text": "Découvrir les bases de la visualisation de données en R avec le package {ggplot2}\nConstruire une courbe épidémique simple"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#objectifs",
    "href": "sessions_core/06_epicurves.fr.html#objectifs",
    "title": "Introduction to data visualization with ggplot2",
    "section": "",
    "text": "Découvrir les bases de la visualisation de données en R avec le package {ggplot2}\nConstruire une courbe épidémique simple"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#introduction",
    "href": "sessions_core/06_epicurves.fr.html#introduction",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Introduction",
    "text": "Introduction\nPour cette dernière session, nous allons vous donner une courte introduction à la visualisation de données à l’aide du package {ggplot2}, un outil populaire. Gardez en tête que la visualisation de données est un énorme sujet, et {ggplot2} un vaste package et il n’est pas réaliste de tout traiter en trois heures. La session d’aujourd’hui est une introduction que nous espérons douce aux concepts de base de la visualisation, en prenant pour objet un graphe fameux en épidémiologie, la courbe épidémique.\nNotre visualisation finale ressemblera à ceci :"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#setup",
    "href": "sessions_core/06_epicurves.fr.html#setup",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Setup",
    "text": "Setup\nDépendances. Cette session suppose que vous savez utiliser RStudio, que vous êtes capable d’importer des données et que vous connaissez les verbes de base de manipulation des données que nous avons vus dans les sessions de base jusqu’à présent. Si vous avez besoin d’un rappel sur l’un de ces sujets, nous vous encourageons à revoir les sessions de base du parcours d’apprentissage.\n\nCette session utilisera la version nettoyée de l’ensemble de données Moissala sur la rougeole.\n\n\n\n  Course Folder\n\n\n\n Ouvrez votre projet Rstudio du cours et créez un nouveau script appelé “courbe_epi.R” avec les métadonnées appropriées. Enregistrez le dans R/. Pour cette session, nous aurons besoin de charger les packages {here}, {rio}, {dplyr}, {lubridate}, et{ggplot2}. Ajoutez une section # IMPORTATION DONNÉES où vous importez les données nettoyées du cours (linelist_moissala_clean_FR.RDS)."
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#les-paradigmes-de-la-création-de-graphiques",
    "href": "sessions_core/06_epicurves.fr.html#les-paradigmes-de-la-création-de-graphiques",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Les paradigmes de la création de graphiques",
    "text": "Les paradigmes de la création de graphiques\nIn R, and indeed in everything, there are a loIl y a de nombreuses approches à la visualisation de données, en général et en R en particulier. Les deux plus grands paradigmes sont :\n\nTout en un : cette approche est caractérisée par l’existence d’une fonction (en général complexe) pour gérer tous les aspects de la construction d’un graphique. Base R par exemple, utilise cette approche (et n’est pas le seul).\nGraphiques en couches (ou modulaires) : le graphique est décomposé en éléments (formes, titres, barres d’erreurs, thèmes…) associées à des couches. Différentes fonctions ajoutent ou modifient ces éléments. Ce paradigme est utilisé par les packages {ggplot2}, {highcharter}, ou {echarts4r} et un certain nombre d’outils modernes.\n\nUne discussion approfondie sur les raisons pour lesquelles on peut utiliser une approche plutôt qu’une autre dépasse le cadre de ce cours, mais nous noterons que la plupart des paquets de visualisation modernes ont tendance à utiliser un [modèle en couches] {.hovertip bs-toggle=‘tooltip’ bs-title=“C’est parce que les modèles en couches ont tendance à être plus pratiques lors de la construction de visualisations complexes ou hautement personnalisées.”}. En gardant cela à l’esprit, examinons les types de couches dont nous parlons dans notre approche « en couches ».\n\nDécomposition d’un graphique\nDans ce tutoriel, nous décomposons les graphiques en quatre composantes (couches) :\n\nLe canevas / les données\nLes formes géométriques primaires\nLes titres et labels\nLe thème\n\nOn peut illustrer ces composants avec la courbé épidémique schématique suivante :\n\n\n\n\n\nLa première couche, le caneva (ou la toile) est fondamentale. Comme un artiste prépare sa toile vierge et ses outils avant de se lancer dans une peinture, R doit en premier lieu créer un canevas prêt à accueillir les éléments de représentation graphique. C’est lors de la création du canevas que nous indiquons à R que nous voulons créer un graphique, et avec quelles variables.\nIci, nous allons spécifier à R que nous voulons un graphique où l’axe horizontal représente la date, et l’axe vertical représente le nombre de cas. Une fois le canevas mise en place, nous ajouterons d’autres couches, comme un artiste ajouterait de la peinture, leur signature ou un cadre.\n\n\nOssature d’un ggplot\nLa recette pour construire un ggplot (un graphe produit par le package {ggplot}) est de la forme suivante :\n\nCréation d’un canevas à l’aide de ggplot(aes(...))\nAjout de couches sur le canevas avec +\n\nNotez que {ggplot2} utilise l’opérateur + pour ajouter des couches sur le graphe.\nLa syntaxe générale d’un ggplot est :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf |&gt;                    # passer les données\n  ggplot(aes(x = ...,    # étape 1 : créer le canevas\n             y = ...)) +\n  couche_1(...) +        # étape 2 : ajout de la première couche\n  couche_2(...) +        # étape 3 : ajout d'une autre couche\n  ...                    # continuer à ajouter des couches...\n\nLe nombre de couches à ajouter dépend de la complexité du graphique que vous souhaitez créer. Dans notre cas, nous ajouterons trois couches en utilisant les fonctions suivantes :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf |&gt;                    # passer les données\n  ggplot(aes(x = ...,    # étape 1 : créer le canevas\n\n             y = ...)) +\n  geom_col(...) +        # étape 2 : ajout des formes (barres)\n  labs(...) +            # étape 3 : ajouter des titres\n  theme_classic(...)     # étape 4 : amélioration du thème\n\nNous pouvons mettre à jour notre précédent schéma avec ces fonctions :\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDans l’exemple précédent, nous passons le jeu de données à la fonction ggplot() à l’aide de l’opérateur pipe (comme nous l’avons souvent fait avec d’autres fonctions). C’est possible car le premier argument nécessaire de la fonction est le dataframe contenant les variables à représenter. Soyez attentifs, il est facile de se tromper et de chercher à utiliser un + à la place du |&gt;\n\n\nDans la section suivante, nous allons décrire les différentes étapes plus en détail, en utilisant notre jeu de données rougeole à Moissala pour faire notre première courbe épidémique."
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#sec-epicurve-steps",
    "href": "sessions_core/06_epicurves.fr.html#sec-epicurve-steps",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Votre premier ggplot",
    "text": "Votre premier ggplot\n\nPréparer vos données : Agrégation par jour\nNous aimerions tracer une courbe des cas quotidiens. Vous l’aurez peut-être remarqué, nos données actuelles sont quotidiennes, mais il est évident que plusieurs cas peuvent se produire certains jours. Donc,il faut agréger les données par jour. Heureusement, vous avez déjà appris à résumer les données lors des sessions précédentes.\n\nEn utilisant count(), créez un nouveau dataframe appelé df_cases qui résume le nombre total de cas observés par jour. L’en-tête de ce cadre de données devrait ressembler à ceci :\n\n\n  date_debut n\n1 2022-08-13 1\n2 2022-08-17 1\n3 2022-08-18 1\n4 2022-08-22 1\n5 2022-08-30 2\n6 2022-09-01 1\n\n\n\nBien !\nDans les étapes suivantes, vous allez utiliser df_cas pour tracer une courbe épidémique du nombre de cas par semaine. En revanche, les exemples données dans les exercices pour illustrer le fonctionnement des fonctions seront faits sur le nombre de hospitalisations par semaine. Pour cela, j’utiliserai un dataframe df_hopital, qui ressemble à ceci :\n\n\n  date_admission patients\n1     2022-08-14        1\n2     2022-08-25        1\n3     2022-09-02        1\n4     2022-09-06        1\n5     2022-09-09        1\n6     2022-09-10        1\n\n\n\n\nCréer le canevas\nLa première étape est de créer votre “canevas” en spécifiant votre jeu de données et le nom des colonnes que vous voulez représenter sur le graphique. Cela est fait à l’aide de la fonction ggplot(aes()) selon la syntaxe suivante :\n\n# NE PAS EXÉCUTER (PSEUDO-CODE)\ndf_data |&gt;\n  ggplot(aes(x = x_axis_variable_name,\n             y = y_axis_variable_name))\n\nPour l’exemple, je vais placer la date (date_admission) sur l’axe des x et le nombre de patients (patients) sur l’axe des y :\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients))\n\n\n\n\n\n\n\n\nDans Rstudio, ce graphique devrait apparaître dans l’onglet “Plots” dans le panneau en bas à droite (par défaut) :\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nJust like with {dplyr}, we write our column names without quotation marks. This is unsurprising as {ggplot2}, like {dplyr}, is a member of the {tidyverse} and therefore uses similar syntax.\n\n\nQu’est ce que cette fonction aes() que nous avons imbriqué dans la fonction ggplot() ?\nLa fonction aes() n’est jamais utilisée seule, elle est toujours passée à ggplot(). Elle sert à faire correspondre les variables du jeu de données aux éléments visuels du graphique (en anglais on parle de “mapping”, qui est occasionnellement traduit par “mappage”). Les plus basiques de ces éléments graphiques sont les axes, mais on peut aussi définir comment la couleur ou la taille d’éléments varie en fonction de variables dans les données (par exemple, statut à la sortie).\n\nCréez une nouvelle section # PLOT COURBE EPI. Ensuite, en vous inspirant de l’exemple précédent, créez la base d’un ggplot avec le dataframe df_cas, et définissez l’axe des x et des x.\n\nPour le moment, le résultat devrait ressembler à ceci :\n\n\n\n\n\n\n\n\n\nTrès bien. Maintenant, ajoutons les barres\n\n\nAjouter les formes\nMaintenant que la toile est prête, commençons à dessiner dessus, et ajoutons des formes. Dans {ggplot2}, les formes géométriques sont surnommées des “géométries” ou “geom” en raccourci, et représentent les données. Les geoms les plus courants sont :\n\nDiagrammes en bâtons (geom_col() or geom_bar())\nHistogrammes (geom_histogram())\nNuages de points(geom_point())\nCourbes(geom_line())\nDiagramme en boîte à moustache (boxplots) (geom_boxplot())\n\nAujourd’hui nous allons nous concentrer sur les diagrammes en bâton, pour créer une courbe épidémique. Nous allons utiliser la fonction geom_col().\nNous allons maintenant rajouter les barres à la courbe des cas hospitalisés. Rappelez-vous que l’on ajoute une nouvelle couche à notre objet ggplot à l’aide de +.\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col()\n\n\n\n\n\n\n\n\nC’est génial, cela ressemble vraiment à une épicurve. Bien qu’elle ait l’air un peu… grise. Si nous voulons mettre à jour la couleur de nos barres (appelée le fill), nous devons simplement ajouter l’argument fill to geom_col().\nFaisons un essai :\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\")\n\n\n\n\n\n\n\n\n\nMettez à jour votre graphe pour ajouter les barres avec la couleur #2E4573.\n\nVotre graphe devrait ressembler à ceci :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDans {ggplot2}, les couches doivent être ajoutées à un objet ggplot existant (le canevas définit à l’étape 1). Exécuter la fonction geom_col() toute seule ne produira pas un graphe. Si l’on reprend notre analogie avec la peinture, ce serait comme essayer d’utiliser la peinture sans support (toile).\n\n\nCe graphe s’améliore d’instant en instant ! Maintenant il est temps de le rendre un petit peu plus informatif…\n\n\nAjouter les titres\nUn bon graphique doit avoir des titres et des labels informatifs or pour le moment, ce n’est pas le cas de nos graphiques (n n’est pas très informatif).\nLa fonction lab() permet d’ajouter des titres et labels à plusieurs éléments du graphique :\n\nTitre des axes (x = ety =)\nTitre du graphique (title =)\nCaption\n\nComme avec les autres couches, nous pouvons ajouter la couche contenant les titres et labels à notre graphe avec le signe + :\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Patients par Jour\",\n       title = \"Hospitalisations pour rougeole dans la région de Madoul (Tchad)\")\n\n\n\n\n\n\n\n\n\nAjoutez des titres raisonnables à votre graphe.  Bonus. Ajoutez une source des données en utilisant caption.\n\nVotre graphe pourrait maintenant ressembler à celle-ci (par exemple) :\n\n\n\n\n\n\n\n\n\n\n\nChanger le thème\nLe thème de base de ggplot n’est pas très attractif, et la taille des polices est trop petite pour être lisible sur la majorité des supports. Si vous voulez utiliser votre graphique dans des rapports ou des présentations, il vaudrait mieux améliorer son apparence.\nPour cela, il suffit d’ajouter une couche “thème” à notre graphe (la dernière couche pour aujourd’hui !). Si le nom des fonctions des geoms commençait toujours par geom_, le nom de toutes les fonctions de thème commence par theme_. Il existe plusieurs thèmes prédéfinis, et vous pouvez aller les regarder sur le site de {ggplot2}.\nAujourd’hui, nous allons utiliser theme_classic(), qui offre une alternative élégante au thème de base :\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Patients par Jour\",\n       title = \"Hospitalisations pour rougeole dans la région de Madoul (Tchad)\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nC’est déjà plus joli. Maintenant, nous voudrions augmenter la taille de la police. Nous pouvons faire ça en ajustant la taille de la police à l’aide de l’argument base_size:\n\ndf_hopital |&gt;\n  ggplot(aes(x = date_admission,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date\",\n       y = \"Patients par Jour\",\n       title = \"Hospitalisations pour rougeole dans la région de Madoul (Tchad)\") +\n  theme_classic(base_size = 17)\n\n\n\n\n\n\n\n\n’est beaucoup mieux !\nRappelez-vous que la taille de la police doit être choisie en fonction de la destination du graphe (présentation, rapport informel, rapport final ?). Il en va de même pour le choix du thème, qui reste un choix partiellement subjectif. Il existe des principes de visualisation qui peuvent guider vos choix lors de la création d’un graphe (ou d’une table), mais la visualisation de données est autant un art qu’une science.\n\nAjoutez une dernière couche à votre graphe pour ajouter un thème de votre choix, avec une taille de police plus appropriée.\n\n\n\nSauvegarder votre graphique\nSi vous souhaitez enregistrer votre graphe, vous pouvez cliquer sur le bouton « Exporter » dans le panneau de tracé de RStudio :"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#la-fin",
    "href": "sessions_core/06_epicurves.fr.html#la-fin",
    "title": "Introduction to data visualization with ggplot2",
    "section": "La Fin !",
    "text": "La Fin !\nBravo! Vous avez créé votre première courbe épidémique en R !\n\n\n\n Solutions file"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#aller-plus-loin",
    "href": "sessions_core/06_epicurves.fr.html#aller-plus-loin",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Aller plus loin",
    "text": "Aller plus loin\n\nExercices supplémentaires\n\nUtilisez le theme_minimal() sur un de vos graphiques, avec une police de taille de base de 18.\nAllez sur ce site, choisissez une couleur et mettez à jour la couleur de vos barres.\n\n\n\nExercices de défi\n\nAu lieu d’agréger par date, comptez le nombre de patients par sous-préfecture. Essayez d’adapter votre code pour créer un diagramme à barres du nombre de patients par sous-préfecture.\n\n\n\nSatellites\n\nCourbes épidémiques hebdomadaires\nGraphiques multiples (facetting)"
  },
  {
    "objectID": "sessions_core/06_epicurves.fr.html#ressources",
    "href": "sessions_core/06_epicurves.fr.html#ressources",
    "title": "Introduction to data visualization with ggplot2",
    "section": "Ressources",
    "text": "Ressources\n\nUn livre complet sur l’utilisation de {ggplot2}.\n\nUn chapitre entier sur les épicurves"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html",
    "href": "sessions_extra/data_exploration.fr.html",
    "title": "Exploration des données",
    "section": "",
    "text": "Effectuer une exploration rapide d’un ensemble de données importé\nProduire des tableaux de fréquence pour les variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#objectifs",
    "href": "sessions_extra/data_exploration.fr.html#objectifs",
    "title": "Exploration des données",
    "section": "",
    "text": "Effectuer une exploration rapide d’un ensemble de données importé\nProduire des tableaux de fréquence pour les variables"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#setup",
    "href": "sessions_extra/data_exploration.fr.html#setup",
    "title": "Exploration des données",
    "section": "Setup",
    "text": "Setup\nDependances. Cette session supplémentaire suppose que vous avez suivi les sessions introduction à R et R studio, et importation de données.\n\nPour cette session, nous travaillerons avec notre liste brute de rougeole de Moissala qui peut être téléchargée ici :\n\n\n\n  Course Folder\n\n\n\n Assurez-vous qu’il est correctement stocké dans data/raw de votre projet. Ensuite, ouvrez un nouveau script appelé data-exploration.R, et assurez-vous que les paquets {here}, {rio} et {dplyr} sont chargés. Enfin, importez les données dans R sous la forme d’un objet appelé df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#exploration-des-données",
    "href": "sessions_extra/data_exploration.fr.html#exploration-des-données",
    "title": "Exploration des données",
    "section": "Exploration des données",
    "text": "Exploration des données\nJuste après avoir importé des données dans R, nous pouvons avoir envie d’y jeter un coup d’œil. Lorsque l’on parle d’exploration de données, on veut généralement faire plusieurs choses :\n\nExaminer les dimensions des données (c’est-à-dire le nombre de lignes et de colonnes).\nExaminer les noms des colonnes\nVisualiser les premières ou les dernières lignes\nDéterminer le type des variables\nDéterminer la plage de valeurs des variables continues\nObserver les valeurs possibles de chaque variable catégorielle\n\nCe processus est crucial et nous permettra de nous familiariser avec nos données et d’identifier les problèmes qui seront traités lors de l’étape de nettoyage des données."
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#exploration-de-base",
    "href": "sessions_extra/data_exploration.fr.html#exploration-de-base",
    "title": "Exploration des données",
    "section": "Exploration de base",
    "text": "Exploration de base\nLa toute première chose que vous voulez savoir sur vos données, ce sont les dimensions, c’est-à-dire le nombre de lignes et le nombre de colonnes qui composent vos données. Il existe plusieurs façons d’obtenir ces informations dans R :\n\nRegardez votre volet environnement dans RStudio et vérifiez vos données - le nombre à côté (5230x25) nous indique qu’il s’agit d’un data frame avec 5230 lignes et 25 colonnes.\nUtilisez dim() sur vos données pour renvoyer un vecteur avec le nombre de lignes et le nombre de colonnes.\nVous pouvez aussi utiliser ncol() pour obtenir le nombre de colonnes et nrow() pour le nombre de lignes.\n\nIl est bon de se souvenir de ces nombres afin de pouvoir repérer rapidement tout changement inattendu dans vos données au cours de votre analyse (c’est-à-dire plus ou moins de lignes ou de colonnes que prévu).\n\nEn utilisant la méthode de votre choix, obtenez les dimensions de votre data frame df_linelist."
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#noms-de-variables",
    "href": "sessions_extra/data_exploration.fr.html#noms-de-variables",
    "title": "Exploration des données",
    "section": "Noms de variables",
    "text": "Noms de variables\nComme nous allons utiliser les noms des variables très souvent au cours de notre analyse, nous voulons nous familiariser avec eux dès le début. De plus, nous devons identifier celles qui devront être renommées lors du nettoyage des données. La fonction names() renvoie un vecteur de tous les noms de variables dans notre cadre de données :\n\nnames(df_linelist)\n\n [1] \"id\"                   \"full_name\"            \"sex\"                 \n [4] \"age\"                  \"age_unit\"             \"region\"              \n [7] \"sub_prefecture\"       \"village_commune\"      \"date_onset\"          \n[10] \"date_consultation\"    \"hospitalisation\"      \"date_admission\"      \n[13] \"health_facility_name\" \"malaria_rdt\"          \"fever\"               \n[16] \"rash\"                 \"cough\"                \"red_eye\"             \n[19] \"pneumonia\"            \"encephalitis\"         \"muac\"                \n[22] \"vacc_status\"          \"vacc_doses\"           \"outcome\"             \n[25] \"date_outcome\"        \n\n\n\nQue pensez-vous des noms de votre ensemble de données ? Pouvez-vous déjà repérer des noms de variables que vous aimeriez renommer ?"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#inspecter-vos-données",
    "href": "sessions_extra/data_exploration.fr.html#inspecter-vos-données",
    "title": "Exploration des données",
    "section": "Inspecter vos données",
    "text": "Inspecter vos données\nIl est également intéressant d’inspecter vos données, cela peut vous permettre de repérer plus facilement certaines incohérences, des variables avec beaucoup de valeurs manquantes, et cela vous permettra de voir à quelles valeurs s’attendre pour chacune d’entre elles. Vous pouvez “print” vos données dans la console en :\n\nExécutant l’objet df_linelist seul (attention, vous ne voudrez peut-être pas faire cela si vous avez un grand ensemble de données).\nUtilisant la fonction head() pour voir les 6 premières lignes (vous pouvez augmenter ce nombre en utilisant l’argument n)\nUtilisant la fonction tail() pour voir les 6 dernières lignes (encore une fois, vous pouvez augmenter ce nombre en utilisant l’argument n)\n\nCes méthodes n’afficheront que les 40 premières lignes de vos données au maximum, car c’est la limite de votre console. Alternativement, vous pouvez utiliser View() pour voir vos données sous forme de tableau. Cela ouvrira une nouvelle fenêtre avec vos données affichées comme dans une feuille de calcul Excel. Note : cette commande ne fait qu’afficher les données, elle ne vous permet pas de les modifier.\n\n\n\n\n\n\nTip\n\n\n\nSoyez très prudent avec View() sur un grand jeu de données car cela peut faire planter votre session RStudio. Pour éviter cela, vous pouvez imprimer la sortie dans la console.\n\n\n\nPouvez-vous afficher les 15 premières lignes de vos données ? Que se passe-t-il lorsque vous modifiez la largeur de votre fenêtre de console et que vous exécutez à nouveau la commande ?"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#types-des-variables",
    "href": "sessions_extra/data_exploration.fr.html#types-des-variables",
    "title": "Exploration des données",
    "section": "Types des variables",
    "text": "Types des variables\nNous voulons maintenant vérifier le type des différentes variables. C’est important car une partie du nettoyage des données consiste à s’assurer que les variables numériques sont de type numeric, dates Date, et que les variables catégorielles sont de type factor ou character. Vous avez déjà vu la fonction class(), qui permet de vérifier le type d’un vecteur. Dans R, chaque variable d’un dataframe est un vecteur. Nous pouvons extraire toutes les valeurs de ce vecteur en utilisant le sign $, et les passer à la fonction class() :\n\nclass(df_linelist$age)\n\n\nEssayez d’extraire toutes les valeurs de la variable sex. Quelle est le type de cette variable ?\n\nVous pouvez également utiliser str() sur votre dataframe pour vérifier le type de toutes les variables à la fois :\n\nstr(df_linelist)\n\n\nUtilisez str() pour vérifier le type de données de chaque colonne. Y a-t-il quelque chose d’étrange ? Rappelez-vous que vous pouvez aussi utiliser des fonctions comme is.character() et is.numeric() si vous voulez tester le type d’une colonne en particulier."
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#exploration-des-variables-continues",
    "href": "sessions_extra/data_exploration.fr.html#exploration-des-variables-continues",
    "title": "Exploration des données",
    "section": "Exploration des variables continues",
    "text": "Exploration des variables continues\nMaintenant que vous savez comment extraire les valeurs d’une variable, vous pouvez vouloir explorer certaines des valeurs des variables numériques pour vérifier les incohérences. Calculer des statistiques récapitulatives pour ces variables, et Base R fournit de nombreuses fonctions pratiques :\n\n\n\n\n\n\n\n\n\nFonction\nDescription\nExemple\nRetours\n\n\n\n\nmin()\nValeur minimale\nmin(x)\nValeur minimale unique\n\n\nmax()\nValeur maximale\nmax(x)\nValeur maximale unique\n\n\nmean()\nMoyenne arithmétique\nmean(x)\nValeur moyenne\n\n\nmedian()\nValeur moyenne\nmedian(x)\nValeur moyenne\n\n\nrange()\nMin et max\nrange(x)\nVecteur de (min, max)\n\n\nIQR(x)\nQ3 - Q1\nIQR(x)\nQ3 - Q1\n\n\nquantile()\nQuantiles spécifiés\nquantile(x, probs = c(0.25, 0.75))\nQuantiles demandés\n\n\nsd()\nEcart-type\nsd()\nEcart-type\n\n\nvar()\nVariance\nvar(x)\nVariance\n\n\nsum()\nSomme des valeurs\nsum(x)\nSomme\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCes fonctions exigent que vous supprimiez explicitement les valeurs manquantes (NA) en utilisant l’argument na.rm = TRUE\n\n\nVous pouvez extraire les valeurs d’une variable en utilisant $, et les passer à n’importe laquelle de ces fonctions.\n\nUtilisez la syntaxe $ pour obtenir :\n\nLa valeur minimale de age\nLe maximum de muac\n\nDes problèmes ?"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#exploration-des-variables-catégorielles",
    "href": "sessions_extra/data_exploration.fr.html#exploration-des-variables-catégorielles",
    "title": "Exploration des données",
    "section": "Exploration des variables catégorielles",
    "text": "Exploration des variables catégorielles\nEnfin, examinons les valeurs de nos variables catégorielles. Pour ce faire, nous pouvons utiliser des tableaux de fréquence. C’est pratique car :\n\nIls nous permettent de voir rapidement les valeurs uniques d’une variable catégorielle\nLe nombre d’observations pour chacune de ces catégories\n\nPour ce faire, on utilise la fonction count() du package {dplyr}, qui accepte un dataframe et le nom d’une (ou plusieurs !) colonne(s) en tant qu’arguments. Il compte alors le nombre d’observations de chaque élément unique dans cette colonne. Par exemple, voyons les valeurs possibles de la variable sex :\n\ncount(df_linelist, sex)\n\nLe résultat est un nouveau dataframe, plus petit, contenant le nombre de patients observés, stratifié par sex. Il semble que cette variable nécessite un recodage… Nous le ferons dans une prochaine session.\n\nEn utilisant les données de votre liste, examinez les valeurs de la variable outcome. A quoi cela ressemble-t-il ?\nMaintenant, essayez d’ajouter l’argument sort = TRUE à la fonction count(). Que fait cet argument ?"
  },
  {
    "objectID": "sessions_extra/data_exploration.fr.html#cest-fait",
    "href": "sessions_extra/data_exploration.fr.html#cest-fait",
    "title": "Exploration des données",
    "section": "C’est fait !",
    "text": "C’est fait !\nBravo pour ce premier coup d’œil sur vos données !\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_extra/faceting.fr.html",
    "href": "sessions_extra/faceting.fr.html",
    "title": "Graphiques multiples (facetting)",
    "section": "",
    "text": "Dans cette session, le but est d’apprendre à :\n\ncréer des graphiques multiples très rapidement avec {ggplot2}\nmodifier les paramètres les plus courants pour améliorer l’apparence de ces graphiques"
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#objectifs",
    "href": "sessions_extra/faceting.fr.html#objectifs",
    "title": "Graphiques multiples (facetting)",
    "section": "",
    "text": "Dans cette session, le but est d’apprendre à :\n\ncréer des graphiques multiples très rapidement avec {ggplot2}\nmodifier les paramètres les plus courants pour améliorer l’apparence de ces graphiques"
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#introduction",
    "href": "sessions_extra/faceting.fr.html#introduction",
    "title": "Graphiques multiples (facetting)",
    "section": "Introduction",
    "text": "Introduction\nPrérequis : ce satellite s’appuie sur la session sur les courbes épidémiques, durant laquelle nous avons appris à visualiser la distribution quotidienne des cas de rougeoles au cours du temps à l’aide de {ggplot2} :\n\n\n\n\n\n\n\n\n\nCe graphique est très utile, mais ce qui serait encore plus utile serait de pouvoir le décliner rapidement selon les modalités d’une autre variable. Par exemple, nous pourrions vouloir insérer un graphique similaire mais par groupe d’âge dans un rapport de situation [sitrep en anglais]. Il y a plusieurs manières d’arriver à ce résultat. Vous pourriez :\n\nfiltrer un jeu de données pour chacune des classes d’âge, copier-coller le code du graphe et l’adapter pour créer un graphique par classe d’âge\napprendre à utiliser les boucles for ou les fonctions des familles apply() ou map() qui servent répéter des actions sans copier-coller\nfaire confiance à {ggplot2} pour avoir une solution rapide…\n\nLa première option est fastidieuse et source d’erreurs, et nous la déconseillons. La seconde option n’est pas mauvaise en soi : les outils mentionnés sont extrêmement puissants et de bonnes cibles d’apprentissage pour quand vous serez plus à l’aise avec le langage. Mais ils sont trop avancés pour ce petit tutoriel, et une options simple existe déjà dans {ggplot2}."
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#mise-en-place",
    "href": "sessions_extra/faceting.fr.html#mise-en-place",
    "title": "Graphiques multiples (facetting)",
    "section": "Mise en place",
    "text": "Mise en place\n\nNous utiliserons la même liste linéaire nettoyée que précédemment et qui peut être téléchargée ici :\n\n\n\n Télécharger les données\n\n\n\n Si ce n’est pas déjà fait, enregistrez le jeu de données dans data/clean puis créez un nouveau script appelé faceting.R dans votre sous-dossier R (alternativement, vous pouvez rajouter une section au script sur les courbes épis).\n Si vous créez un nouveau script, ajoutez un en-tête approprié et chargez les paquets suivants : {here}, {rio} et {tidyverse}. Importez ensuite les données propres dans R et enregistrez-les dans un objet df_linelist."
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#un-graphe-par-modalité-faceting",
    "href": "sessions_extra/faceting.fr.html#un-graphe-par-modalité-faceting",
    "title": "Graphiques multiples (facetting)",
    "section": "Un graphe par modalité (faceting)",
    "text": "Un graphe par modalité (faceting)\nDans ggplot, “faceting” est est l’action de créer des graphiques en plusieurs parties. La fonction facet_wrap() trace automatiquement un graphique pour chacune des modalités d’une variable. Par exemple, vous pouvez créer une courbe épi par sexe, ou par site. Comme les autres couches d’un ggplot, on l’ajoute à un graphique avec un +. Cela crée une figure avec plusieurs petits graphiques, les fameuses facettes.\n\nPréparer les données\nDans cette leçon, nous expliquerons le code en traçant la courbe par sous-préfecture, et vous tracerez la courbe par groupe d’âge.\nSi l’on veut tracer la courbe épidémique par sous-préfecture, il faut que cette variable soit dans le data frame que nous passons à ggplot(). Nous allons donc créer un nouveau jeu de données agrégées qui contient le nombre de patients par jour et par sous-préfecture.\n\ndf_pref &lt;- df_linelist %&gt;%\n  count(date_debut, sous_prefecture,\n        name = 'patients')\n\nhead(df_pref)\n\n  date_debut sous_prefecture patients\n1 2022-08-13        Moissala        1\n2 2022-08-17        Moissala        1\n3 2022-08-18        Moissala        1\n4 2022-08-22        Moissala        1\n5 2022-08-30        Moissala        2\n6 2022-09-01        Moissala        1\n\n\n\nVous devez tracer le nombre de patients par groupe d’âge, donc il vous faut un data frame agrégé par jour et groupe d’âge. Créez-le et enregistrez-le comme df_age. Il a le format suivant :\n\n\n  date_debut age_groupe n\n1 2022-08-13  1 - 4 ans 1\n2 2022-08-17 5 - 14 ans 1\n3 2022-08-18   &lt; 6 mois 1\n4 2022-08-22 6 - 8 mois 1\n5 2022-08-30   &lt; 6 mois 1\n6 2022-08-30 6 - 8 mois 1\n\n\n\n\n\nTracer le graphique\nMaintenant que les données sont prêtes, il ne nous reste plus qu’à tracer le graphique. Examinez le code ci-dessous, il est presque identique à ce que nous avons fait précédemment, à part la dernière ligue qui crée les facettes :\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_debut,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date d'apparition des symptomes\",\n       y = \"Cas de rougeole\",\n       title = \"Measles cases in Mandoul (Chad)\") +\n  theme_classic(base_size = 15) +\n  facet_wrap(vars(sous_prefecture))   # Graphique par sous-pref !\n\n\n\n\n\n\n\n\nJ’espère que vous êtes soufflés ! D’un point de vue syntaxe, la fonction facer_wrap() prend en argument le nom de la variable catégorique qui nous intéresse, enrobé dans la fonction vars().\n\nA votre tour. Tracez le graphe par classe d’âge. Il devrait ressembler à ça :"
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#modifier-laspect-des-facettes",
    "href": "sessions_extra/faceting.fr.html#modifier-laspect-des-facettes",
    "title": "Graphiques multiples (facetting)",
    "section": "Modifier l’aspect des facettes",
    "text": "Modifier l’aspect des facettes\nOuvrez la page d’aide de la fonction sur le site du paquet pour avoir la liste des arguments acceptés. Nous allons aborder certains d’entre eux à présent.\n\nNombre de lignes ou de colonnes\nLes arguments nrow et ncol vous permettent de décider combien de facettes il doit y avoir sur une ligne, ou sur une colonne.\nSi nous voulions avoir toutes les facettes sur deux lignes :\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_debut,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date d'apparition des symptomes\",\n       y = \"Cas de rougeole\",\n       title = \"Cas de rougeole dans la région de Mandoul (Tchad)\") + \n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sous_prefecture),\n             nrow = 2)  \n\n\n\n\n\n\n\n\nOu au contraire nous pouvons forcer le nombre de lignes à 4 pour avoir une figure tout en hauteur :\n\ndf_pref %&gt;%\n  ggplot(aes(x = date_debut,\n             y = patients)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date d'apparition des symptomes\",\n       y = \"Cas de rougeole\",\n       title = \"Cas de rougeole dans la région de Mandoul (Tchad)\") + \n  theme_classic(base_size = 15) +\n  \n  facet_wrap(vars(sous_prefecture),\n             nrow = 4)  \n\n\n\n\n\n\n\n\n\nUtilisez un des deux arguments présentés ci-dessus pour créer un graphe avec trois colonnes.\n\n\n\nPlages des axes\nAvez-vous remarqué que les valeurs minimales et maximales en x et en y étaient les mêmes pour toutes les facettes ? C’est que par défaut facet_wrap() fixe les plages pour les deux axes. Ce comportement est raisonnable pour pouvoir comparer les facettes et éviter d’induire le lecteur en erreur.\nCeci étant dit, si vous êtes plus intéressé par la forme de la courbe à l’intérieur de chaque facette que par la comparaison des catégories entre elles, il peut être approprié de zoomer sur les données disponibles en autorisant des axes indépendants (“libres” de varier). Prévenez alors le lecteur que les facettes ne sont pas toutes à la même échelle.\nL’argument scales [échelles] accepte les valeurs suivantes :\n\n\"fixed\" : la valeur par défaut, x et y à la même échelle pour toutes les facettes\n\"free_x\" : l’échelle de x peut varier entre facettes\n\"free_y\" : l’échelle de y peut varier entre facettes\n\"free\" : les deux axes peuvent varier entre facettes\n\nContrastez le graphe précédent avec celui-ci :\n\n\n\n\n\n\n\n\n\nNous avons autorisé à avoir des échelles indépendantes sur toutes les facettes en x et en y, pour zoomer sur les cas dans chaque sous-préfecture.\n\nTracez la courbe par groupe d’âge, avec l’axe des abscisses fixe et l’axe des ordonnées libre."
  },
  {
    "objectID": "sessions_extra/faceting.fr.html#cest-fini",
    "href": "sessions_extra/faceting.fr.html#cest-fini",
    "title": "Graphiques multiples (facetting)",
    "section": "C’est fini !",
    "text": "C’est fini !\nBravo, vous avez créé vos premiers graphiques en fonctions d’une variable catégorique. Cela devrait vous être très utile. Sachez que la fonction fonctionne aussi avec d’autres types de graphes créés par {ggplot2}.\nSi le graphique est très large, il est possible que les étiquettes des dates ne soient pas très lisibles en x, et c’est le cas pour certains des exemples. Cela peut être contrôlé, et le sujet est abordé dans un autre satellite !\n\n\n\n Solutions des exercices"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html",
    "href": "sessions_extra/surveillance_companion.html",
    "title": "Surveillance",
    "section": "",
    "text": "Reuse skills aquired in the FETCH-R modules (import, clean and visualize data)\nMore specifically, analyze alert data to help decide which alerts to prioritize for further field investigation."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#objectives",
    "href": "sessions_extra/surveillance_companion.html#objectives",
    "title": "Surveillance",
    "section": "",
    "text": "Reuse skills aquired in the FETCH-R modules (import, clean and visualize data)\nMore specifically, analyze alert data to help decide which alerts to prioritize for further field investigation."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#introduction",
    "href": "sessions_extra/surveillance_companion.html#introduction",
    "title": "Surveillance",
    "section": "Introduction",
    "text": "Introduction\nThis satellite is a companion to the case study Measles emergency response in the Katanga region (DRC) from the FETCH Surveillance module and may thus not make sense as a standalone document.\nFrom an R point of view, this tutorial builds on skills acquired throughout the FETCH-R modules, introduces a couple of useful generalist functions, and some more specialized ones.\n\n\n\n\n\n\nTip\n\n\n\nDo not hesitate to refer to past sessions and your own scripts to remind yourself of some functions!"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#setup-question-2",
    "href": "sessions_extra/surveillance_companion.html#setup-question-2",
    "title": "Surveillance",
    "section": "Setup (Question 2)",
    "text": "Setup (Question 2)\nSince this is part of a specific module, you will create a new RStudio project. We refer you to the main session for help creating a project and importing your data.\n\nSetup a new project\n\n\nCreate a folder surveillance_case_study associated with the FETCH Surveillance module. Add the following subfolders in it:\n\n\n📁 data\n\n📁 clean\n📁 raw\n\n📁 R\n📁 outputs\n\n\nCreate an RStudio project at the root of the surveillance_case_study folder.\nDownload the raw data.\n\n\n\n\n Download raw data\n\n\n\n 4. Unzip the archive and save the two Excel files it contains in the subfolder data/raw.  5. Create a new script called import_clean.R and save it in the R subdirectory. Add a section to load the following packages: {here}, {rio}, and {tidyverse}.\n\n\n\nImport data in R\nReminder from the case study: you requested access to the routine surveillance data and the laboratory data to the DRC MoH. The MoH agreed to share it with you on a weekly basis. The first dataset you received is of week 20 in 2022 (the data we are working on are simulated).\n\nIf you have not done it already, open the raw data files in Excel (or another equivalent application) to inspect them.\n\nThe surveillance dataset is pretty straightforward to import. The lab dataset is slightly trickier: the data headers do not start at line one. Fear not, the skip argument from the import() function is made for this situation:\n\n# DO NOT RUN (PSEUDO-CODE)\nimport(\n  here(\"data\", \"raw\", \"example_file.xlsx\"), \n  skip = 3  # Skip the first three lines and start importing from line four.\n) \n\n\n\nAdd a section to your script dedicated to data importation.\nImport the surveillance data and store it into a data_surv_raw data frame. Then, import the lab data and save it in a data_lab_raw data frame.\nVerify that the import went well for both data frames (Viewer, check the dimensions or start and tail of data frames)."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#cleaning-question-2-and-3",
    "href": "sessions_extra/surveillance_companion.html#cleaning-question-2-and-3",
    "title": "Surveillance",
    "section": "Cleaning (Question 2 and 3)",
    "text": "Cleaning (Question 2 and 3)\n\nSurveillance data (Q2)\nNow that the data is correctly imported, we are going to perform some more checks, as usual, before a bit of cleaning.\n\nQuick checks\nDuring the case study you won’t have time to inspect and clean all columns in the imparted time, so for now we will focus on key columns: health_zone, week, totalcases and totaldeaths.\n\n\n\n\n\n\nNote\n\n\n\nIf you work on this tutorial in your own time, inspect the quality of the other columns and cross-check information of several columns. We refer you to the discussion of the case study for more checks to perform.\n\n\n\nAdd a section for the exploration and cleaning of the surveillance data into your script.  Now, explore the surveillance data frame and answer the following questions:\n\nWhat are the column names?\nHow many provinces are in the dataset? Is this coherent with what you expect?\nHow many health zones are in the dataset?\nWhat is the range of weeks?\nWhat is the min of totalcaseses?\nWhat is the max of the totaldeaths?\nDo you notice missing data for these columns? Are the strings of text clean?\n\n\n\n\nClean strings\nNow that we have a better idea of what is the state of the data, let’s start cleaning. We are going to write a cleaning pipeline like we did in the main modules (check out your code for the end of the cleaning modules to see an example final pipeline).\n\n\n\n\n\n\nTip\n\n\n\nTo facilitate debugging your pipeline, add commands one by one, checking each new command before adding a new one.\n\n\nWe are going to perform a couple of actions on the columns containing text to remove potential problems:\n\ntransform them to lower casse\nremove potential extra spaces\nreplace - and spaces by _.\n\nBecause you may not have the time to do all of text colums, work on the health_zone or the province column for the following instructions.\n\nStart a cleaning pipeline with a mutate() that turns the chosen column to lower casse.\n\nNow, we are going to introduce two handy functions for more text cleaning. The first one is the str_squish() function from the {stringr} package (help page here), that removes spaces at the start or end of the strings, and replace multiple spaces in the middle of a string by a single space.\n\nexamples &lt;- c(\" Trailing spaces     \",\n              \"Multiple     spaces\",\n              \" Everything     here \")\n\nstr_squish(examples)\n\n[1] \"Trailing spaces\" \"Multiple spaces\" \"Everything here\"\n\n\nThe other function, str_replace (also from the {stringr} package) does what you expect from its name: replace something in a string by something else. It has a pattern argument that take the bit of text to be replaced, and a replacement arguments that takes the bit of text to use as replacement:\n\nstr_replace(\n  \"HAUT-KATANGA\",    # A string of text (or a column, if used in a mutate)\n  pattern = \"-\",     # The bit to replace\n  replacement = \"_\"  # The replacement\n)\n\n[1] \"HAUT_KATANGA\"\n\n\n\nAdd steps to your mutate to:\n\nRemove all unwanted spaces from your chosen column\nChange the - and to _ in the column (in two steps)\n\nThe head of these columns should now be:\n\n\n  country     province    health_zone disease\n1     drc haut_katanga mufunga_sampwe measles\n2     drc haut_katanga        sakania measles\n3     drc haut_katanga        mitwaba measles\n4     drc haut_katanga kilela_balanda measles\n5     drc haut_katanga         likasi measles\n6     drc haut_katanga         kikula measles\n\n\nStore the result data frame in a data_surv object.\n\n\n\nSave the clean data\n\nUse the {rio} package to export data_surv to a .rds file called data_ids_2022-w20_clean in the data/clean subfolder of your project.\n\n\n\n\nLaboratory data (Q2)\nWe are going to follow the same steps as before for the lab data, and focus for now on the columns health_zone, igm_measles and igm_rubella.\n\nQuick checks\n\nPerform data checks on the colums names and dimensions. What are the categories for igm_measles and igm_rubella? What do you need to do to clean these columns?\n\n\n\nClean and recode strings\n\n\nStart a new cleaning pipeline to clean the lab data. As before, for one of the text column, change it to lower casse, remove the extra spaces and replace the or - by _.\nRecode at least one of igm_measles or igm_rubella columns so that the categories are negatif, positif and indetermine.\nStore the cleaner version in a data_lab data frame\n\nThe head of the cleaned columns should now be:\n\n\n   health_zone igm_measles igm_rubella\n1      kambove    negative    negative\n2      kambove    negative    negative\n3      kambove    negative    positive\n4      kambove    negative    negative\n5      kambove    negative    positive\n6      kambove    negative    negative\n7      kambove    negative    negative\n8      kambove    negative    positive\n9       manika    negative    negative\n10   kamalondo    negative    negative\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can use the case_when() function to recode the IGM columns.\n\n\n\n\n\nSave the clean data\n\nExport the data_lab data frame to a .rds file called data_lab_2022-w20_clean in the data/clean subfolder of your project.\n\n\n\n\nGoing further\nThis is the end of the steps for question 2! If you finished in advance and there is still time, reuse the functions we just saw to clean the other text columns in both datasets and recode both IGM column in the lab dataset.\nIf you still have time, perform more checks on the data:\n\nDisplay the health zone for which the numbers by age group add up to a different number than the total (if any)\nAre there any health zone for which the number of deaths is higher than the total number of cases?\nAre there duplicated lines (fully duplicated, or several values for health zone and week)?\nAre there unrealistic case numbers?\n\n\n\nComplete surveillance dataset (Q3)\nDuring the case study and the data checks, you realized that some weeks are missing from the surveillance dataset. You discussed the possible reasons for it, and the associated problems. Here we are going provinceide code to create a dataset that contains all weeks (assuming that missing weeks had zero cases and deaths).\nWe will use the function complete() from the {tidyr} package to add the missing lines and fill the columns containing numbers (totalcases and totaldeaths) with zeros.\nLook at the simplified example below: the Kikula health zone has no row for week 2:\n\n# Create simplified data frame for the example, with three weeks\nexample_df = data.frame(\n  province    = rep(\"haut_katanga\", 5),\n  health_zone = c(\"likasi\", \"likasi\", \"likasi\", \"kikula\", \"kikula\"),\n  week        = c(1, 2, 3, 1, 3),\n  totalcases  = c(2, 1, 3, 1, 2))\n\nexample_df\n\n      province health_zone week totalcases\n1 haut_katanga      likasi    1          2\n2 haut_katanga      likasi    2          1\n3 haut_katanga      likasi    3          3\n4 haut_katanga      kikula    1          1\n5 haut_katanga      kikula    3          2\n\n\nWe use the following code to cross province and health zone and make sure that all their combinations have all the possible week values. Since the weeks range from one to three in that toy example, we pass a vector with weeks ranging from one to three\n\n# Complete the missing week in kikula\nexample_df |&gt; \n  complete(\n    nesting(province, health_zone),\n    week = seq(1, 3),  # vector from 1 to 3\n    fill = list(totalcases = 0)\n  ) \n\n# A tibble: 6 × 4\n  province     health_zone  week totalcases\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 haut_katanga kikula          1          1\n2 haut_katanga kikula          2          0\n3 haut_katanga kikula          3          2\n4 haut_katanga likasi          1          2\n5 haut_katanga likasi          2          1\n6 haut_katanga likasi          3          3\n\n\nNow both health zones within provinces have values for all three weeks.\nIt would be good to automatically pick the week series, since the data frame is going to change every week. To do that, we can remplace hardcoded values by the smallest and largest week number in the week column to get the range of weeks in the dataset:\n\n# Complete the missing week in kikula\nexample_df |&gt; \n  complete(\n    nesting(province, health_zone),\n    week = seq(min(week, na.rm = TRUE),   # vector ranging from smallest to largest week numbers in dataset\n                 max(week, na.rm = TRUE)),\n    fill = list(totalcases = 0)\n  ) \n\n# A tibble: 6 × 4\n  province     health_zone  week totalcases\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 haut_katanga kikula          1          1\n2 haut_katanga kikula          2          0\n3 haut_katanga kikula          3          2\n4 haut_katanga likasi          1          2\n5 haut_katanga likasi          2          1\n6 haut_katanga likasi          3          3\n\n\n\n\nStart a new pipeline that takes the data_surv data frame and keeps only the columns province, health_zone, week and total cas.\nAdd a new step to your pipeline and paste the following code to complete the data frame:\n\n\ncomplete(\n  nesting(province, health_zone),\n  week = seq(min(week, na.rm = TRUE), \n               max(week, na.rm = TRUE)),\n  fill = list(totalcases   = 0, \n              totaldeaths = 0 # also add zero to the totaldeaths column\n  )\n) \n\n\nStore the result of the pipeline in a data frame called data_surv_weeks. The head of that data frame looks like:\n\n\n\n# A tibble: 10 × 5\n   province     health_zone  week totalcases totaldeaths\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n 1 haut_katanga kafubu          1          0           0\n 2 haut_katanga kafubu          2          0           0\n 3 haut_katanga kafubu          3          0           0\n 4 haut_katanga kafubu          4          0           0\n 5 haut_katanga kafubu          5          0           0\n 6 haut_katanga kafubu          6          0           0\n 7 haut_katanga kafubu          7          0           0\n 8 haut_katanga kafubu          8          0           0\n 9 haut_katanga kafubu          9          0           0\n10 haut_katanga kafubu         10          0           0\n\n\n\nWhen you are done, export that data frame to a .rds file called data_ids_2022-w20__weeks_clean in the data/clean subfolder of your project.\n\n\n\n\nGoing further\nThis is the end of question 3; if you are finished in advance, do not hesitate to carry on checking the data and listing potential problems and cleaning the columns."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#defining-alerts-question-4",
    "href": "sessions_extra/surveillance_companion.html#defining-alerts-question-4",
    "title": "Surveillance",
    "section": "Defining alerts (Question 4)",
    "text": "Defining alerts (Question 4)\n\nPreparing the dataset\nWe are going to carry on preparing the datasets for the analyses.\n\nIf you have not had the time to clean both health zone and province in both datasets, as well as both igm columns in the lab dataset you can import cleaner versions of the data:\n\n\n\n Download clean data\n\n\n\n Unzip the archive in your data/clean subfolder and import the .rds files in your RStudio project using rio::import() as usual. Assign the cleaned data frames to data_surv, data_lab and data_surv_weeks and carry on.\n\n\nSubset health zone\nTo simplify the work, we are going to focus on four health zones: Dilolo, Kampemba, Kowe, and Lwamba.\n\nStart a new pipeline from data_surv_weeks. Its first step it to only retain data for the the Dilolo, Kampemba, Kowe, and Lwamba health zones.\n\n\n\nWeekly indicator\nThe first indicator we want to caclulate is whether a health zone has 20 or more suspected cases in one week. This indicator is binary and only considers data in a given health zone and week, which corresponds to individual rows of our data frame.\n\nAdd a mutate() to your pipeline, to create a cases20 column that contains 1 if a given health zone has 20 cases or more in that week, and 0 otherwise.\n The top of the data frame created by the pipe thus far looks like this:\n\n\n# A tibble: 10 × 6\n   province     health_zone  week totalcases totaldeaths cases20\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n 1 haut_katanga kampemba        1         75           0       1\n 2 haut_katanga kampemba        2         42           0       1\n 3 haut_katanga kampemba        3         46           0       1\n 4 haut_katanga kampemba        4         50           0       1\n 5 haut_katanga kampemba        5         43           0       1\n 6 haut_katanga kampemba        6         33           0       1\n 7 haut_katanga kampemba        7         45           0       1\n 8 haut_katanga kampemba        8         52           0       1\n 9 haut_katanga kampemba        9         38           0       1\n10 haut_katanga kampemba       10         46           0       1\n\n\n\n\n\nCumulative indicator\nThe second indicator you want to calculate is whether a health zone has more than 35 cumulated suspected cases within three weeks. This is a bit more complicated than the previous case: within heath zone you need to calculate the sum of cases by groups of three weeks, but the groups are not fixed, they are rolling across time. We are getting in the teritory of moving averages/sums/etc.\n\nCumulative sum\nWe are going to use the rollapply() function from the {zoo} package, as it is versatile and powerful. As its name suggests, the rollapply() function applies a function in a rolling way to a vector or a column of a data frame.\nSince we are constrained in time, we are going to provinceide the code of the rollapply() function to calculate the cumulative sum over three weeks, but check out the details in the Going further section when you have time.\nThis is how to do it for one health zone:\n\n# Create mini example data frame\nexample_df = data.frame(\n  province    = \"Haut Katanga\",\n  health_zone = \"Dilolo\",\n  week        = 1:10,\n  totalcases  = rep(1, times = 10))\n\nexample_df \n\n       province health_zone week totalcases\n1  Haut Katanga      Dilolo    1          1\n2  Haut Katanga      Dilolo    2          1\n3  Haut Katanga      Dilolo    3          1\n4  Haut Katanga      Dilolo    4          1\n5  Haut Katanga      Dilolo    5          1\n6  Haut Katanga      Dilolo    6          1\n7  Haut Katanga      Dilolo    7          1\n8  Haut Katanga      Dilolo    8          1\n9  Haut Katanga      Dilolo    9          1\n10 Haut Katanga      Dilolo   10          1\n\nexample_df |&gt; \n  mutate(cumcas = rollapply(\n    data  = totalcases, # The column to work on\n    width = 3,          # Width of the window  \n    FUN   = sum,        # Function to apply, here the sum   \n    align = \"right\",    # Windows are aligned to the right\n    partial = TRUE,     # Allows calcul to be made even if window is less than three\n    na.rm = TRUE        # Extra unamed argument to be passed to the sum function\n  )\n  )\n\n       province health_zone week totalcases cumcas\n1  Haut Katanga      Dilolo    1          1      1\n2  Haut Katanga      Dilolo    2          1      2\n3  Haut Katanga      Dilolo    3          1      3\n4  Haut Katanga      Dilolo    4          1      3\n5  Haut Katanga      Dilolo    5          1      3\n6  Haut Katanga      Dilolo    6          1      3\n7  Haut Katanga      Dilolo    7          1      3\n8  Haut Katanga      Dilolo    8          1      3\n9  Haut Katanga      Dilolo    9          1      3\n10 Haut Katanga      Dilolo   10          1      3\n\n\n\n\nBy health zone\nNow, we want to do this cumulative sum by health zone. This is not that complicated: we are going to sort our data frame properly by health zone and week, and use the .by argument to tell the mutate() function to perform the action by health zone.\n\n\n\n\n\n\nNote\n\n\n\nYou may remember from the aggregation session how we summarized by groups using the .by argument in the summarize() function. This is exactly the same idea, except that instead of returning one value by group (as summarize() does), we want to return one value per row (as mutate() does).\nAs a little reminder of how summarize() + .by work, here is how we would calculate the total number of patients and deceased by province over the whole dataset:\n\ndata_surv_weeks |&gt; \n  summarize(\n    .by = province,  # Do things by province\n    cases_tot = sum(totalcases, na.rm = TRUE),\n    dead_tot  = sum(totaldeaths, na.rm = TRUE)\n  )\n\n# A tibble: 4 × 3\n  province     cases_tot dead_tot\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n1 haut_katanga      5948       34\n2 haut_lomami       6928       70\n3 lualaba           1485        3\n4 tanganyika        7836      137\n\n\n\n\n\n\nAdd a step to your previous pipeline to sort the data frame by province, health zone and week with the arrange() function.\nThen add the following code to calculate the cumulative sum:\n\n\nmutate(\n  .by = c(province, health_zone),\n  cumcas = rollapply(\n    data  = totalcases,\n    width = 3,          # Width of the window  \n    FUN   = sum,        # Function to apply, here the sum   \n    align = \"right\",    # Windows are aligned to the right\n    partial = TRUE,     # Allows calcul to be made even if window is less than three\n    na.rm = TRUE        # Extra unamed argument to be passed to the sum function\n  )\n)\n\n\nNow that the complicated part is over (the calcul of the cumulative sum) we are left to summarize the information with a binary indicator, for heach week and health zone. Then we can create a second indicator, that aggregates the result of both the weekly and cumulative indicators, to say if an alert is to be raised.\n\n\nAdd a new step to your pipeline to calculate a binary indicator, cumcases35 that is 1 if the cumulative sum of cases for that week is equal or above 35 and 0 if not.\nAdd a new column alert, that is 1 if either the cases20 indicator or the cumcases35 indicator is 1 and 0 otherwise. You can use the | operator, which is R logical OR.\nWhen the pipe is working, assign the result to a data_alert data frame.\n\ndata_alert should look like this:\n\n\n# A tibble: 10 × 9\n   province   health_zone  week totalcases totaldeaths cases20 cumcas cumcases35\n   &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 haut_kata… kampemba        1         75           0       1     75          1\n 2 haut_kata… kampemba        2         42           0       1    117          1\n 3 haut_kata… kampemba        3         46           0       1    163          1\n 4 haut_kata… kampemba        4         50           0       1    138          1\n 5 haut_kata… kampemba        5         43           0       1    139          1\n 6 haut_kata… kampemba        6         33           0       1    126          1\n 7 haut_kata… kampemba        7         45           0       1    121          1\n 8 haut_kata… kampemba        8         52           0       1    130          1\n 9 haut_kata… kampemba        9         38           0       1    135          1\n10 haut_kata… kampemba       10         46           0       1    136          1\n# ℹ 1 more variable: alert &lt;dbl&gt;\n\n\n\n\n\n\n\nHealth zones in alert\nAfter all this work we can finally investigate which health zones are in alert in the last week of our dataset (the now of the case study, week 20)!\n\nFilter your data frame to only keep the 20th week. Which health zones are in alert?\nCreate a vector hz_alert that contains the name of the health zones in alert, so that we can use it to filter data from these health zones later."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#draw-the-epicurve-question-5",
    "href": "sessions_extra/surveillance_companion.html#draw-the-epicurve-question-5",
    "title": "Surveillance",
    "section": "Draw the epicurve (Question 5)",
    "text": "Draw the epicurve (Question 5)\nLet us draw the epicurves of health zones currently in alert (in alert during week 20).\nWe have drawn very similar curves in the epicurve session. Here again we will use the ggplot() function with the geom_col() geom to create a barplot showing the distribution of cases. Since we already have the number of cases per week we do not need to count it ourselved like we did in the past.\n\nDraw an epicurve for one of the health zone in alert.\n The graph should look like this (but maybe for another health zone):\n\n\n\n\n\n\n\n\n\n\nThe facet_wrap() function allows us to plot several subplots in the same graph (see the faceting satellite for more information on faceting):\n\ndata_alert |&gt;\n  filter(health_zone %in% hz_alert) |&gt;\n  ggplot(aes(x = week, \n             y = totalcases)) + \n  geom_col(fill = \"#2E4573\") + \n  theme_bw(base_size = 15) + \n  labs(x = \"Week\",\n       y = \"N cases\",\n       title = \"Health zones in alert\") +\n  facet_wrap(vars(health_zone))   # One graph by health_zone"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#key-indicators-question-6",
    "href": "sessions_extra/surveillance_companion.html#key-indicators-question-6",
    "title": "Surveillance",
    "section": "Key indicators (Question 6)",
    "text": "Key indicators (Question 6)\nLet’s gather more data on both alerts to help you decide which one to investigate.\n\n\n\n\n\n\nTip\n\n\n\nThis session builds on summarizing skills seen in the summary session. Do not hesitate to check it or your code if you forgot something.\n\n\n\nWeek of the first alert\n\nUse the summarize() function to display the first week the alert was raised for each health zone in alert. Which health zone started first?\n\n\n\nSurveillance data indicators\nLet us go back to the full surveillance dataset that contains more columns of interest.\n\n\nAdd a column cunder_5 to data_surv that contains the the number of cases less than five months.\nDerive, for each health zone in alert, the following indicators (organized in a single table):\n\n\nThe number of cases\nThe number of deaths\nThe number of less than five year olds\nThe CFR in percentage\nThe percentage of reported cases under five\n\nThe result should look like this:\n\n\n  health_zone n_cases n_deaths n_under_5 p_under_5       cfr\n1    kampemba     730        0       544 0.7452055 0.0000000\n2      lwamba     256        2       233 0.9101562 0.0078125\n\n\n\n\n\nLab data indicators\nNow we are going to use the laboratory data to derive a couple more indicators.\n\nFor each health zone in alert, derive the following indicators within one table:\n\nThe number of patients tested for measles\nThe number of positives for measles\nThe percentage of positives for measles\nThe number of patient tested for rubeole\nThe number of positive for rubeole\nThe percentage of positive for rubeole\n\nThe result should look like this:\n\n\n  health_zone n_test_meas n_test_meas_pos positivity_measles n_test_rub\n1      lwamba          10               5          0.5000000         10\n2    kampemba          14               4          0.2857143         14\n  n_test_rub_pos positivity_rubella\n1              0         0.00000000\n2              1         0.07142857\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCheck out the section on summaries with conditions to remind you of the more advanced summaries."
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#done",
    "href": "sessions_extra/surveillance_companion.html#done",
    "title": "Surveillance",
    "section": "Done!",
    "text": "Done!\nCongratulation, you are done!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_extra/surveillance_companion.html#sec-going-further",
    "href": "sessions_extra/surveillance_companion.html#sec-going-further",
    "title": "Surveillance",
    "section": "Going Further",
    "text": "Going Further\n\nExploring the rollaply() function\nIf we want to do a cumulative sum of cases over three weeks, we want to apply the sum() function over windows of three weeks.\n\nexample_vect &lt;- rep(1, time = 10)\nexample_vect\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\nrollapply(\n  data  = example_vect,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\"  # The final windows is aligned to the right\n)\n\n[1] 3 3 3 3 3 3 3 3\n\n\nWe inputed a vector of ten values and obtained a vector of lenght height, containing the sums. Obviously the function has a way of dealing with the extremities, and the size of the output is smaller than the size of the input. This would be a problem in a mutate() that creates new columns in a data frame, that need to be the same length as the existing columns.\nYou can control the behavior at the extremities:\n\nFill with NA when there is not enough values to calculate a window of three\nAllow partial sums (some values represent less than three weeks)\n\nThe argument fill = NA pads the extremities with NA (on the left in our case, since we aligned right):\n\nrollapply(\n  data  = example_vect,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  fill  = NA\n)\n\n [1] NA NA  3  3  3  3  3  3  3  3\n\n\nIt is a reasonnable way of dealing with incomplete windows. In our case however, we can do better: if there were 40 cases in week 1 it would be a cause for alert! We thus want the cumulative sum to be calculated from week one to be able to detect early alerts (keeping in mind that a lack of alert in the first two weeks may be a result of incomplete data). The partial = TRUE argument allows this:\n\nrollapply(\n  data    = example_vect,\n  width   = 3,       # Width of the window  \n  FUN     = sum,     # Function to apply, here the sum   \n  align   = \"right\", # Windows are aligned to the right\n  partial = TRUE)\n\n [1] 1 2 3 3 3 3 3 3 3 3\n\n\nThis is close to what we need.\nA last point: you may remember that arithmetic operations in R return NA if some of the values are NA and we usually need to pass the argument na.rm = TRUE to the functions for them to ignore missing values.\nIf we had a slightly less complete vector we would have a problem:\n\nexample_vect_missing &lt;- c(1, 1, 1, NA, 1, 1)\n\nrollapply(\n  data  = example_vect_missing,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  partial = TRUE   # Allows calcul to be made even if window is less than three\n)\n\n[1]  1  2  3 NA NA NA\n\n\nFortunately we can pass the na.rm = TRUE argument to rollapply() so that it passes it to sum().\n\nrollapply(\n  data  = example_vect_missing,\n  width = 3,       # Width of the window  \n  FUN   = sum,     # Function to apply, here the sum   \n  align = \"right\", # Windows are aligned to the right\n  partial = TRUE,  # Allows calcul to be made even if window is less than three\n  na.rm = TRUE     # Extra unamed argument to be passed to the sum function\n)\n\n[1] 1 2 3 2 2 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nHere we applied the sum() function to create a cumulative sum over 3 weeks. But you could, with minimal modifications, apply the mean() function to caclulate a moving average!\n\n\n\n\nPretifying percentages\nThe percent function from the {scales} packages can add percentage formatting to a value.\n\nscales::percent(0.8556)\n\nIt takes an accuracy arguments that controls the number of decimals:\n\nscales::percent(0.8556,\n                accuracy = 0.1)\n\nYou can wrap it around the values that you calulate in the summary tables to change the proportions into nicely formatted percentages. Note that once you are done the column is treated as text (since we added a % sign) and you will not be able to do further arithmetical operations on it."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html",
    "href": "sessions_extra/weekly_epicurves.html",
    "title": "Weekly Epicurves",
    "section": "",
    "text": "In the epicurve session you learned how to plot an epicurve of the number of cases per day:\n\n\n\n\n\n\n\n\n\nThis graph is aggregated by day, which is a reasonable level of aggregation if the outbreak is short or if you wish to zoom on a short period. As epidemiologists we however often want to plot data by week.\nIn this tutorial we will learn two ways of aggregating data by week, plot the data and tweak the date labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#objectives",
    "href": "sessions_extra/weekly_epicurves.html#objectives",
    "title": "Weekly Epicurves",
    "section": "",
    "text": "In the epicurve session you learned how to plot an epicurve of the number of cases per day:\n\n\n\n\n\n\n\n\n\nThis graph is aggregated by day, which is a reasonable level of aggregation if the outbreak is short or if you wish to zoom on a short period. As epidemiologists we however often want to plot data by week.\nIn this tutorial we will learn two ways of aggregating data by week, plot the data and tweak the date labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#setup",
    "href": "sessions_extra/weekly_epicurves.html#setup",
    "title": "Weekly Epicurves",
    "section": "Setup",
    "text": "Setup\nWe will build on code from the epicurve session so you may either write your code in the script associated with that session or create a new script.\n\nCreate a new script for this tutorial or open the script from the epicurve lesson.\n Make sure the following packages are installed and loaded:\n\n{here} to write robust absolute paths,\n{rio} to import the data,\n{dplyr} to manipulate data,\n{ggplot2} to create the graphs,\n{lubridate} to manage dates and times\n{scales} to create prettier labels\n\nIf it is not already done, import the clean data (moissala_linelist_clean_EN.rds) into a df_linelist data frame and create a new section in your script called PREPARE DATA.\n\nAs we did in the core session, the examples in this lesson will be shown for outcomes and you will code the classic epicurve for date of onset in the exercises."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#aggregate-data-by-week",
    "href": "sessions_extra/weekly_epicurves.html#aggregate-data-by-week",
    "title": "Weekly Epicurves",
    "section": "Aggregate Data by Week",
    "text": "Aggregate Data by Week\nWe will to discuss two ways of aggregating data by weeks. You may be more familiar with the first one (using week numbers to identify weeks), but we will to focus more heavily on a more robust way (using the firs day of the week to identify weeks).\n\nUsing Week Numbers\nProbably the most intuitive way of thinking of weekly aggregated data is to think in terms of week numbers, as aggregated data from MoH are often in this format, and you probably created a lot of epicurves with week numbers yourselves.\nTheisoweek() from the {lubridate} packages takes a date (or a vector of dates) and returns the associated ISO week.\n\nexample_date &lt;- as.Date('2025-02-24')\n\nexample_date\n\n[1] \"2025-02-24\"\n\nisoweek(example_date)\n\n[1] 9\n\n\nWe can use this function to create a week_outcome_number in our data frame:\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(week_outcome_number = isoweek(date_outcome))\n\nThe head of the date_outcome and week_outcome_number columns looks like this:\n\n\n  date_outcome week_outcome_number\n1   2022-08-18                  33\n2   2022-08-28                  34\n3   2022-09-03                  35\n4   2022-09-12                  37\n5   2022-09-10                  36\n6   2022-09-18                  37\n\n\n\nYour turn. Use the mutate() and isoweek() functions to create a new column in your data frame called week_onset_number that contains the ISO week associated with every onset date. The head of date_onset and week_onset_number columns should look like this:\n\n\n  date_onset week_onset_number\n1 2022-08-13                32\n2 2022-08-18                33\n3 2022-08-17                33\n4 2022-08-22                34\n5 2022-08-30                35\n6 2022-08-30                35\n\n\n\nNow, you could use this column to aggregate data by week using count() and then plot the weekly aggregated data using {ggplot2} with a code very similar to what we saw in the core epicurve session.\nThere is a problem, though. With isoweek() there is a first week in 2022, but also in 2023, 2024 and so on. With a short outbreak that would be only in 2022, this would be fine. However, our data frame gathers data at the whole region scale, and the dates range from 2022 to 2023. So if we were to just count the number of patients by week number, this table would be wrong:\n\n# WRONG\ndf_linelist |&gt; \n  count(week_onset_number) |&gt; \n  head(10)\n\n   week_onset_number  n\n1                  1 36\n2                  2 35\n3                  3 42\n4                  4 56\n5                  5 70\n6                  6 78\n7                  7 85\n8                  8 49\n9                  9 62\n10                10 81\n\n\nInstead, we could count by week stratified by years:\n\ndf_linelist |&gt; \n  mutate(year_onset = isoyear(date_onset)) |&gt; \n  count(year_onset, week_onset_number) |&gt; \n  head(10)\n\n   year_onset week_onset_number  n\n1        2022                32  1\n2        2022                33  2\n3        2022                34  1\n4        2022                35  8\n5        2022                36  8\n6        2022                37 10\n7        2022                38 17\n8        2022                39 17\n9        2022                40 19\n10       2022                41 16\n\n\nThese counts are perfectly correct. You could plot them using faceting by year, or just filter a given year and plot the weekly numbers with the ISO week number on the x-axis. For example:\n\ndf_linelist |&gt; \n  mutate(year_onset = isoyear(date_onset)) |&gt; \n  count(year_onset, week_onset_number) |&gt; \n  ggplot(aes(x = week_onset_number,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  theme_classic(base_size = 16) +\n  facet_wrap(vars(year_onset),  # Magic to make subplots very easily\n             ncol = 1)\n\n\n\n\n\n\n\n\nIf you have not read about facetting yet, do no worry, think of this plot as a teaser of how easily you can make subplots by a variable! But this is out of the scope of this tutorial. Instead, we will show you another way of aggregating data by week which is robust to multi-year data.\n\n\nUsing the First Day of the Week\nAn alternative way of aggregating by week is to use the function floor_date() (also from the {lubridate} package), which returns the first date of a given period. You can think of it as a sort of rounding to the smallest value, but for dates.\nThe function has a unit argument that allows you to choose the period of interest (week, month…) and a week_start argument where you can pass the first day of the week (Mondays are 1).\n\ndf_linelist &lt;- df_linelist |&gt; \n  mutate(\n    week_outcome_monday = floor_date(date_outcome,\n                                     unit = \"week\",\n                                     week_start = 1)\n  )\n\nLet’s look at all these different time variables to figure out what’s happening:\n\ndf_linelist |&gt; \n  select(id, date_outcome, week_outcome_number, week_outcome_monday) |&gt;\n  arrange(date_outcome) |&gt;     # Sort the data by date\n  head(n = 10)\n\n   id date_outcome week_outcome_number week_outcome_monday\n1   1   2022-08-18                  33          2022-08-15\n2   2   2022-08-28                  34          2022-08-22\n3  10   2022-09-03                  35          2022-08-29\n4  16   2022-09-10                  36          2022-09-05\n5  22   2022-09-12                  37          2022-09-12\n6  14   2022-09-12                  37          2022-09-12\n7  41   2022-09-16                  37          2022-09-12\n8  20   2022-09-17                  37          2022-09-12\n9  17   2022-09-18                  37          2022-09-12\n10 23   2022-09-19                  38          2022-09-19\n\n\nIt might be easier to visualize if we calculate the day of the week associated with each date using the function wday() (which also belong to the {lubridate} package, are you maybe seeing a pattern here 😉):\n\ndf_linelist |&gt; \n  # Get the name of the day for several date variables, to understand a bit better\n  mutate(\n    day_outcome = wday(date_outcome, \n                       label = TRUE, \n                       abbr = FALSE),\n    they_are_mondays   = wday(week_outcome_monday, \n                           label = TRUE, \n                           abbr = FALSE)) |&gt; \n  arrange(date_outcome) |&gt;     # Sort the data by date\n  select(date_outcome,\n         day_outcome,\n         week_outcome_number,\n         week_outcome_monday,\n         they_are_mondays) |&gt; \n  head(n = 10)\n\n   date_outcome day_outcome week_outcome_number week_outcome_monday\n1    2022-08-18       jeudi                  33          2022-08-15\n2    2022-08-28    dimanche                  34          2022-08-22\n3    2022-09-03      samedi                  35          2022-08-29\n4    2022-09-10      samedi                  36          2022-09-05\n5    2022-09-12       lundi                  37          2022-09-12\n6    2022-09-12       lundi                  37          2022-09-12\n7    2022-09-16    vendredi                  37          2022-09-12\n8    2022-09-17      samedi                  37          2022-09-12\n9    2022-09-18    dimanche                  37          2022-09-12\n10   2022-09-19       lundi                  38          2022-09-19\n   they_are_mondays\n1             lundi\n2             lundi\n3             lundi\n4             lundi\n5             lundi\n6             lundi\n7             lundi\n8             lundi\n9             lundi\n10            lundi\n\n\nThis illustrates how week_outcome_number and week_outcome_monday are two ways to have only one value representing a week. While week numbers are not unique as discussed before, dates are!\n\nAdd a new command to your mutate() call and create the variable week_onset_monday that contains the first day of the week for patient date of onset. Choose your argument as if the first day of the week is a Monday.\n\n\n\n\n\n\n\nTip\n\n\n\nGo read the help page for floor_date() to check out the list of possible units.\n\n\n\n\nActually Count Things\nNow that we have variables that represent week, it’s time to do the actual aggregation, ie count things!\n\nCount the number of patients per week of of onset, using the week start (week_onset_monday).\nHere are the first ten lines of what it should look like:\n\n\n   week_onset_monday  n\n1         2022-08-08  1\n2         2022-08-15  2\n3         2022-08-22  1\n4         2022-08-29  8\n5         2022-09-05  8\n6         2022-09-12 10\n7         2022-09-19 17\n8         2022-09-26 17\n9         2022-10-03 19\n10        2022-10-10 16"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#draw-the-epicurve",
    "href": "sessions_extra/weekly_epicurves.html#draw-the-epicurve",
    "title": "Weekly Epicurves",
    "section": "Draw the Epicurve",
    "text": "Draw the Epicurve\nSo far so good, now we can pipe that aggregated data frame into our plot commands, making a couple adjustments to make it work.\n\nCreate a ggplot with the same look at the epicurve from the epicurve core session, but with the first day of the week on the x-axis. Don’t forget to update axes names.\n\nIt should look like that:\n\n\n\n\n\n\n\n\n\nWe see dates on the x-axis, but a bar represent data for a week starting on Monday."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#improve-the-axis",
    "href": "sessions_extra/weekly_epicurves.html#improve-the-axis",
    "title": "Weekly Epicurves",
    "section": "Improve the Axis",
    "text": "Improve the Axis\nNow, let’s learn how to tweak the appearance of that date axis!\n{ggplot2} automatically provided labels for the x-axis, trying to adjust for the range of data. That default may not always please us so we may want to manually force the labels to be more or less frequent, or change their format.\nTo modify the appearance of the axis, we will use another {ggplot2} function, from the scale family: scale_x_date().\n\nModify Breaks\nThe breaks controls the frequency of ticks on the axis.\nThe scale_x_date() function has a date_breaks argument that accepts the interval between two labels in a string. The string can have the following format: \"1 week\", \"2 weeks\", \"4 months\", \"2 years\" etc.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles cases\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(date_breaks = \"4 months\") +  # Define breaks\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nYour turn! Modify your code so that the x-axis displays labels at reasonable intervals on your screen.\n\n\n\nImprove Labels\nNow that we changed the interval between ticks, let’s improve the labels themselves (the way dates are displayed on the axis). By default the labels are in the form year-month-day. We are going to show you two ways to change that.\n\nWith the {scales} Package.With the strptime Syntax\n\n\nThe scale_x_date() function has a label argument, that accepts several entries, among which a vector containing the dates, but also a function that generates labels from the breaks. The {scales} package provides such a function, label_date_short(), that attempts to create efficient and short labels for dates.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles outcomes\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(date_breaks = \"2 months\",\n               labels = scales::label_date_short()) + # Short labels\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModify your code and use label_date_short() to generate labels.\n\n\n\nIf you prefer to have full control on how to format dates, R has a syntax to describe date and time formats. There is a long help page with all the syntax items accessible with the help(strptime) command, but here are a few of the most useful elements to format a date label:\nDay:\n\n%d: from 01 to 31\n%e: from 1 to 31\n\nMonth:\n\n%b: abbreviated month name (current locale on your computer)\n%B: full month name (current locale on your computer)\n%m: month as a decimal number\n\nYear:\n\n%y: Year without the century (two digits)\n%Y: year in four digits\n\nSpecial separators:\n\n%n: newline\n%t: tab\n\nYou can assemble these items in a string, that you pass to different functions that accept a format as argument. Here we will pass it to the format() function to quickly see what display it creates, but after that we will use them in our graph command.\n\n# Create a date vector to explore different formats\nsome_dates &lt;- as.Date(c(\"2024-10-06\", \"2024-12-15\", \"2025-01-20\"))\n\n# Let's try out different syntax\nformat(some_dates, \"%Y-%b-%d\")\n\n[1] \"2024-oct.-06\"  \"2024-déc.-15\"  \"2025-janv.-20\"\n\nformat(some_dates, \"%Y-%b\")\n\n[1] \"2024-oct.\"  \"2024-déc.\"  \"2025-janv.\"\n\nformat(some_dates, \"%Y %B %d\")\n\n[1] \"2024 octobre 06\"  \"2024 décembre 15\" \"2025 janvier 20\" \n\nformat(some_dates, \"%y/%m/%d\")\n\n[1] \"24/10/06\" \"24/12/15\" \"25/01/20\"\n\nformat(some_dates, \"%d/%m/%Y\")\n\n[1] \"06/10/2024\" \"15/12/2024\" \"20/01/2025\"\n\n\nBack to the graph! The scale_x_date() function has an argument date_labels that accepts a string of text in the above format for the date labels.\n\ndf_linelist |&gt; \n  count(week_outcome_monday) |&gt; \n  ggplot(aes(x = week_outcome_monday,\n             y = n)) +\n  geom_col(fill = \"#2E4573\") +\n  labs(x = \"Date of outcome\",\n       y = \"Measles cases\",\n       title = \"Measles outcomes in Mandoul region (Chad)\") +\n  scale_x_date(\n    date_breaks = \"2 months\",      # Define intervals betw. labels\n    date_labels = \"%Y%n%b%n%d\") +  # Define format of labels\n  theme_classic(base_size = 16)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\nModify the code of your graph to have labels look like this:"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#done",
    "href": "sessions_extra/weekly_epicurves.html#done",
    "title": "Weekly Epicurves",
    "section": "Done!",
    "text": "Done!\nCongratulations! Dates are complicated, and their formatting is often scary, but we hope this little introduction showed you some nice tricks for your epicurves!\n\n\n\n Solution File"
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#going-further",
    "href": "sessions_extra/weekly_epicurves.html#going-further",
    "title": "Weekly Epicurves",
    "section": "Going Further",
    "text": "Going Further\n\nExtra execices\n\nUse date format like this: “2024-oct.”, “2024-dec.”\nCreate an epicurve with the date of consultation, using the first day of the week on the x-axis (format dates the way you prefer)\nCreate an epicurve for 2023 data using the date of hospital admission and the ISO week number on the x-axis.\n\n\n\nChallenge\n\nDo the epicurve for the date of onset, but instead of aggregating by week, aggregate it by month. Find an appropriate format for the labels."
  },
  {
    "objectID": "sessions_extra/weekly_epicurves.html#resources",
    "href": "sessions_extra/weekly_epicurves.html#resources",
    "title": "Weekly Epicurves",
    "section": "Resources",
    "text": "Resources\n\nChapter of the Elegant graphics for data analyses book on date scales\nGet started with lubridate from the package homepage."
  }
]